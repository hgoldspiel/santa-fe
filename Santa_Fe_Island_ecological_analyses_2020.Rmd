---
title: "Ecological Outcomes of Tortoise Restoration on Santa Fe Island"
author: "Harrison B Goldspiel"
date: 'Last update: `r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    toc: true
    toc_float: true
    smooth_scroll: false
    css: "styles.css"
    theme: yeti
    code_folding: show
editor_options: 
  chunk_output_type: inline
---

<style>
p.caption {
  font-size: 0.8em;
  font-style: italic;
}
</style>

```{r, setup, warning = FALSE, message = FALSE}
# clear working environment and set wd
rm(list=ls())
wd <- getwd()

library(knitr)
library(kableExtra)
knitr::opts_knit$set(root.dir = wd)
knitr::opts_chunk$set(fig.align = "center", fig.pos = "h", 
                      message = FALSE, warning = FALSE, dpi = 600)

#load some R packages
library(ggplot2)
library(ggalt)
library(ggthemes)
library(ggExtra)
library(lisa)
library(lubridate)
library(tidyverse)
library(reshape2)

# load custom functions and settings
source("custom_functions_settings.R", verbose = FALSE)
```
\  
\  
\  

**Summary**: This document provides a synthesis of initial demographic outcomes of the release of 551 captive bred Española tortoises on the island of Santa Fe in the Galapagos archipelago. I summarize the results from three separate analyses on the (1) growth, (2) survival, and (3) dispersal of these tortoises from 2015 to 2020.

```{r, tortoise-photo, echo = FALSE, out.width = "35%", out.height = "35%", fig.align = "center", fig.cap = "A juvenile Española tortoise on Santa Fe Island."}

include_graphics("images/tortoise.jpg")
```

I'll also examine potential impacts of tortoises on the Santa Fe land iguana population, the only major (extant) native herbivore on Santa Fe, as well as the endemic cactus population.

# Growth
***

## Tortoise morphology---Santa Fe

First I'll load the tortoise data with body metrics and time intervals. 

```{r, load-data}
library(readxl)
# load recapture data
sf_recaps <- suppressMessages(read_excel(
  path = "data/tortoise_data_Mar_2020.xlsx",
  sheet = "Marcacion Recaptura Limpias", na = "NA",
  col_types = c("numeric", rep("text", 4), rep("numeric", 5), 
                rep("text", 4), rep("numeric", 12), rep("text", 3))))

head(sf_recaps)
```

We'll change some column names and create some extra survey variables. I'll clean everything in a long chunk (hidden) and create a new object for examining growth patterns.

```{r, clean-Santa-Fe-tortoise-recapture-data-for-growth-GAMs, echo = FALSE}
# reformat recapture data
recaps_df <- data.frame(PIT_capture = sf_recaps$`Número de PIT`,
                        PIT_release = sf_recaps$`PIT DPNG liberado`,
                        PIT_final = sf_recaps$PIT_final,
                        Year = sf_recaps$`Año`, 
                        Month = sf_recaps$Mes, 
                        Day = sf_recaps$`Día`,
                        Latitude = sf_recaps$Latitud, Longitude = sf_recaps$Longitud,
                        LC_release = sf_recaps$LC_at_liberation,
                        Peso_release = sf_recaps$Peso_at_liberation,
                        Age_release = sf_recaps$age_at_liberation,
                        LC_capture = sf_recaps$`Largo Curvo (cm)`, 
                        Peso_capture = sf_recaps$`Peso (Kg)`, 
                        Age_capture = sf_recaps$age_at_recapture,
                        Cohort = as.factor(sf_recaps$Year_liberated))
# load release data
sf_release <- read_excel(path = "data/tortoise_data_Mar_2020.xlsx",
                         sheet = "Tortugas liberadas DPNG", na = "NA",
                         col_types = c(rep("text", 5), "numeric", "date", 
                                       rep("numeric", 3), "text", 
                                       rep("numeric", 6)))
# reformat release data
release_df <- data.frame(PIT_capture = sf_release$`No. con PIT`,
                         PIT_release = sf_release$`No. con PIT`,
                         PIT_final = sf_release$`No. con PIT (final)`,
                         Year = sf_release$`Year liberated`, 
                         Month = sf_release$`Month liberated`,
                         Day = sf_release$`Day liberated`,
                         Latitude = sf_release$Latitud, Longitude = sf_release$Longitud,
                         LC_release = sf_release$`Largo curvo (cm)`,
                         Peso_release = sf_release$`Peso (g)`/1000,
                         Age_release = sf_release$Age - 0.5,
                         LC_capture = sf_release$`Largo curvo (cm)`,
                         Peso_capture = sf_release$`Peso (g)`/1000,
                         Age_capture = sf_release$Age - 0.5,
                         Cohort = as.factor(sf_release$`Year liberated`))

# combine release and recapture data
santafe.data <- rbind(recaps_df, release_df)

# add unique row ID
santafe.data$unique_id <- c(1:nrow(santafe.data))

# add occasions
santafe.data$Occasion <- NA
santafe.data$Occasion[santafe.data$Year == 2015 & santafe.data$Month == 6] <- 1
santafe.data$Occasion[santafe.data$Year == 2015 & santafe.data$Month == 8] <- 2
santafe.data$Occasion[santafe.data$Year == 2016 & santafe.data$Month == 6] <- 3
santafe.data$Occasion[santafe.data$Year == 2017 & santafe.data$Month == 4] <- 4
santafe.data$Occasion[santafe.data$Year == 2017 & santafe.data$Month == 6] <- 5
santafe.data$Occasion[santafe.data$Year == 2018 & santafe.data$Month == 6] <- 6
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 2] <- 7
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 4] <- 8
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 8] <- 9
santafe.data$Occasion[santafe.data$Year == 2020] <- 10

# add more exact liberation measurement dates
santafe.data$Year_firstmeasure <- santafe.data$Year
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2015"] <- 2015
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2017"] <- 2017
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2019"] <- 2018
santafe.data$Month_firstmeasure <- santafe.data$Month
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2015"] <- 6
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2017"] <- 4
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2019"] <- 12
santafe.data$Day_firstmeasure <- santafe.data$Day
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2015"] <- 27
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2017"] <- 17
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2019"] <- 12

# create "LC class" variable
santafe.data$LC_class <- floor(santafe.data$LC_capture/10)*10

# calculate actual ages (to the nearest month) upon each capture
elapsed_months <- function(end_date, start_date) {
    ed <- as.POSIXlt(end_date)
    sd <- as.POSIXlt(start_date)
    12 * (ed$year - sd$year) + (ed$mon - sd$mon)
}

santafe.data$date_capture <- as.Date(paste(santafe.data$Year, 
                                           santafe.data$Month, 
                                           santafe.data$Day, 
                                           sep = "-"))

santafe.data$date_firstmeasure <- as.Date(paste(santafe.data$Year_firstmeasure, 
                                           santafe.data$Month_firstmeasure, 
                                           santafe.data$Day_firstmeasure, 
                                           sep = "-"))

santafe.data$dec.date <- decimal_date(santafe.data$date_capture)


santafe.data$Age_actual <- 
  santafe.data$Age_release + elapsed_months(santafe.data$date_capture,
                                            santafe.data$date_firstmeasure)/12

# let's impute the mean length and weight of 2019 tortoises at release for 982126055990440
santafe.data$LC_release[santafe.data$PIT_final == "982126055990440"] <- 
  mean(na.omit(santafe.data$LC_release[santafe.data$Cohort == "2019"]))
santafe.data$Peso_release[santafe.data$PIT_final == "982126055990440"] <-
  mean(na.omit(santafe.data$Peso_release[santafe.data$Cohort == "2019"]))
santafe.data$LC_capture[santafe.data$PIT_final == "982126055990440"] <-
  santafe.data$LC_release[santafe.data$PIT_final == "982126055990440"]
santafe.data$Peso_capture[santafe.data$PIT_final == "982126055990440"] <-
  santafe.data$Peso_release[santafe.data$PIT_final == "982126055990440"]

# let's omit all individuals without any release data
santafe.raw <- santafe.data[which(santafe.data$LC_release > 0),]
```

We have some measurement errors and potential outliers in the data. We'll label points as outliers according to a 3 * IQR rule, with quartiles specified separately along 2-cm length increments (for increments with 10 or more points). 

We might have to manually label some additional measurements as outliers if they fall in an increment with a small sample size but are clearly off the length versus weight curve. 

```{r, inspect-scatterplot-for-outliers-among-Santa-Fe-tortoises}
# get thresholds for extreme outliers (3 * IQR)
santafe.thresholds <- santafe.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  group_by(lc_cat_2) %>%
  summarise(Q3 = quantile(Peso_capture, 0.75, na.rm = T),
            Q1 = quantile(Peso_capture, 0.25, na.rm = T),
            IQR = Q3-Q1,
            upper = Q3+3*IQR,
            lower = Q1-3*IQR,
            n = n()) %>% ungroup()

# identify points beyond outlier thresholds
santafe.outliers <- santafe.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  left_join(santafe.thresholds, by = "lc_cat_2") %>%
  filter(Peso_capture > upper & n >= 10 | Peso_capture < lower & n >= 10 |
           Peso_capture > 1 & LC_capture < 20)

# number of Santa Fe outliers
nrow(santafe.outliers)

ggplot(santafe.raw, aes(x = LC_capture, y = Peso_capture)) + 
  geom_point(alpha = 0.3, shape = 16) + 
  geom_point(data = santafe.outliers, aes(x = LC_capture, y = Peso_capture), 
             colour="red", fill = "red", shape = 16) + 
  theme_classic() + mythemes
```

Let's omit those 71 outliers before modeling body condition and growth rates.

```{r, omit-santafe-outliers}
santafe.clean <- santafe.raw[santafe.raw$unique_id %notin% 
                               santafe.outliers$unique_id,]
santafe.clean$PIT_final <- as.factor(santafe.clean$PIT_final)
```

### Body condition

Here I'll model the simple relationship between body mass and size (curved carapace length) using generalized additive mixed models (GAMMs), including a random effect for tortoise ID (PIT tag). This will allow us to estimate a body condition function, while also accounting for the variation in individual morphology and growth patterns. We can do this in the `mgcv` package (Wood, 2011).

```{r, body-condition-GAM-for-Santa-Fe-tortoises}
library(mgcv)
gam.largavpeso.sf <- bam(Peso_capture ~ s(LC_capture) + s(PIT_final, bs="re"), 
                         data = santafe.clean)
summary(gam.largavpeso.sf)
```

```{r, plot-predicted-body-condition-of-SF-tortoises}
library(tidymv)
largavpeso.sf.plot <-  
  plot_smooths(model = gam.largavpeso.sf, series = LC_capture) + 
  geom_point(data = santafe.clean, 
             mapping = aes(x = LC_capture, y = Peso_capture, fill = Cohort,
                           color = Cohort, shape = Cohort), 
             position = "jitter", alpha = 0.7) + 
  geom_line(size = 0.5, col = "black") +
  labs(y = "Weight (kg)", x = "Curved carapace length (cm)") + 
  scale_shape_manual(values = c(21, 22, 24)) +
  scale_color_manual(values = c("indianred4", "dodgerblue4", "goldenrod")) +
  scale_fill_manual(values = c("indianred4", "dodgerblue4", "goldenrod")) + 
  theme(legend.position = "top") + theme_classic() + mythemes

largavpeso.sf.plot
```

It doesn't look like there is any between-cohort variation in body condition. All cohorts are evenly distributed along the fitted body condition curve.

We can explore this further by platting the residuals. Let's inspect a few things:

+ Residuals by release cohort
+ Residuals by time

```{r, body-cond-res-plots}
body.res <-
  santafe.clean %>%
  filter(!is.na(LC_capture) & !is.na(Peso_capture)) %>%
  mutate(resid = gam.largavpeso.sf$residuals) %>%
  mutate(time_since_release = date_capture - date_firstmeasure,
         Cohort2 = as.factor(case_when(Cohort == "2015" ~ "Cohort 1",
                                       Cohort == "2017" ~ "Cohort 2",
                                       Cohort == "2019" ~ "Cohort 3")),
         release = ifelse(time_since_release == 0 | time_since_release == 77, 
                          "release", "recapture"),
         time_occ = case_when(Occasion == "1" ~ mean(dec.date[Occasion == "1"]),
                              Occasion == "2" ~ mean(dec.date[Occasion == "2"]),
                              Occasion == "3" ~ mean(dec.date[Occasion == "3"]),
                              Occasion == "4" ~ mean(dec.date[Occasion == "4"]),
                              Occasion == "5" ~ mean(dec.date[Occasion == "5"]),
                              Occasion == "6" ~ mean(dec.date[Occasion == "6"]),
                              Occasion == "7" ~ mean(dec.date[Occasion == "7"]),
                              Occasion == "8" ~ mean(dec.date[Occasion == "8"]),
                              Occasion == "9" ~ mean(dec.date[Occasion == "9"]),
                              Occasion == "10" ~ mean(dec.date[Occasion == "10"]
                                                      )))
                              
ggplot(body.res, aes(x = Cohort2, y = resid)) +
  geom_violin(fill = "midnightblue", color = "midnightblue") +
  geom_boxplot(width = 0.1) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  ylab("Body condition residual") + xlab("Cohort") +
  theme_classic() + mythemes

body.res %>%
  group_by(time_occ, Cohort2) %>%
  summarise(resid = mean(resid)) %>%
  ggplot() +    
  geom_hline(aes(yintercept = 0), lty = "dashed", alpha = 0.4) +
  geom_point(data = body.res, aes(x = time_occ, y = resid), 
             shape = 16, alpha = 0.1, col = "grey50", position = "jitter") +
  geom_point(aes(x = time_occ, y = resid), color = "red", shape = "-", size = 6) +
  facet_wrap(~Cohort2, nrow = 3) + 
  ylab("Body condition residual") + xlab("Capture date") +
  theme_classic() + mythemes -> bc.res.plot

bc.res.plot
```
There don't appear to be any differences in body condition between release cohorts. There also don't appear to be any trends in body condition over time, except for a recent uptick (heavier) in the last year.

## Tortoise morphology---Española

```{r, read-espanola-data}
espanola.data <- read.csv("data/espanola_tortoise_data.csv")

# add unique id column
espanola.data$unique_id <- c(1:nrow(espanola.data))
```

Let's first examine the data for potential outliers as we did before with the Santa Fe tortoises. We'll constrain our Española data to be within the same age range of our Santa Fe tortoises. We'll also omit data from 1980 to 1991 for comparing body condition, as the weight measurements during those years were filled with measurement or data entry errors that cannot be resolved.

```{r, look-for-Espanola-outliers}
espanola.raw <- 
  espanola.data[espanola.data$Year %notin% c(1980:1991) &
                  espanola.data$Age_capture >= min(santafe.clean$Age_actual) &
                  espanola.data$Age_capture <= max(santafe.clean$Age_actual),]

espanola.thresholds <- espanola.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  group_by(lc_cat_2) %>%
  summarise(Q3 = quantile(Peso_capture, 0.75, na.rm = T),
            Q1 = quantile(Peso_capture, 0.25, na.rm = T),
            IQR = Q3-Q1,
            upper = Q3+3*IQR,
            lower = Q1-3*IQR,
            n = n()) %>% ungroup()

espanola.outliers <- espanola.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  left_join(espanola.thresholds, by = "lc_cat_2") %>%
  filter(Peso_capture > upper & n >= 10 | Peso_capture < lower & n <= 10)

nrow(espanola.outliers)

ggplot(espanola.raw, aes(x = LC_capture, y = Peso_capture)) + 
  geom_point(alpha = 0.3, shape = 16) +
  geom_point(data = espanola.outliers, aes(x=LC_capture, y = Peso_capture), 
             colour="red", fill = "red", shape = 16) + xlim(c(15,70)) +
  theme_classic() + mythemes
```

There are 27 obvious outliers here that we'll remove.

```{r}
espanola.clean <- 
  espanola.data[espanola.data$unique_id %notin% espanola.outliers$unique_id &
                  espanola.data$Year %notin% c(1980:1991) &
                  espanola.data$LC_capture < 70 &
                  espanola.data$Age_capture <= max(santafe.clean$Age_actual) &
                  espanola.data$Age_capture >= min(santafe.clean$Age_actual),]

espanola.clean <- espanola.clean[!is.na(espanola.clean$Year),]
```

### Growth GAMs

Let's combine our cleaned Santa Fe and Española datasets to model both populations together and display the regional growth contrasts.

```{r}
espanola.clean$dec.date <- 
  decimal_date(as.Date(paste(espanola.clean$Year, 
                             espanola.clean$Month, 
                             espanola.clean$Year, 
                             sep = "-"), format = "%Y-%m-%d"))
espanola.clean$Age_actual <- espanola.clean$dec.date - espanola.clean$Birth_year
espanola.clean$mod.ID <- as.factor(espanola.clean$mod.ID)
espanola.clean$PIT <- as.factor(espanola.clean$PIT)

hood.data <- data.frame(
  dec.date = c(santafe.clean$dec.date, espanola.clean$dec.date),
  LC_capture = c(santafe.clean$LC_capture, espanola.clean$LC_capture),
  Peso_capture = c(santafe.clean$Peso_capture, espanola.clean$Peso_capture),
  Age_release = c(santafe.clean$Age_release, espanola.clean$Age_release),
  Age_capture = c(santafe.clean$Age_actual, espanola.clean$Age_actual),
  ID = as.factor(c(as.character(santafe.clean$PIT_final), 
                   as.character(espanola.clean$mod.ID))),
  Island = as.factor(c(rep("Santa Fe", nrow(santafe.clean)), 
                           rep("Española", nrow(espanola.clean)))))

# make island an ordered factor for the factor smooth interactions
hood.data$Island_ord <- ordered(hood.data$Island)

# summary of body condition data captures
hood.data %>%
  group_by(ID, Island) %>%
  summarise(n_raw = n()) %>%
  group_by(Island) %>%
  summarise(tortoises = length(unique(ID)),
            n = sum(n_raw),
            min_n = min(n_raw),
            mean_n = mean(n_raw),
            max_n = max(n_raw),
            sd_n = sd(n_raw)) %>% ungroup()
```

```{r}
gal.clim <- read.csv("data/pa_cdf_climate.csv")
gal.clim$date <- as.Date(gal.clim$observation_date, format = "%m/%d/%Y")
gal.clim$yr_month <- format(gal.clim$date, "%Y-%m")

## get potential evapotranspiration
gal.clim$pet_turc <- 
  0.013*(gal.clim$mean_air_temp/(gal.clim$mean_air_temp+15))*((100/4.1868)+50)

## get monthly temp values
gal.clim.month.mean <- 
  gal.clim %>%
  group_by(yr_month) %>%
  summarise(mean_temp = mean(mean_air_temp, na.rm = T),
            mean_min_temp = mean(min_air_temp, na.rm = T),
            mean_max_temp = mean(max_air_temp, na.rm = T),
            mean_humidity = mean(humidity, na.rm = T),
            tot_precip = sum(precipitation, na.rm = T),
            dec.date = decimal_date(mean(date)))

## new data frame of dates and spi5 values
library(SPEI)
cdf.spi <- 
  data.frame(
    yr_month = gal.clim.month.mean$yr_month[5:nrow(gal.clim.month.mean)],
    dec.date = gal.clim.month.mean$dec.date[5:nrow(gal.clim.month.mean)],
    tot_prec = gal.clim.month.mean$tot_precip[5:nrow(gal.clim.month.mean)],
    spi5 = spi(gal.clim.month.mean$tot_precip,5)$fitted[5:nrow(gal.clim.month.mean),])

## create lagged SPI values to connect to body condition data (1 year rolling average)
cdf.spi$spi5_1yr = rollmean(cdf.spi$spi5, 12, align = "right", fill = NA)

find.spi.lag <- function(cap.date) {
  return(cdf.spi$spi5_1yr[which.min(abs(cdf.spi$dec.date - cap.date))])
  }

hood.data <- hood.data %>%
  mutate(spi5_1yr = map_dbl(dec.date, find.spi.lag))
```


### Body condition

Let's model the relationship between length and weight and compare that body condition function to the Santa Fe tortoise data.

```{r, contrast-SF-and-Espanola-body-condition-scatterplot}
hood.bc.gam <- bam(Peso_capture ~ Island + s(LC_capture) +
                   s(LC_capture, by = Island_ord) + 
                   s(spi5_1yr) +
                   s(ID, bs = "re"), data = hood.data)

summary(hood.bc.gam)

# create length sequence for prediction
larga.sim = c(rep(seq(min(santafe.clean$LC_capture), 
                max(santafe.clean$LC_capture), length.out = 100), 2))

# create sequence of islands for prediction
island.sim = c(rep("Santa Fe", 100), rep("Española", 100))

# create new data frame with model covariates for prediction
newdat = data.frame(LC_capture = larga.sim, 
                    Island_ord = island.sim, 
                    Island = island.sim,
                    spi5_1yr = 0)

# predict
hood.bc.pred <- predict.gam(hood.bc.gam, newdata = newdat,
                            exclude = "s(ID)", newdata.guaranteed = TRUE, 
                            type = "response", se.fit=TRUE)

# put predicted values and error in new data frame for plotting
hood.bc <- data.frame(cbind(island.sim), 
                      as.numeric(as.character(larga.sim)), 
                      as.numeric(as.character(hood.bc.pred$fit)),
                      as.numeric(as.character(hood.bc.pred$se.fit)))
colnames(hood.bc) <- c("Island", "larga", "peso", "SE")

# plot
hood.bc.plot <- ggplot(hood.bc, 
                       aes(x = larga, y = peso, color = Island, fill = Island)) + 
  geom_ribbon(aes(ymin = peso - 1.96*SE, ymax = peso + 1.96*SE), 
              color = "transparent", alpha = 0.2) +
  geom_point(inherit.aes = FALSE, 
             data = hood.data[hood.data$Island == "Santa Fe",], 
             mapping = aes(x = LC_capture, y = Peso_capture), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#00BFC4") + 
  geom_point(inherit.aes = FALSE, 
             data = hood.data[hood.data$Island == "Española",], 
             mapping = aes(x = LC_capture, y = Peso_capture), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#F8766D") + 
  geom_line(size = 1.1) +
  scale_color_manual(values = c("indianred4", "dodgerblue4")) + 
  scale_fill_manual(values = c("indianred4", "dodgerblue4")) +
  labs(y = "Weight (kg)", x = "Curved carapace length (cm)") + 
  theme_classic() + mythemes + theme(legend.position = "bottom") + 
  xlim(min(santafe.clean$LC_capture), max(santafe.clean$LC_capture)) + 
  ylim(c(0,22))

hood.bc.plot
```

It looks like the Santa Fe and Española tortoise populations are showing similar morphological patterns. There is a slight divergence in body condition that begins at about 40 cm, where tortoises on Santa Fe are a bit heavier for a given size than those on Española.

Let's export our body condition model table to a csv file.

```{r}
bc.model.summary <- summary(hood.bc.gam)
write.csv(bc.model.summary$p.table, "data/bc_mod_parametric.csv")
write.csv(bc.model.summary$s.table, "data/bc_mod_smooth.csv")
```

Let's look at the data just one other way with box plots.

```{r, contrast-SF-and-Espanola-body-condition-boxplot}
hood.data$LC_class <- as.factor(floor_any(hood.data$LC_capture, 10))

ggplot(na.omit(hood.data[hood.data$LC_class == "20" | 
                           hood.data$LC_class == "30" |
                           hood.data$LC_class == "40" | 
                           hood.data$LC_class == "50",]), 
       aes(x = LC_class, y = Peso_capture, color = Island)) +
  geom_boxplot(outlier.alpha = 0.5, outlier.shape = 16) + 
  labs(y = "Weight (kg)", x = "Curved carapace length class (cm)") +
  scale_color_manual(values = c("indianred4", "dodgerblue4")) +
  guides(color = guide_legend(title = "Island")) + 
  theme_classic() + mythemes + 
  theme(legend.position = "bottom")
```

These boxplots indicate that any small divergence in body condition specified by the GAM, is likely negligible.

## Tortoise growth rates

Let's now compare the actual somatic growth rates for tortoises on Santa Fe and Española, using intermediate length as a predictor. 

I'll follow a few protocols to make our Santa Fe and Española data more comparable and limit data errors: (1) I omit all growth intervals less than 1 year or greater than 5 years (the latter being the amount of time elapsed since tortoises were introduced to Santa Fe); (2) I apply some filtering rules to omit some questionable measurements that are likely products of data recording and entering errors; and (3) I truncate tabulated growth rates at negative and positive extremes of -2.5 cm / yr and 10 cm / yr.

```{r, tabulate-growth-data}
# first get reduced data frame with:
## (1) just individuals captured at least twice, and 
## (2) containing size data
growth.input <- hood.data %>%
  filter(is.na(LC_capture) == FALSE) %>%
  group_by(Island, ID) %>%
  filter(n() > 1) %>%
  mutate(cap_date = dec.date) %>%
  arrange(cap_date) %>%
  ungroup() %>%
  mutate(unique_id = c(1:length(dec.date))) %>% 
  as.data.frame()

# function to calculate growth rates
growth.tabulate <- function(data){
  ## CLEANING LOOP
  clean_data <- NULL
  # nest by island
  for(Island in unique(data$Island)){
    # nest by tortoise ID
    for(ID in unique(data$ID[data$Island %in% Island])){
      tdata <- data[data$Island %in% Island & data$ID %in% ID,]
      final_cap = last(tdata$unique_id)
      current_cap = 1
      while(current_cap != final_cap){
        for(cap in 2:nrow(tdata)){
          current_cap = tdata$unique_id[cap]
          if(
            # If recap is too soon after the previous capture...
            tdata$cap_date[cap] - tdata$cap_date[cap-1] < 1 |
            # or shrinks
            tdata$LC_capture[cap] / tdata$LC_capture[cap-1] < 0.95 |
            # or grows quicker than 10 cm / yr
            (tdata$LC_capture[cap] - tdata$LC_capture[cap-1]) / 
            (tdata$cap_date[cap] - tdata$cap_date[cap-1]) > 10) {
            # remove cap 
            tdata <- tdata[-cap,]
            break
          }
        }
      }
      clean_data <- bind_rows(clean_data, tdata)
    }
  }
  #### CALCULATE GROWTH RATES FOR REMAINING INTERVALS ####
  growth_data <- NULL
  clean_data <- clean_data %>%
    group_by(Island, ID) %>%
    filter(n() > 1) %>% ungroup() %>%
    as.data.frame()
  # construct rows for growth dataset from clean data
  for(Island in unique(clean_data$Island)){
    # nest by tortoise ID
    for(ID in unique(clean_data$ID[clean_data$Island %in% Island])){
      tdata <- clean_data[clean_data$Island %in% Island & clean_data$ID %in% ID,]
      for(cap in 2:nrow(tdata)){
        new.df <- data.frame(
          # island
          Island = Island,
          # ID of tortoise
          ID = ID,
          # capture date
          cap_year = tdata$cap_date[cap-1],
          # recapture date
          recap_year = tdata$cap_date[cap],
          # time between captures
          years_between = tdata$cap_date[cap] - tdata$cap_date[cap-1],
          # mid-year between captures
          midyear = mean(c(tdata$cap_date[cap], tdata$cap_date[cap-1])),
          # original length
          cap_lc = tdata$LC_capture[cap-1],
          # recapture length
          recap_lc = tdata$LC_capture[cap],
          # size difference between captures
          delta_lc = tdata$LC_capture[cap] - tdata$LC_capture[cap-1],
          # mid-size between captures
          mid_lc = mean(c(tdata$LC_capture[cap], tdata$LC_capture[cap-1])),
          # mid age
          mid_age = mean(c(tdata$Age_capture[cap], tdata$Age_capture[cap-1])),
          # growth rate
          growth_cm_yr = (tdata$LC_capture[cap] - tdata$LC_capture[cap-1])/
            (tdata$cap_date[cap] - tdata$cap_date[cap-1]),
          spi5 = mean(cdf.spi$spi5[cdf.spi$dec.date >= tdata$cap_date[cap-1] &
                                    cdf.spi$dec.date < tdata$cap_date[cap]]),
          stringsAsFactors = FALSE)
        growth_data <- bind_rows(growth_data, new.df)
      }
    }
  }
  return(growth_data)
}

# run growth function
growth.output <- growth.tabulate(growth.input)

# filter out additional growth intervals
growth.dat <- growth.output %>%
  filter(years_between <= 5) %>%
  mutate(ID = as.factor(ID),
         Island = as.factor(Island),
         growth_rate_pc = p.rank(growth_cm_yr),
         growth_rate_final = growth_cm_yr,
         growth_rate_final = ifelse(growth_cm_yr <= -2.5 | 
                                      growth_cm_yr >= 10, NA, growth_rate_final))
```

Let's take a quick look at a summary of our growth dataset.

```{r, growth-dat-summary}
growth.dat %>%
  group_by(Island) %>%
  summarise(mean_growth = mean(growth_rate_final),
            sd_growth = sd(growth_rate_final)) -> mean.growth.rates

growth.dat %>%
  group_by(ID, Island) %>%
  summarise(n_raw = n()) %>%
  group_by(Island) %>%
  summarise(tortoises = length(unique(ID)),
            n = sum(n_raw),
            min_n = min(n_raw),
            mean_n = mean(n_raw),
            max_n = max(n_raw),
            sd_n = sd(n_raw)) %>%
  left_join(mean.growth.rates, by = "Island") %>%
  mutate(se = sd_growth/sqrt(n)) %>%
  ungroup()
```

Okay now let's run a somatic growth model for just Santa Fe.

```{r, Santa-Fe-somatic-growth-rates-GAM}
santafe.growth.dat <- growth.dat %>%
  filter(Island == "Santa Fe") %>%
  droplevels()

santafe.growth.gam <- bam(growth_rate_final ~ 
                            s(mid_lc) + 
                            s(spi5) +
                            s(ID, bs="re"), 
                          data = santafe.growth.dat)

summary(santafe.growth.gam)
```

```{r, plot-predicted-somatic-growth-rates-of-SF-tortoises}
larga.sim = seq(min(na.omit(santafe.growth.dat$mid_lc)), 
                max(na.omit(santafe.growth.dat$mid_lc)), length.out = 100)

# santa fe prediction
newdat <- data.frame(mid_lc = larga.sim, spi5 = 0)
santafe.pred <- predict.gam(santafe.growth.gam, newdata = newdat, 
                            exclude = "s(ID)", newdata.guaranteed = TRUE,
                            type = "response", se.fit=TRUE)
santafe.pred <- data.frame(cbind(larga.sim, santafe.pred$fit, 
                                 santafe.pred$se.fit))
colnames(santafe.pred) <- c("larga", "rate", "SE")

### PLOT ###
santafe.growth.plot <-  ggplot(santafe.pred, aes(x = larga, y = rate)) + 
  geom_point(inherit.aes = FALSE, data = santafe.growth.dat, 
             mapping = aes(x = mid_lc, y = growth_cm_yr), 
             position = "jitter", alpha = 0.1) + geom_line(size = 1.1) + 
  geom_line(aes(y=rate - 2*SE), linetype = "dashed") + 
  geom_line(aes(y=rate + 2*SE), linetype = "dashed") + 
  geom_line(mapping = aes(y = 0), linetype = "dashed", col = "black") + 
  labs(y = expression(paste("Growth rate (cm yr"^{-1},")")), 
       x = "Intermediate curved carapace length (cm)") + 
  theme_classic() + mythemes +
  scale_shape_manual(values=c(2,1)) + ylim(-2.5, 10)

santafe.growth.plot 
```

The Santa Fe tortoises are growing steadily. 

Let's examine the residuals over time.

```{r, fig.width = 7, fig.height = 4}
santafe.cohorts <- santafe.raw %>%
  group_by(PIT_final) %>%
  summarise(ID = unique(PIT_final),
            Cohort = unique(Cohort))

growth.res <-
  santafe.growth.dat %>%
  filter(!is.na(growth_rate_final)) %>%
  mutate(resid = santafe.growth.gam$residuals) %>%
  left_join(santafe.cohorts, by = "ID") %>%
  mutate(Cohort2 = case_when(Cohort == "2015" ~ "1 (2015)",
                             Cohort == "2017" ~ "2 (2017)",
                             Cohort == "2019" ~ "3 (2019"))

growth.res.plot <- 
  ggplot(growth.res, aes(x = midyear, y = resid)) +
  geom_point(shape = 16, alpha = 0.2) + 
  scale_y_continuous(breaks = c(-3,0,3)) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  ylab("Growth residual") + xlab("Intermediate capture date") +
  theme_classic() + mythemes

growth.res.plot
```

There doesn't appear to be any residual trend over time, indicating that growth rates are stable for the Santa Fe tortoise population.

Let's compare Santa Fe and Española growth rates in the same model.

```{r, hoodensis-somatic-growth-GAM}
growth.dat$Island_ord = ordered(growth.dat$Island)

hood.growth.gam <- bam(growth_rate_final ~ Island + s(mid_lc) + 
                         s(mid_lc, by = Island_ord) + 
                         s(spi5) +
                         s(ID, bs="re"), data = growth.dat)

summary(hood.growth.gam)
```

There is a difference in growth rates between the two populations.

Let's export this model table to a csv.

```{r}
growth.model.summary <- summary(hood.growth.gam)
write.csv(growth.model.summary$p.table, "data/growth_mod_parametric.csv")
write.csv(growth.model.summary$s.table, "data/growth_mod_smooth.csv")
```

Now let's plot out the predicted growth rates for each population.

```{r, plot-predicted-hoodensis-growth-rates}
age.sim = rep(c(seq(min(na.omit(growth.dat$mid_age)), 
                max(na.omit(growth.dat$mid_age)), length.out = 100)),2)

length.sim = c(seq(min(growth.dat$mid_lc[growth.dat$Island == "Santa Fe"]), 
                max(growth.dat$mid_lc[growth.dat$Island == "Santa Fe"]), 
                length.out = 100),
              seq(min(growth.dat$mid_lc[growth.dat$Island == "Española"]), 
                max(growth.dat$mid_lc[growth.dat$Island == "Española"]), 
                length.out = 100))

newdat = data.frame(mid_lc = length.sim,
                    Island = as.factor(c(rep("Santa Fe", 100), 
                                         rep("Española", 100))),
                    Island_ord = as.factor(c(rep("Santa Fe", 100), 
                                             rep("Española", 100))),
                    spi5 = 0)

hood.pred <- predict.gam(hood.growth.gam, newdata = newdat, 
                         newdata.guaranteed = TRUE,
                             exclude = "s(ID)", type = "response", se.fit=TRUE)
hood.pred <- data.frame(length = length.sim, 
                        Island = c(rep("Santa Fe", 100), rep("Española", 100)), 
                        rate = hood.pred$fit, 
                        SE = hood.pred$se.fit)

hood.growth.plot <- ggplot(hood.pred, 
                           aes(x = length, y = rate, 
                               fill = Island, color = Island)) + 
  geom_point(inherit.aes = FALSE, 
             data = growth.dat[growth.dat$Island == "Santa Fe",], 
             mapping = aes(x = mid_lc, y = growth_rate_final), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#00BFC4") + 
  geom_point(inherit.aes = FALSE, 
             data = growth.dat[growth.dat$Island == "Española",], 
             mapping = aes(x = mid_lc, y = growth_rate_final), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#F8766D") + 
  geom_ribbon(aes(ymin = rate - 1.96*SE, ymax = rate + 1.96*SE), 
              color = "transparent", alpha = 0.2) +
  geom_line(size = 1.1) + 
  scale_color_manual(values = c("indianred4", "dodgerblue4")) +
  scale_fill_manual(values = c("indianred4", "dodgerblue4")) +
  labs(y = expression(paste("Growth rate (cm yr"^{-1},")")), 
       x = "Intermediate length (cm)") + theme_classic() + mythemes +
  ylim(0, 7.5) + theme(legend.position = "bottom")

hood.growth.plot
```
There are in fact some differences in the growth rates between tortoises on Santa Fe and Española. The Santa Fe tortoises begin with slower growth rates than those on Española. This could possibly be explained by the harsher environment on Santa Fe. Juvenile tortoises may have more limited foraging opportunities during the day in the hot season because of there is less cover. Release ages could also play a role, as Santa Fe tortoises were on average older upon release than Española tortoises. Tortoises may require a few years to acclimate to their environment after being repatriated.

After they exceed about 40 cm in length, the Santa Fe tortoises begin to growing faster than their counterparts on Española. This would make sense, considering the greater food resources on Santa Fe. There might simply be more food for them to eat.

Of course, climate may play an important role in this contrast. The Española tortoise program spanned almost 50 years from 1975 to present. The Santa Fe program did not begin until 2015. The different time frames mean that we are capturing growth during different periods of climate variation that have unclear effects on tortoise growth.

Let's create a composite growth figure to include in the manuscript.

```{r, composite-growth-fig, fig.height = 7, fig.width = 7}
library(ggpubr)
growth.fig <- 
  ggarrange(hood.bc.plot, hood.growth.plot,
            nrow = 2, common.legend = TRUE, legend = "top",
            labels = c("a", "b"), label.x = c(0.1, 0.1))
growth.fig

ggsave("images/hoodensis_bc_growth_fig.jpg", device = "jpeg",
       width = 7, height = 7, units = "in", dpi = 600)
```

# Survival
***
## Model preparation

Here we'll use capture-mark-recapture population models (i.e., Cormack-Jolly-Seber or CJS models) to get an estimate of survival rates of the three release cohorts of tortoises on Santa Fe. I'll implement these models in Program MARK via the `RMark` package.

First we need to reformat the mark-recapture data to create individual encounter histories for program MARK.

```{r, prepare-survival-data-for-RMark}
library(reshape2)
## Aggregate by tag/mark ID to create annual encounter histories
santafe.ch <- santafe.raw %>%
  dplyr::select(c("PIT_final", "Occasion", "LC_capture", "Age_actual", 
           "Age_release", "LC_release", "Peso_release", "Cohort")) %>%
  mutate(PIT = as.factor(PIT_final),
         Cohort = as.factor(Cohort)) %>%
  group_by(PIT, Occasion, Cohort) %>%
  summarise_all(mean) %>%
  dcast(PIT + Age_release + LC_release + Peso_release + Cohort ~ Occasion) %>%
  mutate_at(c(as.character(1:10)), ~ifelse(is.na(.), 0, 1))
  
colnames(santafe.ch) <- c("PIT", "age_release", "length", "weight", 
                          "release_cohort",  "T0", "T0_17", "T1", "T1_83",
                          "T2", "T3", "T3_67", "T3_84", "T4_17", "T4_75")

# aggregate encounter history and reorder columns for input to MARK
santafe.ch <- 
  data.frame(ch = paste(santafe.ch$T0, santafe.ch$T0_17, santafe.ch$T1, 
                        santafe.ch$T1_83, santafe.ch$T2, santafe.ch$T3,
                        santafe.ch$T3_67, santafe.ch$T3_84,
                        santafe.ch$T4_17, santafe.ch$T4_75, sep = ""), 
             santafe.ch[,c(2:5)])

## write as a .txt file 
write.table(santafe.ch, "data/santafe_ch.txt", sep = "\t", col.names = TRUE, 
            row.names = FALSE, quote=FALSE)
```

We'll use that text file that I just exported to set up the input data.

```{r, set up input data for CJS}
library(RMark)
tortoises <- import.chdata("data/santafe_ch.txt", header = TRUE, 
                               field.types=c("n", "n", "n", "f")) 

effortcov <- data.frame(read.csv("data/tortoise_survey_effort.csv"))
```

Now we'll process the input data for CJS. Because there were uneven time intervals between tortoise surveys we'll have to be careful here and specify the exact amount of time between surveys for the models to estimates annual survival properly.

```{r, process-data-for-juvenile-CJS}
# make process data
tortoises$age_release <- as.factor(tortoises$age_release)
tortoises.process <- 
  process.data(tortoises,model="CJS",begin.time=0,
               time.intervals=c(0.17, 0.83, 0.83, 0.17, 
                                1.00, 0.67, 0.17, 0.33, 0.58), 
               groups = c("release_cohort", "age_release"), age.var = 2,
               initial.ages = c(4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5))
 
kable(tortoises.process$data, "html", 
      caption = "Tortoise capture data in Santa Fe") %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")
```
<br>

Now we'll make the design data for CJS. We have to fix two parameters--detection for the 2015 cohort of tortoises in April of 2017 and detection for the 2015 and 2017 cohorts in February of 2019. The new cohorts of tortoises were released then, but no surveys were conducted. So we need MARK to know that detection for the older cohorts in those time periods was zero.

```{r, make-design-data-for-juvenile-CJS}
# make CJS ddl
tortoises.ddl <- make.design.data(tortoises.process)

# merge effort data
tortoises.ddl$p <- merge_design.covariates(tortoises.ddl$p,effortcov, bytime = TRUE)

# fix detection for the 2015 cohort in occasion 4 (time 1.83) when no sampling occured
tortoises.ddl$p$fix <- NA
tortoises.ddl$p$fix[tortoises.ddl$p$time == "1.83" & 
                      tortoises.ddl$p$release_cohort == "2015"] <- 0

# fix detection for the 2015 & 2017 cohorts in occassion 7 (time 3.67) when no sampling occured
tortoises.ddl$p$fix[tortoises.ddl$p$time == "3.67" &
                      c(tortoises.ddl$p$release_cohort == "2015" |
                          tortoises.ddl$p$release_cohort == "2017")] <- 0

# design data PIMS
kable(tortoises.ddl[[1]][], "html", 
      caption = "PIMS for Phi (survival) parameter") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")

kable(tortoises.ddl[[2]][], "html", 
      caption = "PIMS for p (detection) parameter") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")
```
<br>

Now let's build models. We'll consider four possible survival models in which survival varies temporaly, by release size, or release cohort. We'll also consider whether detection varies by year or effort.

We'll run all combinations of these models as well as nulls---`Phi(.)` and `p(.)`---for a total of 16 CJS models.

```{r, make-models-for-CJS}
# apparent survival (Phi)
Phi.dot = list(formula=~1)
Phi.time = list(formula=~time)
Phi.length = list(formula=~length)
Phi.cohort = list(formula=~release_cohort)

# detection (p)
p.dot = list(formula=~1)
p.time = list(formula=~time)
p.effort = list(formula=~effort)
p.length = list(formula=~length)
```

Let's first examine goodness of fit for our data before ranking models.

```{r, GoF-for-adult-CJS}
RGOF <- release.gof(tortoises.process)
RGOF
chat <- RGOF$Chi.square[3]/RGOF$df[3]
chat
```

There is no lack of model fit. We'll still account for slight overdispersion with c-hat.

## Model outcomes

```{r, run-CJS-models, results = FALSE, warning = FALSE, comment = FALSE, message = FALSE}
# make and model list
tortoises.list <- create.model.list("CJS")

tortoises.results <- mark.wrapper(tortoises.list,
                                  data=tortoises.process,
                                  ddl=tortoises.ddl,
                                  output = FALSE)

tortoises.results <- adjust.chat(chat, tortoises.results)
```

```{r, print-QAICc-table-for-juvenile-CJS-models}
aic.table.tortoises <- model.table(tortoises.results, 
                                   use.lnl = TRUE, use.AIC = TRUE)
aic.table.tortoises$model <- gsub("~", "", aic.table.tortoises$model)
aic.table.tortoises$model <- gsub("1", ".", aic.table.tortoises$model)
aic.table.tortoises$model <- gsub(")", ") ", aic.table.tortoises$model)

kable(aic.table.tortoises[,3:8], "html", 
      caption = "AIC tortoise model rankings", digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")

write.csv(aic.table.tortoises[,3:8], "data/santafe_CJS_aictab_2020.csv")
```
<br>

It doesn't look like any variable strongly influences survival, as the top survival model is the null model Phi(.). There is some strong evidence for time-varying detection, but not much support for effort as a driver of detection variability.

Let's look at what the top model says about apparent survival.

```{r, apparent-survival-estimates-from-top-model}
# beta estimates
kable(tortoises.results$Phi.dot.p.time$results$beta, "html", 
      caption = "Beta estimates of Phi(.)p(time)") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
# real estimates
kable(tortoises.results$Phi.dot.p.time$results$real, "html", 
      caption = "Real estimates of Phi(.)p(time)") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

The model states there is an overall annual survival rate of 0.947.

Because there was model uncertainty, we should still model average to plot our survival estimates.

```{r, model-averaging-for-CJS-models}
set.seed(101)
# survival
tortoises.mod.avg.phi <- model.average(tortoises.results,"Phi", 
                                       vcv=TRUE, drop = FALSE)
tortoises.mod.avg.phi.unique <- unique(tortoises.mod.avg.phi$estimates[,2:5])

kable(tortoises.mod.avg.phi.unique, "html", 
      caption = "Model-averaged Phi estimates") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")

# detection
# remove the fully time dependent model: Phi(time)p(time)
# so we can estimate the variance for detection in the last occasion
tortoises.results.omit <- remove.mark(tortoises.results, 16)
tortoises.mod.avg.p <- model.average(tortoises.results.omit, "p", 
                                     vcv=TRUE, drop = FALSE)
tortoises.mod.avg.p.unique <- unique(tortoises.mod.avg.p$estimates[,2:5])

kable(tortoises.mod.avg.p.unique, "html", 
      caption = "Model-averaged p estimates") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

Let's use the overall survival estimates from the first model to get a quick estimate of abundance, using the following calculations. 

```{r, total-population-estimates}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi + 191*phi^(2/12)
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi + 155*phi^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020 <- N_2019 * phi^(8/12) + 34

# get the lower and upper confidence intervals
# lower 95% CL
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr + 191*lwr^(2/12)
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr + 155*lwr^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020_lwr <- N_2019_lwr * lwr^(8/12) + 34

# upper 95% CL
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr + 191*upr^(2/12)
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr + 155*upr^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020_upr <- N_2019_upr * upr^(8/12) + 34

santafe_pop_15_20 <- 
  data.frame(Year = c("2015", "2016", "2017", "2018", "2019", "2020"),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

kable(santafe_pop_15_20, 
      caption = "Population estimates (2015-2020) of the 
      tortoises released on Santa Fe.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

Let's also track the estimated population size of each cohort individually.

```{r, cohort-specific-population-size-estimates, echo = FALSE}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

# 2015 cohort
N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi 
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(9/12)
# get the lower and upper confidence intervals
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr
N_2020_lwr <- N_2019_lwr * phi^(9/12)
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr
N_2020_upr <- N_2019_upr * phi^(9/12)
# pull together into one table
cohort_2015_pop <- 
  data.frame(Year = c("Release (June 2015)", "2016", 
                      "2017", "2018", "2019", "2020 (March)"),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

# 2017 cohort
N_2017 <- 191
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(11/12)
# get the lower and upper confidence intervals
N_2017_lwr <- 191
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr 
N_2020_lwr <- N_2019_lwr * lwr^(11/12)
N_2017_upr <- 191
N_2018_upr <- N_2017_upr * upr 
N_2019_upr <- N_2018_upr * upr 
N_2020_upr <- N_2019_upr * upr^(11/12)
# pull together into one table
cohort_2017_pop <- 
  data.frame(Year = c("Release (Apr 2017)", "2018", "2019", "2020 (March)"),
             N = c(N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2017_lwr, N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2017_upr, N_2018_upr, N_2019_upr, N_2020_upr))

# 2019 cohort
N_2019_rel <- 155
N_2020 <- N_2019_rel * phi^(13/12)
# get the lower and upper confidence intervals
N_2019_rel_lwr <- 155
N_2020_lwr <- N_2019_rel_lwr * lwr^(13/12)
N_2019_rel_upr <- 155
N_2020_upr <- N_2019_rel_upr * upr^(13/12)
# pull together into one table
cohort_2019_pop <- data.frame(Year = c("Release (Feb 2019)", "2020 (March)"),
                              N = c(N_2019_rel, N_2020),
                              lcl = c(N_2019_rel_lwr, N_2020_lwr),
                              ucl = c(N_2019_rel_upr, N_2020_upr))
# pull all cohort tables into one composite table for Santa Fe
cohort_pops <- rbind(cohort_2015_pop, cohort_2017_pop, cohort_2019_pop)

row.specs = "background-color: #666; color: #fff;"
kable(cohort_pops, 
      caption = "Population estimates of tortoises on Santa Fe (2015-2020).") %>%
  pack_rows("First release cohort (2015)", 1, 6, label_row_css = row.specs) %>%
  pack_rows("Second release cohort (2017)", 7, 10, label_row_css = row.specs) %>%
  pack_rows("Third release cohort (2019)", 11, 12, label_row_css = row.specs) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

```{r, get-population-size-estimates-for-plotting, echo = FALSE}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017pre <- N_2016 * phi^(10/12)
N_2017release <- N_2017pre + 191 
N_2018 <- N_2017release * phi^(14/12)
N_2019pre <- N_2018 * phi^(8/12)
N_2019release <- N_2019pre + 155
N_2019 <- N_2019release * phi^(4/12)
N_2020 <- N_2019 * phi^(8/12)

# get the lower and upper confidence intervals
## lwr
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017pre_lwr <- N_2016_lwr * lwr^(10/12)
N_2017release_lwr <- N_2017pre_lwr + 191
N_2018_lwr <- N_2017release * lwr^(14/12)
N_2019pre_lwr <- N_2018_lwr * lwr^(8/12)
N_2019release_lwr <- N_2019pre_lwr + 155
N_2019_lwr <- N_2019release_lwr * phi^(4/12)
N_2020_lwr <- N_2019_lwr * phi^(8/12)

## upr
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017pre_upr <- N_2016_upr * upr^(10/12)
N_2017release_upr <- N_2017pre_upr + 191
N_2018_upr <- N_2017release * upr^(14/12)
N_2019pre_upr <- N_2018_upr * upr^(8/12)
N_2019release_upr <- N_2019pre_upr + 155
N_2019_upr <- N_2019release_upr * phi^(4/12)
N_2020_upr <- N_2019_upr * phi^(8/12)

N_dates <- 
  decimal_date(as.Date(c("2015-06-01", "2015-06-01", "2016-06-01", "2017-04-01", 
                         "2017-04-01", "2018-06-01", "2019-02-01", "2019-02-01", 
                         "2019-06-01", "2020-03-01"), 
                       format = "%Y-%m-%d"))

total_pop <- 
  data.frame(Year = N_dates,
             N_cum = c(0,205,205,205,396,396,396,551,551,551),
             N_hat = c(0,N_2015, N_2016, N_2017pre, N_2017release, 
                       N_2018, N_2019pre, N_2019release, N_2019, N_2020),
             lwr = c(0,N_2015_lwr,N_2016_lwr, N_2017pre_lwr, N_2017release_lwr, 
                     N_2018_lwr, N_2019pre_lwr, N_2019release_lwr, 
                     N_2019_lwr, N_2020_lwr),
             upr = c(0,N_2015_upr,N_2016_upr, N_2017pre_upr, N_2017release_upr, 
                     N_2018_upr, N_2019pre_upr, N_2019release_upr, 
                     N_2019_upr, N_2020_upr))

# 2015 cohort
N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi 
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(9/12)

# get the lower and upper confidence intervals
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr
N_2020_lwr <- N_2019_lwr * phi^(9/12)
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr
N_2020_upr <- N_2019_upr * phi^(9/12)

cohort_2015_pop <- 
  data.frame(Year = c(1,2,3,4,5,5.75),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lwr = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             upr = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

# 2017 cohort
N_2017 <- 191
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(11/12)
# get the lower and upper confidence intervals
N_2017_lwr <- 191
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr 
N_2020_lwr <- N_2019_lwr * lwr^(11/12)
N_2017_upr <- 191
N_2018_upr <- N_2017_upr * upr 
N_2019_upr <- N_2018_upr * upr 
N_2020_upr <- N_2019_upr * upr^(11/12)

cohort_2017_pop <- 
  data.frame(Year = c(2.83,3.83,4.83,5.75),
             N = c(N_2017, N_2018, N_2019, N_2020),
             lwr = c(N_2017_lwr, N_2018_lwr, N_2019_lwr, N_2020_lwr),
             upr = c(N_2017_upr, N_2018_upr, N_2019_upr, N_2020_upr))


# 2019 cohort
N_2019_rel <- 155
N_2020 <- N_2019_rel * phi^(13/12)
# get the lower and upper confidence intervals
N_2019_rel_lwr <- 155
N_2020_lwr <- N_2019_rel_lwr * lwr^(13/12)
N_2019_rel_upr <- 155
N_2020_upr <- N_2019_rel_upr * upr^(13/12)

cohort_2019_pop <- data.frame(Year = c(4.67,5.75),
                              N = c(N_2019_rel, N_2020),
                              lwr = c(N_2019_rel_lwr, N_2020_lwr),
                              upr = c(N_2019_rel_upr, N_2020_upr))


cohort_pops <- rbind(cohort_2015_pop, cohort_2017_pop, cohort_2019_pop)
cohort_pops$cohort <- c(rep("2015",6), rep("2017",4), rep("2019",2))
```

Let's put these estimates of survival, detection, and population size together in a single figure.

```{r}
# create the df for plotting population parameter estimates
tortoises.mod.avg.phi.unique$cohort <- 
  c(rep("2015",9), rep("2017",9), rep("2019", 9))

tortoises.mod.avg.phi.unique$year <- 
  c(rep(c(2015,2015,2016,2017,2017,2018,2019,2019,2019),3))

tortoises.phi.df <- tortoises.mod.avg.phi.unique %>%
  filter(lcl > 0.01) %>% # remove the final 2019 survival estimate with inflated variances
  group_by(year) %>%
  summarise(phi = mean(estimate),
            se = mean(se),
            lcl = mean(lcl),
            ucl = mean(ucl)) %>%
  ungroup() %>%
  mutate(time = c(2015.5, 2016.5, 2017.5, 2018.5, 2019.5))

det.df <- tortoises.mod.avg.p.unique[c(1:2,4:8),] %>%
  mutate(year = decimal_date(as.Date(c("2015-08-01", "2016-06-01", 
                                       "2017-06-01", "2018-06-01",
                                       "2019-04-01", "2019-08-01", 
                                       "2020-03-01"), 
                                     format = "%Y-%m-%d")))

scaleFUN <- function(x) sprintf("%.2f", x)

espanola.phi <- data.frame(stage = c("juvenile", "subadult/adult"),
                           phi = c(0.931, 0.979),
                           lcl = c(0.902, 0.927),
                           ucl = c(0.951, 0.992))

santafe.phi.plot <- 
  ggplot(tortoises.phi.df,  aes(x = time, y = phi)) +
  geom_hline(data = espanola.phi, inherit.aes = FALSE, 
             aes(yintercept = phi), 
             lty = "dashed", lwd = 1.1, col = "grey") +
  geom_pointrange(aes(ymin = lcl, ymax = ucl), 
                  shape = 21, fill = "black", fatten = 3, 
                  color = "black", size = 1.1, stroke = 1.3) +
  labs(y = expression(paste("Apparent survival ( ", phi, " )")), x = "Year") + 
  scale_y_continuous(limits = c(floor_any(min(tortoises.phi.df$lcl),0.05), 1), 
                     labels = scaleFUN) + 
  xlim(2015,2020.5) + 
  theme(legend.position = "top") + 
  annotate("text", x = 2020.15, y = 0.94, 
           label = "juvenile", size = 4, col = "black") +
  annotate("text", x = 2020.15, y = 0.99, 
           label = "(sub)adult", size = 4, col = "black") + 
  theme_classic() + mythemes

santafe.phi.plot
  
santafe.p.plot <- 
  ggplot(det.df, aes(x = year, y = estimate)) +  geom_line() + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl), 
                  shape = 21, fill = "black", fatten = 8) +
  geom_hline(aes(yintercept = mean(det.df$estimate)), lty = "dashed") +
  ylab("Detection probability") + xlab("Year") +
  scale_y_continuous(limits = c(0.3,1), labels = scaleFUN) +
  xlim(2015,2020.5) + theme_classic() + mythemes

santafe.p.plot

santafe.n.plot <- 
  ggplot(data = total_pop) +
  geom_line(aes(x = Year, y = N_cum), color = "black") +
  geom_line(aes(x = Year, y = N_hat), color = "black") +
  geom_ribbon(aes(x = Year, ymin = lwr, ymax = upr), alpha = 0.5) +
  annotate("text", 
           x = decimal_date(as.Date("2015-06-01", format = "%Y-%m-%d")), 
           y = 205+34, label = "Release 1", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2017-04-01", format = "%Y-%m-%d")),  
           y = 396+34, label = "Release 2", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2019-02-01", format = "%Y-%m-%d")),
           y = 551+34, label = "Release 3", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-30", format = "%Y-%m-%d")),
           y = 551, label = 551, size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-30", format = "%Y-%m-%d")),
           y = last(total_pop$N_hat), 
           label = round(last(total_pop$N_hat),0), size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-30", format = "%Y-%m-%d")),
           y = last(total_pop$N_hat) * 0.88, 
           label = paste("(",round(last(total_pop$N_hat)/551*100,1),"%",")", 
                         sep = ""), size = 4) +
  ylab("Population size") + xlab("Year") +
  xlim(2015,2020.5) + ylim(0,600) + theme_classic() + mythemes

santafe.n.plot
```

```{r, fig.height = 6, fig.width = 9}
# combine survival, abundance, and morphology figures into a 2x2 composite
ggarrange(santafe.phi.plot + ggtitle("a"),
          santafe.n.plot + ggtitle("b"), 
          hood.bc.plot + ggtitle("c"),
          hood.growth.plot + ggtitle("d"),
          legend = "bottom", common.legend = TRUE)

ggsave("images/hoodensis_demographic_outcomes.jpg", device = "jpeg",
       width = 9, height = 7, units = "in", dpi = 600)
```

# Population projections
***

We'll make deterministic and stochastic population projections in the R package `popbio.` These will be **female-only** models, making the assumption that approximately half of all tortoise eggs become female.

Let's first create our four-stage Lefkovitch matrices.

```{r}
library(popbio)
# hatching viability parameter estimates and quantiles from kevin'a ABC
egghatchvia <- c(0.3447368, 0.2305263, 0.2636842, 0.3005263, 0.3078947, 
                 0.3447368, 0.3815789, 0.4184211, 0.418421, 0.4184211)

names(egghatchvia) <- c("mean", "p025", "p05", "p10", "p25", 
                        "p50", "p75", "p90", "p95", "p975")

# starting female population in 2020
n_2020 <- c(0, 0, round(last(total_pop$N_hat)/2), 20)

# vital rates
propfem <- 0.5 # proportion of population that is female
repro <- 17 # reproductive age
# mean annual number of female eggs produced
F1 <- 3
F1_lwr <- 2 
F1_upr <- 4 
# survivorship from egg to juvenile (age 1) (from Kevin's Espnola ABC)
G1 <- egghatchvia["mean"] 
G1_lwr <- egghatchvia["p025"]
G1_upr <- egghatchvia["p975"]
# annual survival, phi (1-4 yrs)
p1 <- 0.75 
p1_lwr <- 0.6
p1_upr <- 0.9
# young juvenile stage survival parameter for matrix
P1 <- (1-p1^(3-1))*p1/(1-p1^3)
P1_lwr <- (1-p1_lwr^(3-1))*p1_lwr/(1-p1_lwr^3)
P1_upr <- (1-p1_upr^(3-1))*p1_upr/(1-p1_upr^3)
# juvenile/subadult survival (4-17 yrs) (Santa Fe rates)
p2 <- tortoises.results$Phi.dot.p.time$results$real$estimate[1]
p2_lwr <- tortoises.results$Phi.dot.p.time$results$real$lcl[1]
p2_upr <- tortoises.results$Phi.dot.p.time$results$real$ucl[1]
# juvenile/subadult stage survival parameter for matrix
P2 <- (1-p2^(13-1))*p2/(1-p2^13)
P2_lwr <- (1-p2_lwr^(13-1))*p2_lwr/(1-p2_lwr^13)
P2_upr <- (1-p2_upr^(13-1))*p2_upr/(1-p2_upr^13)
# survivorship from 1 to 4 (using the range from Gibbs et al. 2014)
G2 <- round(p1^3*(1-p1)/(1-p1^3),3) 
G2_lwr <- round(p1_lwr^3*(1-p1_lwr)/(1-p1_lwr^3),3)
G2_upr <- round(p1_upr^3*(1-p1_upr)/(1-p1_upr^3),3)
# survivorship from 4 to 17 (using the subadult/adult survival rates from Espanola)
G3 <- round(p2^13*(1-p2)/(1-p2^13),3) 
G3_lwr <- round(p2_lwr^13*(1-p2_lwr)/(1-p2_lwr^13),3)
G3_upr <- round(p2_upr^13*(1-p2_upr)/(1-p2_upr^13),3)
# annual survival for adult stage, phi (8 + years old)
P3 <- 0.979 
P3_lwr <- 0.927
P3_upr <- 0.992

# make matrices
stages <- c("egg/hatchling", "young juvenile", "juvenile/subadult", "adult")
tortoise.matrix <- matrix(c(0, 0, 0, F1,
                            G1, P1, 0, 0,
                            0, G2, P2, 0,
                            0, 0, G3, P3),
                          nrow = 4, ncol = 4, byrow = T)
tortoise.matrix.lwr <- matrix(c(0, 0, 0, F1_lwr,
                                G1_lwr, P1_lwr, 0, 0,
                                0, G2_lwr, P2_lwr, 0,
                                0, 0, G3_lwr, P3_lwr),
                              nrow = 4, ncol = 4, byrow = T)
tortoise.matrix.upr <- matrix(c(0, 0, 0, F1_upr,
                                G1_upr, P1_upr, 0, 0,
                                0, G2_upr, P2_upr, 0,
                                0, 0, G3_upr, P3_upr),
                              nrow = 4, ncol = 4, byrow = T)
```

Now let's run the deterministic projection to extract stable stage proportions and population growth rates.

We will project the Santa Fe population from 2020 to 2100.

```{r}
set.seed(123)

it <- 81 # time steps for model

# deterministic model
tortoise.proj <- pop.projection(tortoise.matrix, n_2020, it)
tortoise.proj.lwr <- pop.projection(tortoise.matrix.lwr, n_2020, it)
tortoise.proj.upr <- pop.projection(tortoise.matrix.upr, n_2020, it)

proj.df <- data.frame(Year = c(2020:2100), 
                      N_projected = tortoise.proj$stage.vectors[4,],
                      N_proj_lwr = tortoise.proj.lwr$stage.vectors[4,],
                      N_proj_upr = tortoise.proj.upr$stage.vectors[4,])

# time to saturation (K = 1500 female tortoises)
min(proj.df$Year[proj.df$N_projected >= 1500]) # max year at saturation
min(proj.df$Year[proj.df$N_proj_upr >= 1500]) # earliest year at saturation
    
# plot projection (without density dependence)
ggplot(proj.df, aes(Year, N_projected)) + geom_line(col = "blue", lwd = 1.1) + 
  geom_line(aes(x = Year, y = N_proj_lwr), col = "grey10") +
  geom_line(aes(x = Year, y = N_proj_upr), col = "grey10") +
  theme_classic() + xlim(2020, 2050) + ylim(0,1500)

# minimum adult population size
min(proj.df[,2:4]) 
# population growth rate
tortoise.proj$lambda 
tortoise.proj.lwr$lambda
tortoise.proj.upr$lambda
# stable stages 
tortoise.proj$stable.stage 
tortoise.proj.lwr$stable.stage 
tortoise.proj.upr$stable.stage 
# generation time
generation.time(tortoise.matrix)
generation.time(tortoise.matrix.lwr)
generation.time(tortoise.matrix.upr)
```

Without any other constraints on the tortoise population, these vital rates should ensure long-term persistence without future releases. Growth rates are very high, and the stable stage proportion for adult is between 0.1--0.2.

Now let's create our stochastic model.

```{r}
# stochastic projection (with density dependence)
tortoise.matrices <- list(tortoise.matrix, tortoise.matrix.lwr, 
                          tortoise.matrix.upr)
# nmax = K = K for Santa Fe (3000) divided by 2 times the stable stage prop. for adults
tortoise.proj.stoch <- 
  stoch.projection(matrices = tortoise.matrices,
                   n0 = n_2020, 
                   tmax = it, 
                   nreps = 10000,
                   prob = c(0.68, 0.16, 0.16),
                   nmax = 1500/tortoise.proj$stable.stage[4])

final.fem.pop <- tortoise.proj.stoch[,4]
hist(final.fem.pop, main = "Santa Fe adult female pop. in 2100", 
     xlab = "N adults")
abline(v = mean(final.fem.pop), col = "red", lwd = 2)
```

Almost all of our stochastic projections end with a female adult population > 1000 individuals. The mean projection for 2100 is just below 1500.

Let's run the stochastic projection again, but this time we'll put the projections in a for loop that will let us get population size estimates at each time step so we can plot out the projected female population from 2020 to 2100.

```{r}
extin=c()
popQuant = matrix(NA, 3, 82)
popQuant[,1] = rep(sum(n_2020), 3)
popMean	= vector('numeric', 82)
popMean[1] = sum(n_2020)
popSD	= vector('numeric', 82)
popSD[1] = NA

for(i in 1:81){
  matriz=c()
  interactionX=10000
  quasi=75
  popExtinctProject <- 
    stoch.projection(matrices=tortoise.matrices, n0=n_2020, tmax=i, 
                     nmax = 1500/tortoise.proj$stable.stage[4], 
                     nreps = interactionX, 
                     prob = c(0.68, 0.16, 0.16), verbose=FALSE)
  for(ii in 1:interactionX){
    a <- popExtinctProject[ii,4]
    matriz <- rbind(matriz,c(a))
  }
  vv <- matriz[matriz<quasi]
  s <- length(vv)
  extin <- c(extin,s)
  
  popQuant[,i+1] <- quantile(popExtinctProject[,4], probs=c(0.025, 0.5, 0.975))
  popMean[i+1] <- mean(popExtinctProject[,4])
  popSD[i+1] <- sd(popExtinctProject[,4])
}

stoch.proj.df <- data.frame(Year = c(2020:2100), 
                            N_projected = c(n_2020[4],popMean[2:81]),
                            N_proj_med = c(n_2020[4],popQuant[2,2:81]),
                            N_proj_lwr = c(n_2020[4],popQuant[1,2:81]),
                            N_proj_upr = c(n_2020[4],popQuant[3,2:81]))

# table of stochastic projections (annual means across iterations)
kable(stoch.proj.df) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")

# plot projection (with density dependence)
stoch.pop.plot <- ggplot(stoch.proj.df, aes(Year, N_projected)) + 
  geom_ribbon(aes(ymin = N_proj_lwr, ymax = N_proj_upr), 
              fill = "grey", alpha = 0.7) +
  geom_line(lwd = 1.1) + ylab("Female population (adults)") +
  theme_classic() + mythemes

stoch.pop.plot

# save plot
ggsave("images/pop_projection_tortoises.jpg", device = "jpeg",
       width = 6, height = 4, units = "in", dpi = 600)

plot(extin/interactionX, type='l', lwd=2, xlab="Years into the future", 
     main="Extinction probability for Santa Fe population")

# pop growth rate
popSGR <- stoch.growth.rate(tortoise.matrices, 
                            verbose=F,
                            prob = c(0.68, 0.16, 0.16))

lambdaCI <- list()
lambdaCI$approx	<- exp(popSGR$approx)
lambdaCI$sim <- exp(popSGR$sim)
lambdaCI$sim.CI	<- exp(popSGR$sim.CI)
cat('lambda\n')
print(lambdaCI)
```

These projections obviously do not take into account environmental stochasticity that affects tortoise vital rates (e.g., drought, ENSO cycles, temperature change, shifting sex ratios). Those information would help improve the accuracy of these projections, setting them in a more realistic future context with ongoing global change.

Let's attach this projection figure to our other survival and abundance figures.

```{r, fig.height = 6, fig.width = 10}
library(cowplot)
ggdraw() +
  draw_plot(santafe.phi.plot, x = 0, y = 0.5, width = 0.5, height = 0.5) +
  draw_plot(santafe.p.plot, x = 0.5, y = 0.5, width = 0.5, height = 0.5) +
  draw_plot(santafe.n.plot, x = 0, y = 0, width = 0.5, height = 0.5) +
  draw_plot(stoch.pop.plot, x = 0.5, y = 0, width = 0.5, height = 0.5) +
  draw_plot_label(label = c("a", "b", "c", "d"), size = 15,
                  x = c(0.08, 0.58, 0.08, 0.58), y = c(1, 1, 0.5, 0.5))

# save plot
ggsave("images/phi_p_N_estimates.jpg", device = "jpeg",
       width = 6, height = 4, units = "in", dpi = 600)
```

# Dispersal
***
## Data preparation

To assess dispersal I used the coordinates from individual tortoise capture records on Santa Fe from 2015 to 2020.

```{r, read-dispersal-data}
# rename santa fe data frame, remove rows without location data
movements <- santafe.data[is.na(santafe.data$Latitude) == FALSE,]
movements$Date <- paste(movements$Month, movements$Day, movements$Year, 
                        sep = "/")
movements$Date <- as.Date(movements$Date,format='%m/%d/%Y')
```

We should add one more column to the data frame---**Days_ellapsed**---to describe the time since release for each observation. But because there are three release dates, we really need three distinct groups of values for that column specific to their release cohorts.

```{r, process-dispersal-dates-and-export-to-GIS}
# create shapefile
movements2015 <- subset(movements, Cohort == "2015")
movements2017 <- subset(movements, Cohort == "2017")
movements2019 <- subset(movements, Cohort == "2019")
movementsNA <- subset(movements, is.na(Cohort))
movements2015$Days_ellapsed <- julian(movements2015$Date, 
                                      origin = as.Date("2015-06-27"))
movements2017$Days_ellapsed <- julian(movements2017$Date, 
                                      origin = as.Date("2017-04-17"))
movements2019$Days_ellapsed <- julian(movements2019$Date, 
                                      origin = as.Date("2019-02-27"))
movementsNA$Days_ellapsed <- NA
# combine them into one dataset again
movements <- rbind(movements2015, movements2017, movements2019, movementsNA)
```

Let's now convert our coordinates to UTMs, calculate the distance of each point from the original release point, and make some simple plots of the study area and tortoise locations. 

I'll start by only showing the 2015 release cohort over time. Then I'll produce the same plots including the 2017 cohort. I also need to update the UTM coordinates for the Santa Fe island shapefile so they are on the same scale as the tortoise points (relative to a central release point of 0,0).

```{r}
library(sp)
library(rgdal)
library(raster)
# create shapefile
coordinates(object = movements) <- ~ Longitude + Latitude
proj4string(movements) <- CRS("+proj=longlat +datum=WGS84")
movements.shp <- spTransform(movements, CRSobj = CRS("+init=epsg:32715"))
movements.shp$X <- movements.shp@coords[,"Longitude"]
movements.shp$Y <- movements.shp@coords[,"Latitude"]
# Here I create new X and Y UTM fields that make coordinates relative to 
# the release point (0,0). 
# This will make it easier to quickly assess dispersal distances in the maps, 
# by centering the release point at 0,0.
movements.shp$X_corrected <- movements.shp$X - 827253
movements.shp$Y_corrected <- movements.shp$Y - 9909160
movements.data <- as.data.frame(movements.shp)
# reformat the occasion column as factor
movements.data <- movements.data %>%
  mutate(occ = as.factor(Occasion),
         occ = recode(occ, "1" = "June 2015", "2" = "August 2015", 
                      "3" = "June 2016", "4" = "April 2017", "5" = "June 2017", 
                      "6" = "June 2018", "7" = "February 2019", 
                      "8" = "April 2019", "9" = "August 2019", 
                      "10" = "March 2020")) %>% as.data.frame()
```

## Spatial patterns - recapture data

```{r, load-santa-fe-outline-and-put-on-same-spatial-scale-as-tortoise-data}
santafe.shp <- readOGR("data/Santa_Fe.shp", verbose=FALSE)
santafe.shp <- spTransform(santafe.shp, CRS("+init=epsg:32715"))
santafe <- fortify(santafe.shp)
santafe$X <- santafe$long - 827253
santafe$Y <- santafe$lat - 9909160
```

Here is the code to make dispersal maps for specific occasions and cohorts. I'll make plots for the first release cohorts and the total population.

First let's look at the general distribution, showing tortoise locations at each occasion with overlayed 95% confidence ellipses.

```{r, code-for-dispersal-scatterplot-and-ellipse-maps-of-2015 cohort, fig.height=10, fig.width=12}
library(ggsn)
disp.scatter <- function(data, occasion, cohort){
  ggplot(data = data[data$occ == occasion & data$Cohort == cohort,], 
         aes(x = X_corrected, y = Y_corrected)) +
    geom_polygon(inherit.aes = FALSE, data = santafe, 
                 aes(x = santafe$X, y = santafe$Y), fill = "grey") +
    geom_point(shape = 16, alpha = 0.5) +
    geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
               shape = 4, size = 1, stroke = 1.5, color = "red") +
    stat_ellipse(aes(x = X_corrected, y = Y_corrected), color = "blue", 
                 level = 0.95, lwd = 0.9) +
    theme_classic() + mythemes + coord_equal() + theme(legend.position="none") + 
    labs(x = "Distance from release (m)", y = "Distance from release (m)") +
    annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
    annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)
}

stat.ellipse.area <- function(plot){
 # Get ellipse coordinates from plot 
 # (from StackOverflow: https://tinyurl.com/yaulv58n)
  pb = ggplot_build(plot)
  el = pb$data[[4]][c("x","y")]
  # Center of ellipse
  ctr = MASS::cov.trob(el)$center 
  # Calculate distance to center from each point on the ellipse
  dist2center <- sqrt(rowSums((t(t(el)-ctr))^2))
  # Calculate area of ellipse from semi-major and semi-minor axes. 
  # These are, respectively, the largest and smallest values of dist2center. 
  return(pi*min(dist2center)*max(dist2center)/10000) # area in hectares of ellipse
}

p1 <- disp.scatter(movements.data, "June 2016", "2015")
p2 <- disp.scatter(movements.data, "June 2017", "2015")
p3 <- disp.scatter(movements.data, "June 2018", "2015")
p4 <- disp.scatter(movements.data, "August 2019", "2015")

# first cohort spread
first.cohort.spread <- data.frame(
  year = c(2016:2019),
  area = c(stat.ellipse.area(p1),stat.ellipse.area(p2),
           stat.ellipse.area(p3),stat.ellipse.area(p4)),
  prop.island = c(stat.ellipse.area(p1)/2473,stat.ellipse.area(p2)/2473,
                  stat.ellipse.area(p3)/2473,stat.ellipse.area(p4)/2473)
)

p1 <- p1 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[1], 1), " ha (",
                         round(first.cohort.spread$prop.island[1]*100, 1), "%)", 
                         sep = ""), size = 5)
p2 <- p2 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[2], 1), " ha (",
                         round(first.cohort.spread$prop.island[2]*100, 1), "%)", 
                         sep = ""), size = 5)
p3 <- p3 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[3], 1), " ha (",
                         round(first.cohort.spread$prop.island[3]*100, 1), "%)", 
                         sep = ""), size = 5)
p4 <- p4 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[4], 1), " ha (",
                         round(first.cohort.spread$prop.island[4]*100, 1), "%)", 
                         sep = ""), size = 5)

plot_grid(p1, p2, p3, p4,
          ncol  = 2, 
          labels = c("1 year", "2 years", "3 years", "4 years"), 
          label_size = 20)

ggsave("images/dispersal_C1_map.jpg", device = "jpeg",
       width = 10, height = 5, units = "in", dpi = 600)
```

The first cohort is slowly spreading over the center of the island and seems to be doubling in area almost every year since release.

Let's see what these movements look like for the 2015 cohort when you connect the observations of individual tortoises over time as traces.

```{r, plot-traces-of-2015-cohort, fig.cap = "Individual tortoise dispersal routes from first release cohort on Santa Fe island (2015-2020)"}
traces1 <- ggplot() +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(data = movements.data[movements.data$Cohort == "2015",], 
            aes(x = X_corrected, 
                y = Y_corrected, group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "2015 cohort (4.5 years)", subtitle = "", caption = "") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

traces1
```

Let's now look at all the traces of all cohorts together.

```{r, plot-traces-of-2017-cohort, fig.cap = "Individual tortoise dispersal routes on Santa Fe island (2015-2020)"}
all.traces <-
  ggplot(data = movements.data,
                  aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(aes(group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() +
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)+
  theme(plot.margin = unit(c(0,0,0,0), "mm"))

all.traces
```


Interesting how tortoise movement has not been one directional. Many tortoises make large outward movements after release, only to return close to the center of the island on another occasion. These are only snapshops, so we really can't say much about tortoise movement or dispersal from these traces, other than that tortoises seem to be exploratory in these initial post-release movements.

Finally, let's look at dispersal ellipses for the whole tortoise population from the last survey occasion in 2020. 

```{r, fig.cap = "Distribution of tortoise cohorts on Santa Fe, as of March 2020."}
p.final.cohorts <-   
  ggplot(data = movements.data[movements.data$occ == "March 2020" & 
                                   !is.na(movements.data$Cohort),], 
         aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(inherit.aes = FALSE, data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_point(shape = 16, alpha = 0.5) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  stat_ellipse(aes(x = X_corrected, y = Y_corrected, color = Cohort),
               level = 0.95, lwd = 0.9) + 
  scale_y_continuous(limits = c(-2100, 3100), breaks = seq(-2000, 2000, 1000)) +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + mythemes + coord_equal() + theme(legend.position="top") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  theme(plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))

# Get ellipse coordinates from plot 
# (from StackOverflow: https://tinyurl.com/yaulv58n)
pb <- ggplot_build(p.final.cohorts)
cohort.areas <- NULL
for(group in unique(pb$data[[4]]$group)){
  el = pb$data[[4]]
  el.group = el[el$group == group,]
  el.group.xy = el.group[c("x","y")]
  # Center of ellipse
  ctr = MASS::cov.trob(el.group.xy)$center 
  # Calculate distance to center from each point on the ellipse
  dist2center <- sqrt(rowSums((t(t(el.group.xy)-ctr))^2))
  # Calculate area of ellipse from semi-major and semi-minor axes. 
  # These are, respectively, the largest and smallest values of dist2center. 
  area_ha <- pi*min(dist2center)*max(dist2center)/10000
  dat <- data.frame(cohort = group,
                    color = el.group$colour,
                    area_ha = area_ha,
                    area_perc = area_ha/2473 * 100,
                    stringsAsFactors = FALSE)
  cohort.areas <- bind_rows(cohort.areas, dat)
}

p.final.cohorts1 <- 
  p.final.cohorts + 
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15) +
  annotate("text", x = -2500, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "1"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "1"], 
                               2), "%)", sep = ""), size = 4, 
           color = cohort.areas$color[cohort.areas$cohort == "1"]) +
  annotate("text", x = 0, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "2"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "2"], 
                               2), "%)", sep = ""), size = 4,
            color = cohort.areas$color[cohort.areas$cohort == "2"]) +
  annotate("text", x = 2500, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "3"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "3"], 
                               2), "%)", sep = ""), size = 4,
            color = cohort.areas$color[cohort.areas$cohort == "3"]) +
  theme(plot.margin = unit(c(0,0,0,0), "mm"))

p.final.cohorts1
ggsave("images/distribution_cohorts_2020.jpg", device = "jpeg",
       width = 6, height = 5, units = "in", dpi = 600)
```

These final distributions seem to reinforce the "doubling" seen in the first cohort's dispersal distances over time. The first cohort is distributed over an area roughly twice the size of the second cohort, which is also roughly twice as widespread as the third cohort.

What about the ellipse for the whole population in 2020?

```{r}
p.final <- 
  ggplot(data = movements.data[movements.data$occ == "March 2020",], 
         aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(inherit.aes = FALSE, data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_point(shape = 16, alpha = 0.5) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 1, stroke = 1.5, color = "red") +
  stat_ellipse(aes(x = X_corrected, y = Y_corrected),
               level = 0.95, lwd = 0.9, color = "blue") +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + mythemes + coord_equal() + theme(legend.position="top") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

p.final + annotate("text", x = 0, y = 1800, 
                   label = paste(round(stat.ellipse.area(p.final), 1), 
                                 " ha (",
                                 round(stat.ellipse.area(p.final)/2473*100, 1), 
                                 "%)", 
                                 sep = ""), size = 5)
ggsave("images/distribution_total_2020.jpg", device = "jpeg",
       width = 10, height = 5, units = "in", dpi = 600)
```

Let's now examine how tortoise distributions vary over time with kernel density maps.

```{r}
library(spatstat)
# create a spatstat spatial planar point pattern (ppp) object
tortoises.ppp <- as(movements.shp, "ppp")
santafe.owin <- as.owin(santafe.shp)

# merge the points to the island boundary
tortoises.santafe <- tortoises.ppp[santafe.owin]
tortoises.santafe$marks <- tortoises.santafe$marks %>%
  mutate(occ = as.factor(Occasion),
         occ = recode(occ, "1" = "June 2015", "2" = "August 2015", 
                      "3" = "June 2016", "4" = "April 2017", "5" = "June 2017", 
                      "6" = "June 2018", "7" = "February 2019", 
                      "8" = "April 2019", "9" = "August 2019", 
                      "10" = "March 2020")) %>% as.data.frame()
```

Here I calculate kernel density of tortoises on Santa Fe, at six time events (August 2015, June 2016, June 2017, June 2018, August 2019, and March 2020). These maps are kind of like heat maps: brighter colors/higher values indicate greater tortoise densities. 

```{r, fig.height=5, fig.width=10}
# kernel density function
den.fun <- function(ppp, res){
  den.list <- list()
  ras.list <- list()
  for(occasion in c("August 2015", "June 2016", "June 2017", 
                    "June 2018", "August 2019", "March 2020")){
    # get kernel density surface
    t <- subset.ppp(ppp, occ == occasion)
    t <- rescale(t, 100)
    den <- density.ppp(t, diggle = TRUE, sigma = bw.ppl, eps = 1)
    den$xcol <- den$xcol*100
    den$yrow <- den$yrow*100
    den$xrange <- den$xrange*100
    den$yrange <- den$yrange*100
    # convert spatstat images to raster
    ras <- raster(den)
    crs(ras) <- CRS("+init=epsg:32715")
    # add objects to lists
    den.list[[occasion]] <- den
    ras.list[[occasion]] <- ras
  }
  return(list(density = den.list, raster = ras.list))
}

den.list <- den.fun(ppp = tortoises.santafe)
tortoise.brick.raw <- brick(den.list$raster)
values(tortoise.brick.raw)[values(tortoise.brick.raw) < 0] <- 0
tortoise.brick.adj <- tortoise.brick.raw
tortoise.brick.adj.lcl <- tortoise.brick.raw
tortoise.brick.adj.ucl <- tortoise.brick.raw

# correct density for detection probability
det.seq <- list()
det.seq[["est"]] <- det.df$estimate[c(1:4,6:7)]
det.seq[["lcl"]] <- det.df$ucl[c(1:4,6:7)]
det.seq[["ucl"]] <- det.df$lcl[c(1:4,6:7)]
for(i in c(1:6)){
  values(tortoise.brick.adj[[i]]) <- 
    values(tortoise.brick.adj[[i]])/det.seq[["est"]][i]
  values(tortoise.brick.adj.lcl[[i]]) <-
    values(tortoise.brick.adj.lcl[[i]])/det.seq[["lcl"]][i]
  values(tortoise.brick.adj.ucl[[i]]) <-
    values(tortoise.brick.adj.ucl[[i]])/det.seq[["ucl"]][i]
}

# write individual rasters
for(i in names(tortoise.brick.raw)){
  writeRaster(tortoise.brick.raw[[i]], filename = 
                file.path(paste("data/tdensity/tortdenraw", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
  writeRaster(tortoise.brick.adj[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
  writeRaster(tortoise.brick.adj.lcl[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj_lcl", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
   writeRaster(tortoise.brick.adj.ucl[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj_ucl", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
}
# write rasterbrick as multi-band raster
writeRaster(tortoise.brick.raw, 
            filename=file.path("data/tort_kden_raw_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj, 
            filename=file.path("data/tort_kden_adj_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj.lcl, 
            filename=file.path("data/tort_kden_adj_lcl_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj.ucl, 
            filename=file.path("data/tort_kden_adj_ucl_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)

library(rasterVis)
names(tortoise.brick.adj) <- c("Y2015", "Y2016", "Y2017", 
                               "Y2018", "Y2019", "Y2020")
names(tortoise.brick.adj.lcl) <- c("Y2015", "Y2016", "Y2017", 
                                   "Y2018", "Y2019", "Y2020")
names(tortoise.brick.adj.ucl) <- c("Y2015", "Y2016", "Y2017", 
                                   "Y2018", "Y2019", "Y2020")

release.pt <- data.frame(x = 827253, y = 9909160)
coordinates(release.pt) <- ~ x + y

total.density.plots <-
  levelplot(tortoise.brick.adj, par.settings = viridisTheme, 
            scales = list(cex = 1.5),
            colorkey = list(labels = list(cex = 1.5)),
            par.strip.text = list(cex = 1.5), layout = c(3,2)) +
  layer(sp.points(release.pt, pch = 4, cex=1, col="red", alpha = 0.7))

total.density.plots
ggsave("images/kernel_density_2015_2020.jpg", device = "jpeg",
       width = 10, height = 5, units = "in", dpi = 600)
```

In this next composite figure I'm only showing densities for the first release cohort. 

```{r, fig.height=5, fig.width=10}
den.list <- den.fun(ppp = subset(tortoises.santafe, Cohort == "2015"))
tortoise.brick.2015 <- brick(den.list$raster)
# replace negative values with 0
values(tortoise.brick.2015)[values(tortoise.brick.2015) < 0] <- 0
# adjust estimates for imperfect detection
for(i in c(1:6)){
  values(tortoise.brick.2015[[i]]) <- 
    values(tortoise.brick.2015[[i]]) / det.seq[["est"]][i]
}
names(tortoise.brick.2015) <- c("Y2015", "Y2016", "Y2017", 
                                "Y2018", "Y2019", "Y2020")
levelplot(tortoise.brick.2015, par.settings = viridisTheme, 
          scales = list(cex = 1.5),
          colorkey = list(labels = list(cex = 1.5)),
          par.strip.text = list(cex = 1.5), layout = c(3,2),
          main = list("Dispersal of first release cohort", cex = 1.5)) +
  layer(sp.points(release.pt, pch = 4, cex=1, col="red", alpha = 0.7))

ggsave("images/kernel_density_2015_2020_C1.jpg", device = "jpeg",
       width = 10, height = 5, units = "in", dpi = 600)
```

At four and a half years since release, the first release cohort is widely dispersed across several spatial clusters.

Let's now quantify dispersal over time. In this next chunk of code and following figure I look at the kernel density estimates from dispersal distances (Euclidean distance from release point), highlighting the distances of the 50% isopleth with black lines, 95% isopleth with blue lines, and max distances with red lines for each occasion.

```{r}
movements.data$dist <- sqrt((movements.data$X - 827253)^2 +
                              (movements.data$Y - 9909160)^2)
movements.data$dist[movements.data$Days_ellapsed == 0] <- 0

# density plot function
den.plot <- function(data, cohort, occasion){
  dens <- density(data[data$Cohort %in% cohort & data$occ == occasion,]$dist)
  q95 <- quantile(dens, 0.95)
  q50 <- quantile(dens, 0.50)
  ggplot(data[data$Cohort %in% cohort & data$occ == occasion,], aes(dist)) + 
    geom_density(fill = "grey") + 
    geom_segment(aes(x = q50, xend = q50, yend = 0, y = 0.0075),
                 lwd = 0.8, color = "black", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    geom_segment(aes(x = q95, xend = q95, yend = 0, y = 0.0075), 
                 lwd = 0.8, color = "blue", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    geom_segment(aes(x = max(dist), xend = max(dist), yend = 0, y = 0.0075), 
                 lwd = 0.8, color = "red", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    theme_classic() + mythemes + theme(plot.title = element_text(size = 18)) +
    scale_x_continuous(expand = c(0,0), limits = c(0,2100), 
                       breaks = seq(0,2000,250)) +
    scale_y_continuous(expand = c(0,0), limits = c(0,0.0075)) + 
    geom_rug(sides = "b", alpha= 0.5)
}

# 2015 cohort
## 2015 dispersal plot for 2015 cohort / total
p15_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "August 2015") +
  labs(title = "August 2015 (2 months)", x = NULL, y = NULL)
## 2016 dispersal plot for 2015 cohort / total
p16_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2016") +
  labs(title = "June 2016 (1 year)", x = NULL, y = NULL)
## 2017 dispersal plot for 2015 cohort
p17_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2017") +
  labs(title = "June 2017 (2 years)", x = NULL, y = NULL)
## 2018 dispersal plot for 2015 cohort
p18_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2018") +
  labs(title = "June 2018 (3 years)", x = NULL, y = NULL)
## 2019 dispersal plot for 2015 cohort
p19_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "August 2019") +
  labs(title = "August 2019 (4 years)", x = NULL, y = NULL)
## 2020 dispersal plot for 2015 cohort
p20_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "March 2020") +
  labs(title = "March 2020 (4.5 years)", x = NULL, y = NULL)

# 2017 cohort
## 2017 dispersal plot for 2017 cohort
p17_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "June 2017") +
  labs(title = "June 2017 (2 months)", x = NULL, y = NULL)
## 2018 dispersal plot for 2017 cohort
p18_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "June 2018") +
  labs(title = "June 2018 (1 year)", x = NULL, y = NULL)
## 2019 dispersal plot for 2017 cohort
p19_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "August 2019") +
  labs(title = "August 2019 (2 years)", x = NULL, y = NULL)
## 2020 dispersal plot for 2017 cohort
p20_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "March 2020") +
  labs(title = "March 2020 (2.75 years)", x = NULL, y = NULL)

# total
## 2015 dispersal plot for total
p15 <- den.plot(data = movements.data, cohort = "2015", occasion = "August 2015") +
  labs(title="August 2015",x=NULL, y = NULL)
## 2016 dispersal plot for total
p16 <- den.plot(data = movements.data, cohort = "2015", occasion = "June 2016") +
  labs(title="June 2016",x=NULL, y = NULL)
## 2017 dispersal plot for total
p17 <- den.plot(data = movements.data, cohort = c("2015", "2017"), 
                occasion = "June 2017") +
  labs(title="June 2017",x=NULL, y = NULL)
## 2018 dispersal plot for total
p18 <- den.plot(data = movements.data, cohort = c("2015", "2017"), 
                occasion = "June 2018") +
  labs(title="June 2018",x=NULL, y = NULL)
## 2019 dispersal plot for total
p19 <- den.plot(data = movements.data, cohort = c("2015", "2017", "2019"), 
                occasion = "August 2019") + labs(title="August 2019",
                                                 x=NULL, y = NULL)
## 2020 dispersal plot for total
p20 <- den.plot(data = movements.data, cohort = c("2015", "2017", "2019"), 
                occasion = "March 2020") + labs(title="March 2020",
                                                x=NULL, y = NULL)
```

```{r, fig.height = 10, fig.width = 12}
# 2015 cohort dispersal plot
dispersal_15cohort <- ggarrange(p15_c15, p16_c15, p17_c15, 
                                p18_c15, p19_c15, p20_c15,
                                ncol = 1, nrow = 6)
annotate_figure(dispersal_15cohort,
                top = text_grob("2015 cohort dispersal", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

```{r, fig.height = 8, fig.width = 10}
# 2017 cohort dispersal plot
dispersal_17cohort <- ggarrange(p17_c17, p18_c17, p19_c17, p20_c17, 
                                ncol = 1, nrow = 4)

annotate_figure(dispersal_17cohort,
                top = text_grob("2017 cohort dispersal", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

```{r, fig.height = 10, fig.width = 12}
# Total disperal plot
dispersal_total <- ggarrange(p15, p16, p17, p18, p19, p20, ncol = 1, nrow = 6)

annotate_figure(dispersal_total,
                top = text_grob("Total dispersal (all cohorts)", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

Let's make this previous visualization another way using ridgeplots. I'll align these dispersal surfaces with the population size on Santa Fe.

```{r, fig.height = 5, fig.width = 9.5}
library(ggridges)
library(purrr)
# cumulative N plot
N.plot <-
  total_pop %>%
  map_df(rev) %>%
  ggplot(aes(x = Year, y = N_hat)) +
  scale_x_reverse() +
  geom_line(lwd = 1) +
  geom_ribbon(aes(x = Year, ymin = 0, ymax = N_hat), fill = "grey") +
  coord_flip() + scale_y_continuous(limits = c(0,600), breaks = c(0,250,500)) +
  scale_x_reverse(limits = c(2020.4, 2014.3), breaks = c(2015:2020)) +
  theme_bw() + mythemes + xlab("Year") + ylab("N-est")

disp.plot <-
  movements.data %>%
  filter(Days_ellapsed > 0 & occ != "April 2019") %>%
  droplevels() %>%
  ggplot(aes(x = dist, y = fct_rev(occ))) +
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2,
                      rel_min_height = 0.01, jittered_points = TRUE,
                      position = position_points_jitter(width = 0.5, height = 0),
                      point_shape = "|", point_size = 1,
                      alpha = 0.7, vline_size = 0.8, vline_color = "blue") +
  theme_bw() + mythemes +
  scale_x_continuous(expand = c(0.02,0), limits = c(0,2000), breaks = seq(0,2000,250)) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  annotate("text", x = 1500, y = 1.3, label = "March 2020", size = 5) +
  annotate("text", x = 1500, y = 2.3, label = "August 2019", size = 5) +
  annotate("text", x = 1500, y = 3.3, label = "June 2018", size = 5) +
  annotate("text", x = 1500, y = 4.3, label = "June 2017", size = 5) +
  annotate("text", x = 1500, y = 5.3, label = "June 2016", size = 5) +
  annotate("text", x = 1500, y = 6.3, label = "August 2015", size = 5) +
  labs(x = "Distance from release (m)", y = NULL)

ggarrange(N.plot, disp.plot, widths = c(1, 4), ncol = 2)
```

Let's directly contrast the initial (+2 months, +1 year, +2 years) dispersal distances between the first two release cohorts. Here I'll show the 95% isopleth with dashed lines and the max distance with solid lines.

```{r, fig.height = 5, fig.width = 8}
init.disp.contrast <- 
  movements.data[c(movements.data$Cohort == "2015" & 
                     movements.data$occ == "August 2015") |
                   c(movements.data$Cohort == "2015" & 
                       movements.data$occ == "June 2016") |
                   c(movements.data$Cohort == "2015" & 
                       movements.data$occ == "June 2017") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "June 2017") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "June 2018") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "August 2019"),] 

init.disp.contrast <- 
  init.disp.contrast[is.na(init.disp.contrast$PIT_final) == FALSE,]

init.disp.contrast$Ellapsed <- "1-2 months"
init.disp.contrast$Ellapsed[c(init.disp.contrast$Cohort == "2015" & 
                                init.disp.contrast$occ == "June 2016") |
                              c(init.disp.contrast$Cohort == "2017" &
                                  init.disp.contrast$occ == "June 2018")] <- "1 year"
init.disp.contrast$Ellapsed[c(init.disp.contrast$Cohort == "2015" &
                                init.disp.contrast$occ == "June 2017") |
                              c(init.disp.contrast$Cohort == "2017" &
                                  init.disp.contrast$occ == "August 2019")] <- "2 years"

init.disp.contrast$Ellapsed <- factor(init.disp.contrast$Ellapsed, 
                                      levels = c("1-2 months", "1 year", "2 years"))

disp.sum <- init.disp.contrast %>%
  droplevels() %>%
  group_by(Cohort, Ellapsed) %>%
  summarise(q95 = quantile(dist, 0.95, na.rm = T),
            maxdist = max(dist, na.rm = T)) %>%
  ungroup() 

levels(init.disp.contrast$Cohort) <- c("1", "2", "3")
levels(disp.sum$Cohort) <- c("1", "2")

init.disp.contrast.p <- ggplot(init.disp.contrast, aes(dist)) + 
  geom_density(aes(fill = Cohort), alpha = 0.3, lwd = 0.9) +
  geom_segment(data = disp.sum, aes(x = q95, xend = q95, yend = 0, 
                                    y = Inf, color = Cohort), 
               lwd = 0.8, lty = "dashed") +
  geom_segment(data = disp.sum, 
               aes(x = maxdist, xend = maxdist, 
                   yend = 0, y = Inf, color = Cohort), 
               lwd = 0.8, lty = "solid") +
  geom_text(data = disp.sum, 
            aes(label = floor(q95), x = q95, y = 0.0085, 
                angle = 90, color = Cohort), 
            size = 3, show.legend = FALSE) +
  geom_text(data = disp.sum, 
            aes(label = floor(maxdist), x = maxdist, y = 0.0085, 
                angle = 90, color = Cohort), 
            size = 3, show.legend = FALSE) +
  facet_grid(rows = vars(Ellapsed)) + theme_light() + mythemes +
  theme(plot.title = element_text(size = 18)) + 
  labs(y = "Density", x = "Distance from release (m)") +
  coord_cartesian(ylim = c(0, 0.0075), clip = 'off') +
  scale_x_continuous(expand = c(0.02,0), limits = c(0,1600), 
                     breaks = seq(0,1500,250)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_rug(sides = "b", aes(color = Cohort), show.legend = FALSE) +
  theme(panel.spacing = unit(2, "lines")) + 
  theme(plot.margin = unit(c(2,1,1,1), "lines")) + 
  theme(strip.text = element_text(size = 13))
  
init.disp.contrast.p
```

A few takeaways:

(1) Tortoises from all three cohorts seem to rapidly disperse within the first two months after release, and become a bit more fixed thereafter. The second cohort seems to disperse a bit more widely than the first in that initial period. This could be evidence of a density-dependent dispersal process.

(2) The first cohort seemed to become spatially fixed two years post-release. This could be a natural dispersal plateau for the population on this island or be due to a sampling bias that missed individuals that were outside of the sampling zone.

## Spatial patterns - telemetry data

Let's also look at dispersal using radiotelemetry data from a sample of the 2015 cohort, tracked for two years, from release to June of 2017. I'll prepare the data the same way I did for the recapture data.

```{r, read-and-prepare-radiotelemetry-data}
telemetry <- read.csv("data/telemetry_clean.csv")
telemetry$Frecuencia <- as.factor(telemetry$Frecuencia)
telemetry$Date <- as.Date(telemetry$Date,format='%m-%d-%Y')
telemetry <- telemetry[,4:9]

# create extra rows for the June 2015 origin point for each tortoise
teletemp <- data.frame(Date = as.Date("2015-06-27"),
                       PIT = unique(telemetry$PIT),
                       Frecuencia = unique(telemetry$Frecuencia),
                       Latitud = -0.82076,
                       Longitud = -90.060063,
                       LC_cm = NA)

telemetry <- rbind(telemetry, teletemp)
telemetry$Days_ellapsed <- julian(telemetry$Date, 
                                  origin = as.Date("2015-06-27"))

# write to csv, make projected UTM shapefile in ArcMap
write.csv(telemetry, "data/telemetry_data_GIS.csv")

# read shapefile from ArcMap
telemetry.shp <- readOGR("data/telemetry_data_UTM2.shp")

# here I create new X and Y UTM fields that make coordinates relative to the release point (0,0). this will make it easier to quickly assess dispersal distances in the maps by centering the release point at 0,0.

telemetry.shp$X_corrected <- telemetry.shp$X - 827253
telemetry.shp$Y_corrected <- telemetry.shp$Y - 9909160
telemetry.data <- as.data.frame(telemetry.shp)
```

Now let's look at those traces, both in aggregate and color-coded by individual.

```{r, plot-traces-of-radiotelemetry-data-from-2015-cohort}
traces.tele <- ggplot() +
  geom_polygon(data = santafe, aes(x = santafe$X, y = santafe$Y), 
               fill = "grey") +
  geom_path(data = telemetry.data, 
            aes(x = X_corrected, y = Y_corrected, group = Frecuencia), 
            alpha = 0.4, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), shape = 4, size = 2, 
             stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() +
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "", subtitle = "", caption = "") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

traces.tele
```

Let's also look at the same figure but zoomed in and with different colors for each individual.

```{r, plot-zoomed-in-traces-of-radiotelemetry-data-from-2015-cohort}
traces.tele.ind <- ggplot() +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(data = telemetry.data, 
            aes(x = X_corrected, y = Y_corrected, 
                group = Frecuencia, color = Frecuencia), lwd = 0.8) +
  geom_point(aes(x = 0, y = 0), shape = 4, size = 2, 
             stroke = 1.5, color = "black") +
  theme_classic() + mythemes + 
  coord_equal(xlim = c(-1500,1500), ylim = c(-1500, 1500)) + 
  theme(legend.position = "none") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "", subtitle = "", caption = "") +
  annotate("text", x = 1400, y = 1400, label = "N", size = 8) +
  annotate("text", x = 1400, y = 1000, label = "\u2191", size = 15)

traces.tele.ind
```

## Summary

```{r, echo = FALSE, fig.height = 9, fig.width = 11}
traces.ms <- 
  ggplot(data = movements.data, aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(aes(group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  theme_bw() + mythemes + coord_equal() +
  theme(plot.margin = unit(c(0,5,0,0), "mm"), title = element_text(size = 5)) +
  scale_x_continuous(limits = c(-3600, 3700)) +
  scale_y_continuous(limits = c(-2300, 2500)) +
  labs(x = "Distance from release (m)", 
       y = "Distance from release (m)", title = "c") 
  

top <- ggarrange(N.plot + ggtitle("a") + theme(title = element_text(size = 6)), 
                 disp.plot + ggtitle("b") + theme(title = element_text(size = 6)), 
                 widths = c(1, 4), ncol = 2)

den2020pts <- rasterToPoints(tortoise.brick.adj$Y2020, spatial = TRUE)
den2020df  <- data.frame(den2020pts)
den2020df$X_corrected <- den2020df$x - 827253
den2020df$Y_corrected <- den2020df$y - 9909160

library(scico)
den2020 <- ggplot() + 
  geom_raster(data = den2020df , 
              aes(x = X_corrected, y = Y_corrected, fill = Y2020)) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red", alpha = 0.5) +
  theme_bw() + mythemes + coord_equal() + theme(legend.position = "right") +
  theme(plot.margin = unit(c(0,0,0,0), "mm")) +
  scale_x_continuous(limits = c(-3600, 3700)) +
  scale_y_continuous(limits = c(-2300, 2500)) +
  labs(x = "Distance from release (m)", y = NULL, title = "d",
       fill = "Density (per ha)") + 
  scale_fill_scico(palette = 'batlow') +
  theme(legend.key.width=unit(1,"cm"), axis.text.y = element_blank(),
        axis.ticks.y = element_blank(), title = element_text(size = 5))

bottom <- plot_grid(traces.ms + ggtitle("c") + theme(title = element_text(size = 6)),
                    den2020 + ggtitle("d") + theme(title = element_text(size = 6)), 
                    ncol = 2, axis = "tblr", 
                    rel_widths = c(1, 1.14), align = "h")

jpeg("images/dispersal_plots.jpg", width = 11, height = 9, units = "in", res = 600)

grid.arrange(top, bottom, nrow = 2)

dev.off()
```

Let's make one final summary table of our dispersal statistics.

```{r, echo = FALSE}
movements.data.copy <- movements.data %>%
  mutate(Cohort = "Total")

movements.data %>% 
  na.omit() %>%
  bind_rows(movements.data.copy) %>%
  filter(occ != "June 2015" &
           occ != "April 2017" &
           occ != "February 2019" &
           occ != "April 2019") %>%
  group_by(occ, Cohort) %>%
  summarise(Ellapsed = round(max(Days_ellapsed, na.rm = T),1),
            Median = round(median(dist), 1),
            Mean = round(mean(dist),1),
            SD = round(sd(dist),1),
            Upper = round(quantile(dist, 0.95),1),
            Max = round(max(dist, na.rm = T),1)) -> disp.table

disp.table <- disp.table[-c(2,4),-1]

colnames(disp.table) <- c("Cohort", "Days since release", "Median (m)",
                          "Mean (m)", "SD (m)", "95% isopleth (m)", "Max (m)")

library(knitr)
library(kableExtra)
disp.table %>%
  kable(format = "html", escape = F,
        caption = "Summary of tortoise dispersal on Santa Fe from 2015 to 2020.", 
        booktabs = T) %>%
  column_spec(column = 1:7, width = "1em", width_min = "1em") %>% 
  kable_styling("hover", bootstrap_options = c("condensed"))  %>% 
  pack_rows("August 2015", 1, 1, label_row_css = row.specs) %>%
  pack_rows("June 2016", 2, 2, label_row_css = row.specs) %>%
  pack_rows("June 2017", 3, 5, label_row_css = row.specs) %>%
  pack_rows("June 2018", 6, 8, label_row_css = row.specs) %>% 
  pack_rows("August 2019", 9, 12, label_row_css = row.specs) %>%
  pack_rows("March 2020", 13, 16, label_row_css = row.specs)

write.csv(disp.table, "data/tortoise_dispersal_summary.csv")
```

# Ecosystem response

Let's examine our Santa Fe land iguana data from 2011 to 2020 to see whether the population has been affected by the tortoise introduction so far. 

```{r, echo = FALSE, out.width = "35%", out.height = "35%", fig.align = "center", fig.cap = "A male Santa Fe land iguana (*Conolophus pallidus*)."}

include_graphics("images/iguana.jpg")
```

I'll do this using two corroborative data sets: 

  (1) distance sampling data from transect surveys in 2011, 2017, and 2020

  (2) plot counts from 2011 and 2020

## Distance sampling data

### Original 2011 full-island survey

Let's first analyze our iguana population data from the full-island survey of transects conducted in 2011.

First we'll load the iguana and covariate data and prepare it for the distance sampling models in `unmarked`.

```{r, load-packages-and-iguana-data}
# load packages 
library(unmarked) 

# load iguana data 
iguanas2011 <- read.csv("data/iguanas_distsamp_2011.csv")

# subset by sex
males2011 <- iguanas2011[iguanas2011$TYPE == "ITM",]
females2011 <- iguanas2011[iguanas2011$TYPE == "ITH",]
juveniles2011 <- iguanas2011[iguanas2011$TYPE == "ITJ",]
total2011 <- rbind(males2011, females2011, juveniles2011)

# prepare for unmarked
## male observations
dists_machos <- 
  data.frame(distance = as.numeric(as.character(males2011$DISTANCE)),  
             transect = as.factor(males2011$TRANSECT))
# add in other transects without observations
levels(dists_machos$transect) <- c(levels(dists_machos$transect),
                                   unique(iguanas2011$TRANSECT[
                                     iguanas2011$TRANSECT %notin%
                                     as.character(dists_machos$transect)]))
## female observations
dists_hembras <- 
  data.frame(distance = as.numeric(as.character(females2011$DISTANCE)),  
             transect = as.factor(females2011$TRANSECT))
# add in other transects without observations
levels(dists_hembras$transect) <- c(levels(dists_hembras$transect),
                                   unique(iguanas2011$TRANSECT[
                                     iguanas2011$TRANSECT %notin%
                                     as.character(dists_hembras$transect)]))
## juvenile observations
dists_juvs <- 
  data.frame(distance = as.numeric(as.character(juveniles2011$DISTANCE)), 
             transect = as.factor(juveniles2011$TRANSECT))
# add in other transects without observations
levels(dists_juvs$transect) <- c(levels(dists_juvs$transect),
                                   unique(iguanas2011$TRANSECT[
                                     iguanas2011$TRANSECT %notin%
                                     as.character(dists_juvs$transect)]))

## total observations
dists_all <- 
  data.frame(distance = as.numeric(as.character(total2011$DISTANCE)), 
             transect = as.factor(total2011$TRANSECT))
# add in other transects without observations
levels(dists_all$transect) <- c(levels(dists_all$transect),
                                   unique(iguanas2011$TRANSECT[
                                     iguanas2011$TRANSECT %notin%
                                     as.character(dists_all$transect)]))

# load transect covariate data
covs <- read.csv(file = "data/distsamp_covars.csv", 
                 header = TRUE, row.names="transect") %>%
  mutate(transect = rownames(.)) %>%
  as.data.frame()
```

Our iguana data were originally recorded at the individual-level with continuous exact distances, but `distsamp()` requires the data at the transect-level with observations binned by the distance intervals. So we'll do that for each group here, truncating the data for each at the 0.975 quantile distance for each population to remove outliers (Buckland et al. 2001).

```{r, format-distance-sampling-data}
# pool males and females to find common quantile distance for all adults
dists_adults <- rbind(dists_machos, dists_hembras)
dists_adults$quantile <- q.rank(dists_adults$distance)
max.dist.adults <- min(dists_adults$distance[dists_adults$quantile >= 0.975], 
                       na.rm = T)
# all adults
dists_adults %>% arrange(transect) -> dists_adults
yDat_adults <- formatDistData(dists_adults, distCol="distance",
                              transectNameCol="transect",
                              dist.breaks=seq(0, max.dist.adults, length.out = 5))
# reorder data frame by transect order in covariate df for later integration
yDat_adults <- yDat_adults[match(covs$transect, rownames(yDat_adults)),]

# males
yDat_machos <- formatDistData(dists_machos, distCol="distance",
                              transectNameCol="transect",
                              dist.breaks=seq(0, max.dist.adults, length.out = 5))
yDat_machos <- yDat_machos[match(covs$transect, rownames(yDat_machos)),]

# females
yDat_hembras <- formatDistData(dists_hembras, distCol="distance",
                              transectNameCol="transect",
                              dist.breaks=seq(0, max.dist.adults, 
                                              length.out = 5))
yDat_hembras <- yDat_hembras[match(covs$transect, rownames(yDat_hembras)),]

# juveniles (no truncation because of the small sample)
yDat_juvs <- formatDistData(dists_juvs, distCol="distance",
                            transectNameCol="transect", 
                            dist.breaks=seq(0,9,length.out = 5))
yDat_juvs <- yDat_juvs[match(covs$transect, rownames(yDat_juvs)),]

# total
dists_all$quantile <- q.rank(dists_all$distance)
max.dist.all <- min(dists_all$distance[dists_all$quantile >= 0.975], na.rm = T)
yDat_all <- formatDistData(dists_all, distCol="distance",
                           transectNameCol="transect",
                           dist.breaks=seq(0, max.dist.all, length.out = 5))
yDat_all <- yDat_all[match(covs$transect, rownames(yDat_all)),]
```

Before moving on, we should check for colinearity among our covariates. Note: our covariates were linked to each transect in GIS by extending a 50m buffer around each transect (with flat ends) and calculating mean elevation, slope, and dominant vegetation type and aspect. 

Let's look at the variance inflation factors (VIFs) to see if there is any colinearity.

```{r, check-colinearity-with-VIFs}
# get VIFs
corvif(covs[,1:4]) # no colinearity
```

There doesn't seem to be any colinearity we need to worry about here.

Now let's create unmarked distance sampling frames -- `unmarkedFrameDS()` -- for each iguana category, pulling together the distance observations and spatial covariates and specifying the metadata for the sampling (i.e., transect length, measurement units, etc.) to make population estimates. We use these `unmarkedFrame` objects to run our models.

```{r, make-2011-umf}
###################################### ADULTS ##################################
umf_adults <- unmarkedFrameDS(y=as.matrix(yDat_adults), 
                              siteCovs=data.frame(elev = covs$elev,
                                                  slope = covs$slope,
                                                  aspect = covs$aspect,
                                                  veg = covs$veg), 
                              survey="line", 
                              dist.breaks=seq(0,max.dist.adults,length.out = 5), 
                              tlength=rep(500, 311), unitsIn="m")
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_adults)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_adults) <- sc.s
# summary of male data
summary(umf_adults)
hist(umf_adults, xlab="distance (m)", main="Distribution of Adult Distances", 
     cex.lab=0.8, cex.axis=0.8)

###################################### MALES ###################################
# males
umf_machos <- unmarkedFrameDS(y=as.matrix(yDat_machos), 
                              siteCovs=data.frame(elev = covs$elev,
                                                  slope = covs$slope,
                                                  aspect = covs$aspect,
                                                  veg = covs$veg), 
                              survey="line", 
                              dist.breaks=seq(0,max.dist.adults,length.out = 5), 
                              tlength=rep(500, 311), unitsIn="m")
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_machos)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_machos) <- sc.s

###################################### FEMALES #################################
# females
umf_hembras <- unmarkedFrameDS(y=as.matrix(yDat_hembras), 
                              siteCovs=data.frame(elev = covs$elev,
                                                  slope = covs$slope,
                                                  aspect = covs$aspect,
                                                  veg = covs$veg), 
                              survey="line", 
                              dist.breaks=seq(0,max.dist.adults,length.out = 5), 
                              tlength=rep(500, 311), unitsIn="m")
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_hembras)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_hembras) <- sc.s

###################################### JUVENILES ###############################
# juveniles
umf_juvs <- unmarkedFrameDS(y=as.matrix(yDat_juvs), 
                            siteCovs=data.frame(elev = covs$elev,
                                                slope = covs$slope,
                                                aspect = covs$aspect,
                                                veg = covs$veg), 
                            survey="line", 
                            dist.breaks=seq(0,9,length.out = 5), 
                            tlength=rep(500, 311), unitsIn="m")
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_juvs)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_juvs) <- sc.s
# summary of juvenile data
summary(umf_juvs)
hist(umf_juvs, xlab="distance (m)", main="Distribution of Juvenile Distances", 
     cex.lab=0.8, cex.axis=0.8)

###################################### TOTAL ###################################
# total
umf_all <- unmarkedFrameDS(y=as.matrix(yDat_all), 
                           siteCovs=data.frame(elev = covs$elev,
                                               slope = covs$slope,
                                               aspect = covs$aspect,
                                               veg = covs$veg), 
                           survey="line", 
                           dist.breaks = seq(0,max.dist.all,length.out = 5), 
                           tlength=rep(500, 311), unitsIn="m")
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_all)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_all) <- sc.s
# summary of female data
summary(umf_all)
hist(umf_all, xlab="distance (m)", main="Distribution of Iguana Distances", 
     cex.lab=0.8, cex.axis=0.8)
```
\ 
\ 

#### **Total iguanas**
***
Let's first build models for the full iguana population. We'll identify the most suitable detection function for all iguanas and use that going forward for model selection.

```{r, total-iguanas-compare-detection-functions}
all.hazard <- distsamp(
  ~veg 
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_all, keyfun="hazard", output="density", unitsOut="ha", rel.tol=0.001)

all.halfnorm <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_all, keyfun="halfnorm", output="density", unitsOut="ha", rel.tol=0.001)

all.negexp <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_all, keyfun="exp", output="density", unitsOut="ha", rel.tol=0.001)

library(AICcmodavg)
aictab(cand.set = list(all.hazard, all.halfnorm, all.negexp),
     modnames = c("hazard", "halfnorm", "negative exponential"))
```

The hazard function appears to be the best for our iguana data.

Let's now run a goodness of fit test on the global iguana model to decide whether our model structure is appropriate or if we need to account for overdispersion.

```{r, GoF-total-iguanas, cache = TRUE}
fitstats <- function(fm) {
    observed <- getY(fm@data)
    expected <- fitted(fm)
    resids <- residuals(fm)
    sse <- sum(resids^2)
    chisq <- sum((observed - expected)^2 / expected, na.rm = TRUE)
    freeTuke <- sum((sqrt(observed) - sqrt(expected))^2, na.rm = TRUE)
    out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)
    return(out)
}

set.seed(1)
GoF.all <- parboot(all.hazard, fitstats, nsim=1000, report=5)
GoF.all
par(mfrow = c(3,1))
plot(GoF.all)

c.hat.all <- GoF.all@t0[2] / mean(GoF.all@t.star[,2]); c.hat.all
```

Our global model has some issues with goodness of fit. The c-hat value is acceptable, but the model performs poorly on all three goodness of fit tests. Let's see if using a negative binomial distribution improves the model fit with `gdistsamp`.

In this case, we won't fit anything for **phi** (just the intercept), which is the availability parameter.

```{r, total-GoF-take-two-with-negbin, cache = TRUE}
umf_all_g <- unmarkedFrameGDS(y=as.matrix(yDat_all), 
                              siteCovs=data.frame(elev = covs$elev,
                                                  slope = covs$slope,
                                                  aspect = covs$aspect,
                                                  veg = covs$veg), 
                              survey="line", 
                              dist.breaks=seq(0,max.dist.all,length.out = 5), 
                              tlength=rep(500, 311), unitsIn="m", numPrimary = 1)
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_all_g)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_all_g) <- sc.s

all.hazard.nb <- gdistsamp(
  ~elev+I(elev^2)+slope+aspect+veg, 
  ~1, 
  ~veg,
  mixture = "NB",
  umf_all_g, keyfun="hazard", output="density", unitsOut="ha", rel.tol=0.001)

set.seed(1)
GoF.all.nb <- parboot(all.hazard.nb, fitstats, nsim=1000, report=5)
GoF.all.nb
par(mfrow = c(3,1))
plot(GoF.all.nb)

c.hat.all.nb <- GoF.all.nb@t0[2] / mean(GoF.all.nb@t.star[,2]); c.hat.all.nb
```

The negative binomial abundance model yields a much better model fit, so let's stick with this for all our iguana model groups.

We will use the following candidate model list for all iguana groups.

```{r, make-and-compare-models-for-total-iguanas}
all <- list() # make a list to store macho models
all$null <- gdistsamp(lambdaformula = ~1,
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_all_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

all$elev <- gdistsamp(lambdaformula = ~elev, 
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_all_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

all$elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_all_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

all$slope <- gdistsamp(lambdaformula = ~slope,  
                          phiformula = ~1, 
                          pformula = ~1,
                          umf_all_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

all$aspect <- gdistsamp(lambdaformula = ~aspect, 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_all_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

all$veg <- gdistsamp(lambdaformula = ~veg, 
                        phiformula = ~1, 
                        pformula = ~1, 
                        umf_all_g, mixture = "NB",
                        keyfun="hazard", output="density", unitsOut="ha")

all$topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_all_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

all$topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_all_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

all$subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                              phiformula = ~1, 
                              pformula = ~1, 
                              umf_all_g, mixture = "NB",
                              keyfun="hazard", output="density", unitsOut="ha")

all$global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_all_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

all$p.null <- gdistsamp(lambdaformula = ~1, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_all_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

all$p.elev <- gdistsamp(lambdaformula = ~elev, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_all_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

all$p.elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_all_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

all$p.slope <- gdistsamp(lambdaformula = ~slope, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_all_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

all$p.aspect <- gdistsamp(lambdaformula = ~aspect, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_all_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

all$p.veg <- gdistsamp(lambdaformula = ~veg, 
                          phiformula = ~1, 
                          pformula = ~veg, 
                          umf_all_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

all$p.topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_all_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

all$p.topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_all_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

all$p.subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                                phiformula = ~1, 
                                pformula = ~veg, 
                                umf_all_g, mixture = "NB",
                                keyfun="hazard", output="density", unitsOut="ha")

all$p.global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_all_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

# Making a QAIC table - list of all models for ranking
library(AICcmodavg)
# make custom model names showing the variables
modnames <- c("lambda(.) p(.)", 
              "lambda(elev) p(.)", 
              "lambda(elev + elev^2^) p(.)",
              "lambda(slope) p(.)", 
              "lambda(aspect) p(.)",
              "lambda(veg) p(.)", 
              "lambda(elev + slope + aspect) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect) p(.)",
              "lambda(elev + slope + aspect + veg) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect + veg) p(.)", 
              "lambda(.) p(veg)", 
              "lambda(elev) p(veg)", 
              "lambda(elev + elev^2^) p(veg)",
              "lambda(slope) p(veg)", 
              "lambda(aspect) p(veg)", 
              "lambda(veg) p(veg)", 
              "lambda(elev + slope + aspect) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect) p(veg)",
              "lambda(elev + slope + aspect + veg) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect + veg) p(veg)")

# Rank by QAIC and print 
all.rankings <- as.data.frame(aictab(cand.set = all, 
                                        modnames = modnames,
                                        c.hat = c.hat.all.nb, second.ord = FALSE, 
                                        sort = TRUE))

all.rankings$Deviance <- round(-2*all.rankings$Quasi.LL,2) # get deviances
all.rankings <- all.rankings[,c(1,2,4,6,9,10)]
colnames(all.rankings) <- c("Model", "K", "Delta_QAIC", 
                               "QAIC_wt.", "Cum. weight", "Deviance")

kable(all.rankings, "html", row.names = FALSE, 
      caption = "Poisson abundance model rankings for total iguanas", 
      digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "350px")

write.csv(all.rankings, "data/iguana_all_QAIC.csv")
```

It seems like aspect is overwhelmingly driving iguana distributions, with more iguanas in areas with north and west-facing slopes. There is still some model uncertainty, with several other models within 6 QAIC units and a cumulative weight of 0.95. 

Let's follow the same approach for all our iguana subgroups. I don't show all the code for these sections, as they will be virtually the same as what was presented above.

Male and female adult iguanas should display the same detection function, so let's examine goodness of fit on a pooled adult dataset rather than each sex individually.

```{r, adult-iguanas-compare-detection-functions}
adults.hazard <- distsamp(
  ~veg 
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_adults, keyfun="hazard", output="density", unitsOut="ha", rel.tol=0.0001)

adults.halfnorm <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_adults, keyfun="halfnorm", output="density", unitsOut="ha", rel.tol=0.0001)

adults.negexp <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_adults, keyfun="exp", output="density", unitsOut="ha", rel.tol=0.0001)

aictab(cand.set = list(adults.hazard, adults.halfnorm, adults.negexp),
     modnames = c("hazard", "halfnorm", "negative exponential"))
```

The hazard function again is what we probably want. Let's examine goodness of fit.

```{r, GoF-adults, cache = TRUE}
set.seed(12)
GoF.adults <- parboot(adults.hazard, fitstats, nsim=1000, report=5)
GoF.adults
par(mfrow = c(3,1))
plot(GoF.adults)

c.hat.adults <- GoF.adults@t0[2] / mean(GoF.adults@t.star[,2]); c.hat.adults
```

Let's look at the negative binomial global hazard model fit statistics for adults.

```{r, GoF-adults-nb, cache = TRUE}
umf_adults_g <- unmarkedFrameGDS(y=as.matrix(yDat_adults), 
                                 siteCovs=data.frame(elev = covs$elev,
                                                     slope = covs$slope,
                                                     aspect = covs$aspect,
                                                     veg = covs$veg), 
                                 survey="line", 
                                 dist.breaks=seq(0, max.dist.adults,
                                                 length.out = 5), 
                                 tlength=rep(500, 311), 
                                 unitsIn="m", 
                                 numPrimary = 1)
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_adults_g)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_adults_g) <- sc.s

adults.hazard.nb <- gdistsamp(
  ~elev+I(elev^2)+slope+aspect+veg, 
  ~1, 
  ~veg,
  mixture = "NB",
  umf_adults_g, keyfun="hazard", output="density", unitsOut="ha", rel.tol=0.001)

set.seed(1)
GoF.adults.nb <- parboot(adults.hazard.nb, fitstats, nsim=1000, report=5)
GoF.adults.nb
par(mfrow = c(3,1))
plot(GoF.adults.nb)

c.hat.adults.nb <- GoF.adults.nb@t0[2] / mean(GoF.adults.nb@t.star[,2]) 
c.hat.adults.nb
```

This model fits the goodness of fit tests, with minimal additional overdispersion. Let's compare models for male and female iguanas using this distribution and c-hat correction.
\ 
\ 

#### **Male iguanas**
***

First we need to create a new `unmarkedFrameGDS` for male iguanas.

```{r}
umf_machos_g <- unmarkedFrameGDS(y=as.matrix(yDat_machos), 
                                 siteCovs=data.frame(elev = covs$elev,
                                                     slope = covs$slope,
                                                     aspect = covs$aspect,
                                                     veg = covs$veg), 
                                 survey="line", 
                                 dist.breaks=seq(0, max.dist.adults,
                                                 length.out = 5), 
                                 tlength=rep(500, 311), 
                                 unitsIn="m", 
                                 numPrimary = 1)
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_machos_g)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_machos_g) <- sc.s
```

Now let's build and rank our candidate model suite for male iguanas.

```{r, make-and-compare-macho-models, echo = FALSE}
machos <- list() # make a list to store macho models
machos$null <- gdistsamp(lambdaformula = ~1,
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_machos_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

machos$elev <- gdistsamp(lambdaformula = ~elev, 
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_machos_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

machos$elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_machos_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

machos$slope <- gdistsamp(lambdaformula = ~slope,  
                          phiformula = ~1, 
                          pformula = ~1,
                          umf_machos_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

machos$aspect <- gdistsamp(lambdaformula = ~aspect, 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_machos_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

machos$veg <- gdistsamp(lambdaformula = ~veg, 
                        phiformula = ~1, 
                        pformula = ~1, 
                        umf_machos_g, mixture = "NB",
                        keyfun="hazard", output="density", unitsOut="ha")

machos$topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_machos_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

machos$topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_machos_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

machos$subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                              phiformula = ~1, 
                              pformula = ~1, 
                              umf_machos_g, mixture = "NB",
                              keyfun="hazard", output="density", unitsOut="ha")

machos$global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_machos_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

machos$p.null <- gdistsamp(lambdaformula = ~1, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_machos_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

machos$p.elev <- gdistsamp(lambdaformula = ~elev, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_machos_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

machos$p.elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_machos_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

machos$p.slope <- gdistsamp(lambdaformula = ~slope, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_machos_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

machos$p.aspect <- gdistsamp(lambdaformula = ~aspect, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_machos_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

machos$p.veg <- gdistsamp(lambdaformula = ~veg, 
                          phiformula = ~1, 
                          pformula = ~veg, 
                          umf_machos_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

machos$p.topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_machos_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

machos$p.topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_machos_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

machos$p.subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                                phiformula = ~1, 
                                pformula = ~veg, 
                                umf_machos_g, mixture = "NB",
                                keyfun="hazard", output="density", unitsOut="ha")

machos$p.global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_machos_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

# Making a QAIC table - list of machos models for ranking
# make custom model names showing the variables
modnames <- c("lambda(.) p(.)", 
              "lambda(elev) p(.)", 
              "lambda(elev + elev^2^) p(.)",
              "lambda(slope) p(.)", 
              "lambda(aspect) p(.)",
              "lambda(veg) p(.)", 
              "lambda(elev + slope + aspect) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect) p(.)",
              "lambda(elev + slope + aspect + veg) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect + veg) p(.)", 
              "lambda(.) p(veg)", 
              "lambda(elev) p(veg)", 
              "lambda(elev + elev^2^) p(veg)",
              "lambda(slope) p(veg)", 
              "lambda(aspect) p(veg)", 
              "lambda(veg) p(veg)", 
              "lambda(elev + slope + aspect) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect) p(veg)",
              "lambda(elev + slope + aspect + veg) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect + veg) p(veg)")

# Rank by QAIC and print 
machos.rankings <- as.data.frame(aictab(cand.set = machos, 
                                        modnames = modnames,
                                        c.hat = c.hat.adults.nb, second.ord = FALSE, 
                                        sort = TRUE))

machos.rankings$Deviance <- round(-2*machos.rankings$Quasi.LL,2) # get deviances
machos.rankings <- machos.rankings[,c(1,2,4,6,9,10)]
colnames(machos.rankings) <- c("Model", "K", "Delta_QAIC", 
                               "QAIC_wt.", "Cum. weight", "Deviance")

kable(machos.rankings, "html", row.names = FALSE, 
      caption = "Poisson abundance model rankings for male iguanas", 
      digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "350px")

write.csv(machos.rankings, "data/iguana_machos_QAIC.csv")
```

Similar rankings to the full iguana population. 

```{r}
machos$p.aspect
```

Aspect seems to be important and vegetation type affects detection.

\ 
\ 

#### **Female iguanas**
***

```{r}
umf_hembras_g <- unmarkedFrameGDS(y=as.matrix(yDat_hembras), 
                                 siteCovs=data.frame(elev = covs$elev,
                                                     slope = covs$slope,
                                                     aspect = covs$aspect,
                                                     veg = covs$veg), 
                                 survey="line", 
                                 dist.breaks=seq(0, max.dist.adults,
                                                 length.out = 5), 
                                 tlength=rep(500, 311), 
                                 unitsIn="m", 
                                 numPrimary = 1)
# scale continuous covariates (elevation, slope)
sc <- siteCovs(umf_hembras_g)
sc.s <- cbind(scale(sc[,1:2]), sc[,3:4])
siteCovs(umf_hembras_g) <- sc.s
```

```{r, make-and-compare-female-models, echo = FALSE}
hembras <- list() # make a list to store hembra models
hembras$null <- gdistsamp(lambdaformula = ~1,
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_hembras_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

hembras$elev <- gdistsamp(lambdaformula = ~elev, 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_hembras_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

hembras$elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_hembras_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

hembras$slope <- gdistsamp(lambdaformula = ~slope,  
                           phiformula = ~1, 
                           pformula = ~1,
                           umf_hembras_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

hembras$aspect <- gdistsamp(lambdaformula = ~aspect, 
                            phiformula = ~1, 
                            pformula = ~1, 
                            umf_hembras_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

hembras$veg <- gdistsamp(lambdaformula = ~veg, 
                         phiformula = ~1, 
                         pformula = ~1, 
                         umf_hembras_g, mixture = "NB",
                         keyfun="hazard", output="density", unitsOut="ha")

hembras$topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                          phiformula = ~1, 
                          pformula = ~1, 
                          umf_hembras_g, mixture = "NB",
                          keyfun="hazard", output="density", unitsOut="ha")

hembras$topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                           phiformula = ~1, 
                           pformula = ~1, 
                           umf_hembras_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

hembras$subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                               phiformula = ~1, 
                               pformula = ~1, 
                               umf_hembras_g, mixture = "NB",
                               keyfun="hazard", output="density", unitsOut="ha")

hembras$global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                            phiformula = ~1, 
                            pformula = ~1, 
                            umf_hembras_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

hembras$p.null <- gdistsamp(lambdaformula = ~1, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_hembras_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

hembras$p.elev <- gdistsamp(lambdaformula = ~elev, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_hembras_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

hembras$p.elev2 <- gdistsamp(lambdaformula = ~elev+I(elev^2), 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_hembras_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

hembras$p.slope <- gdistsamp(lambdaformula = ~slope, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_hembras_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

hembras$p.aspect <- gdistsamp(lambdaformula = ~aspect, 
                              phiformula = ~1, 
                              pformula = ~veg, 
                              umf_hembras_g, mixture = "NB",
                              keyfun="hazard", output="density", unitsOut="ha")

hembras$p.veg <- gdistsamp(lambdaformula = ~veg, 
                           phiformula = ~1, 
                           pformula = ~veg, 
                           umf_hembras_g, mixture = "NB",
                           keyfun="hazard", output="density", unitsOut="ha")

hembras$p.topo <- gdistsamp(lambdaformula = ~elev+slope+aspect, 
                            phiformula = ~1, 
                            pformula = ~veg, 
                            umf_hembras_g, mixture = "NB",
                            keyfun="hazard", output="density", unitsOut="ha")

hembras$p.topo2 <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect, 
                             phiformula = ~1, 
                             pformula = ~veg, 
                             umf_hembras_g, mixture = "NB",
                             keyfun="hazard", output="density", unitsOut="ha")

hembras$p.subglobal <- gdistsamp(lambdaformula = ~elev+slope+aspect+veg, 
                                 phiformula = ~1, 
                                 pformula = ~veg, 
                                 umf_hembras_g, mixture = "NB",
                                 keyfun="hazard", output="density", unitsOut="ha")

hembras$p.global <- gdistsamp(lambdaformula = ~elev+I(elev^2)+slope+aspect+veg, 
                              phiformula = ~1, 
                              pformula = ~veg, 
                              umf_hembras_g, mixture = "NB",
                              keyfun="hazard", output="density", unitsOut="ha")

# Making a QAIC table - list of hembras models for ranking
# make custom model names showing the variables
modnames <- c("lambda(.) p(.)", 
              "lambda(elev) p(.)", 
              "lambda(elev + elev^2^) p(.)",
              "lambda(slope) p(.)", 
              "lambda(aspect) p(.)",
              "lambda(veg) p(.)", 
              "lambda(elev + slope + aspect) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect) p(.)",
              "lambda(elev + slope + aspect + veg) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect + veg) p(.)", 
              "lambda(.) p(veg)", 
              "lambda(elev) p(veg)", 
              "lambda(elev + elev^2^) p(veg)",
              "lambda(slope) p(veg)", 
              "lambda(aspect) p(veg)", 
              "lambda(veg) p(veg)", 
              "lambda(elev + slope + aspect) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect) p(veg)",
              "lambda(elev + slope + aspect + veg) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect + veg) p(veg)")

# Rank by QAIC and print 
hembras.rankings <- as.data.frame(aictab(cand.set = hembras, 
                                         modnames = modnames,
                                         c.hat = c.hat.adults.nb, 
                                         second.ord = FALSE, 
                                         sort = TRUE))

hembras.rankings$Deviance <- round(-2*hembras.rankings$Quasi.LL,2) # get deviances
hembras.rankings <- hembras.rankings[,c(1,2,4,6,9,10)]
colnames(hembras.rankings) <- c("Model", "K", "Delta_QAIC", 
                                "QAIC_wt.", "Cum. weight", "Deviance")

kable(hembras.rankings, "html", row.names = FALSE, 
      caption = "Poisson abundance model rankings for female iguanas", 
      digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "350px")

write.csv(hembras.rankings, "data/iguana_hembras_QAIC.csv")
```

Similar rankings to the full iguana and male populations. 

```{r}
hembras$p.aspect
```
\ 
\ 

#### **Juvenile iguanas**
***

Let's now examine juvenile iguana distance sampling models.

```{r, juv-iguanas-compare-detection-functions}
juvs.hazard <- distsamp(
  ~veg 
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_juvs, keyfun="hazard", output="density", unitsOut="ha", rel.tol=0.0001)

juvs.halfnorm <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_juvs, keyfun="halfnorm", output="density", unitsOut="ha", rel.tol=0.0001)

juvs.negexp <- distsamp(
  ~veg
  ~elev+I(elev^2)+slope+aspect+veg, 
  umf_juvs, keyfun="exp", output="density", unitsOut="ha", rel.tol=0.0001)

aictab(cand.set = list(juvs.hazard, juvs.halfnorm, juvs.negexp),
     modnames = c("hazard", "halfnorm", "negative exponential"))
```

All three detection functions perform similarly. Let's compare the GoF of the half normal and negative exponential functions.

```{r, GoF-juvs, cache = TRUE}
set.seed(12)
GoF.juvs.hn <- parboot(juvs.halfnorm, fitstats, nsim=1000, report=5)
GoF.juvs.hn
par(mfrow = c(3,1))
plot(GoF.juvs.hn)

c.hat.juvs.hn <- GoF.juvs.hn@t0[2] / mean(GoF.juvs.hn@t.star[,2]); 
c.hat.juvs.hn

set.seed(12)
GoF.juvs.neg <- parboot(juvs.negexp, fitstats, nsim=1000, report=5)
GoF.juvs.neg
par(mfrow = c(3,1))
plot(GoF.juvs.neg)

c.hat.juvs.neg <- GoF.juvs.neg@t0[2] / mean(GoF.juvs.neg@t.star[,2]); 
c.hat.juvs.neg
```

The negative exponential function provides a slightly lower c-hat, so let's go with that function. 
```{r, make-and-compare-juveniles-models, echo = FALSE}
juvs <- list() # make a list to store hembra models
juvs$null <- distsamp(~1 ~1,
                      umf_juvs, 
                      keyfun="exp", output="density", unitsOut="ha")

juvs$elev <- distsamp(~1 ~elev, 
                      umf_juvs, 
                      keyfun="exp", output="density", unitsOut="ha")

juvs$elev2 <- distsamp(~1 ~elev+I(elev^2), 
                       umf_juvs, 
                       keyfun="exp", output="density", unitsOut="ha")

juvs$slope <- distsamp(~1 ~slope,  
                       umf_juvs, 
                       keyfun="exp", output="density", unitsOut="ha")

juvs$aspect <- distsamp(~1 ~aspect, 
                        umf_juvs, 
                        keyfun="exp", output="density", unitsOut="ha")

juvs$veg <- distsamp(~1 ~veg, 
                     umf_juvs, 
                     keyfun="exp", output="density", unitsOut="ha")

juvs$topo <- distsamp(~1 ~elev+slope+aspect, 
                      umf_juvs, 
                      keyfun="exp", output="density", unitsOut="ha")

juvs$topo2 <- distsamp(~1 ~elev+I(elev^2)+slope+aspect, 
                       umf_juvs, 
                       keyfun="exp", output="density", unitsOut="ha")

juvs$subglobal <- distsamp(~1 ~elev+slope+aspect+veg, 
                           umf_juvs, 
                           keyfun="exp", output="density", unitsOut="ha")

juvs$global <- distsamp(~1 ~elev+I(elev^2)+slope+aspect+veg, 
                        umf_juvs, 
                        keyfun="exp", output="density", unitsOut="ha")

juvs$p.null <- distsamp(~veg ~1, 
                        umf_juvs, 
                        keyfun="exp", output="density", unitsOut="ha")

juvs$p.elev <- distsamp(~veg ~elev, 
                        umf_juvs, 
                        keyfun="exp", output="density", unitsOut="ha")

juvs$p.elev2 <- distsamp(~veg ~elev+I(elev^2), 
                         umf_juvs, 
                         keyfun="exp", output="density", unitsOut="ha")

juvs$p.slope <- distsamp(~veg ~slope, 
                         umf_juvs, 
                         keyfun="exp", output="density", unitsOut="ha")

juvs$p.aspect <- distsamp(~veg ~aspect, 
                          umf_juvs, 
                          keyfun="exp", output="density", unitsOut="ha")

juvs$p.veg <- distsamp(~veg ~veg, 
                       umf_juvs, 
                       keyfun="exp", output="density", unitsOut="ha")

juvs$p.topo <- distsamp(~veg ~elev+slope+aspect, 
                        umf_juvs, 
                        keyfun="exp", output="density", unitsOut="ha")

juvs$p.topo2 <- distsamp(~veg ~elev+I(elev^2)+slope+aspect, 
                         umf_juvs, 
                         keyfun="exp", output="density", unitsOut="ha")

juvs$p.subglobal <- distsamp(~veg ~elev+slope+aspect+veg, 
                             umf_juvs, 
                             keyfun="exp", output="density", unitsOut="ha")

juvs$p.global <- distsamp(~veg ~elev+I(elev^2)+slope+aspect+veg, 
                          umf_juvs, 
                          keyfun="exp", output="density", unitsOut="ha")

# Making a QAIC table - list of juvs models for ranking
# make custom model names showing the variables
modnames <- c("lambda(.) p(.)", 
              "lambda(elev) p(.)", 
              "lambda(elev + elev^2^) p(.)",
              "lambda(slope) p(.)", 
              "lambda(aspect) p(.)",
              "lambda(veg) p(.)", 
              "lambda(elev + slope + aspect) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect) p(.)",
              "lambda(elev + slope + aspect + veg) p(.)", 
              "lambda(elev + elev^2^ + slope + aspect + veg) p(.)", 
              "lambda(.) p(veg)", 
              "lambda(elev) p(veg)", 
              "lambda(elev + elev^2^) p(veg)",
              "lambda(slope) p(veg)", 
              "lambda(aspect) p(veg)", 
              "lambda(veg) p(veg)", 
              "lambda(elev + slope + aspect) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect) p(veg)",
              "lambda(elev + slope + aspect + veg) p(veg)",
              "lambda(elev + elev^2^ + slope + aspect + veg) p(veg)")

# Rank by QAIC and print 
juvs.rankings <- as.data.frame(aictab(cand.set = juvs, 
                                      modnames = modnames,
                                      c.hat = c.hat.juvs.neg, 
                                      second.ord = FALSE, 
                                      sort = TRUE))

juvs.rankings$Deviance <- round(-2*juvs.rankings$Quasi.LL,2) # get deviances
juvs.rankings <- juvs.rankings[,c(1,2,4,6,9,10)]
colnames(juvs.rankings) <- c("Model", "K", "Delta_QAIC", 
                             "QAIC_wt.", "Cum. weight", "Deviance")

kable(juvs.rankings, "html", row.names = FALSE, 
      caption = "Poisson abundance model rankings for juvenile iguanas", 
      digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "350px")

write.csv(juvs.rankings, "data/iguana_juvs_QAIC.csv")
```

We see some support for an elevation effect on juvenile iguanas. The null model is ranked close to the top though, which may be due to the limited amount of data on juvenile iguanas in this dataset. No support really for a vegetation effect on detection.

```{r}
juvs$elev2
juvs$p.elev2
```

Let's visualize our covariate effects on each iguana group. To do this I’ll make model averaged predictions of density across values of each covariate individually, keeping the other covariates at constant values or getting the average value across factor levels for aspect and vegetation type.

```{r, iguana-covariate-predictions, fig.height = 5, fig.width = 8}
library(plyr)
# 1. ELEVATION
elev.sim <- seq(min(covs$elev), max(covs$elev), length.out = 30)
elev.new <- (elev.sim - mean(covs$elev))/sd(covs$elev)
## predict function for elevation effect
elev.pred.fun <- function(mod.list, group.chat){
  pred = as.data.frame(modavgPred(cand.set = mod.list, type = "response", 
                                  parm.type = "lambda",
                                  newdata = 
                                    data.frame(elev = rep(elev.new, 8),
                                               slope = 0,
                                               aspect = c(rep("N", 60), 
                                                          rep("E", 60), 
                                                          rep("S", 60), 
                                                          rep("W", 60)), 
                                               veg = c(rep(c(rep("Shrubs", 30),
                                                             rep("Herbaceous", 30)), 
                                                           4))), 
                                  c.hat = group.chat)$matrix.output)
  pred$elev <- rep(elev.sim, 8)
  pred = ddply(pred, .(elev), summarize, 
               density.pred = mean(mod.avg.pred),
               se = mean(uncond.se),
               lcl = mean(lower.CL),
               ucl = mean(upper.CL))
  return(pred)
}
elev.pred.males <- elev.pred.fun(machos, c.hat.adults.nb)
elev.pred.females <- elev.pred.fun(hembras, c.hat.adults.nb)
elev.pred.juveniles <- elev.pred.fun(juvs, c.hat.juvs.neg)

# 2. SLOPE
slope.sim <- seq(min(covs$slope), max(covs$slope), length.out = 30)
slope.new <- (slope.sim - mean(covs$slope))/sd(covs$slope)
## predict function for slope effect
slope.pred.fun <- function(mod.list, group.chat){
  pred = as.data.frame(modavgPred(cand.set = mod.list, type = "response", 
                                   parm.type = "lambda",
                                   newdata = 
                                     data.frame(elev = 0, 
                                                slope = rep(slope.new, 8),
                                                aspect = c(rep("N", 60), 
                                                           rep("E", 60), 
                                                           rep("S", 60), 
                                                           rep("W", 60)),
                                                veg = c(rep(c(rep("Shrubs",30),
                                                              rep("Herbaceous",30)), 
                                                            4))), 
                                   c.hat = group.chat)$matrix.output)
  pred$slope <- rep(slope.sim, 8)
  pred = ddply(pred, .(slope), summarize, 
                density.pred = mean(mod.avg.pred), 
                se = mean(uncond.se), 
                lcl = mean(lower.CL), 
                ucl = mean(upper.CL))
  return(pred)
}
slope.pred.males <- slope.pred.fun(machos, c.hat.adults.nb)
slope.pred.females <- slope.pred.fun(hembras, c.hat.adults.nb)
slope.pred.juveniles <- slope.pred.fun(juvs, c.hat.juvs.neg)

# 3. ASPECT
aspect.pred.fun <- function(mod.list, group.chat){
  pred = as.data.frame(modavgPred(cand.set = mod.list, type = "response", 
                                  parm.type = "lambda",
                                  newdata = 
                                    data.frame(elev = 0, 
                                               slope = 0, 
                                               aspect = c(rep("N", 2), 
                                                          rep("E", 2), 
                                                          rep("S", 2), 
                                                          rep("W", 2)), 
                                               veg = c(rep(c("Shrubs",
                                                             "Herbaceous"), 4))), 
                                  c.hat = group.chat)$matrix.output)
  pred$aspect <- c(rep("N", 2), rep("E", 2), rep("S", 2), rep("W", 2))
  pred = ddply(pred, .(aspect), summarize, 
                density.pred = mean(mod.avg.pred), 
                se = mean(uncond.se), 
                lcl = mean(lower.CL), 
                ucl = mean(upper.CL))
  return(pred)
}
aspect.pred.males <- aspect.pred.fun(machos, c.hat.adults.nb)
aspect.pred.females <- aspect.pred.fun(hembras, c.hat.adults.nb)
aspect.pred.juveniles <- aspect.pred.fun(juvs, c.hat.juvs.neg)

# 4. VEGETATION
veg.pred.fun <- function(mod.list, group.chat){
  pred = as.data.frame(modavgPred(cand.set = mod.list, type = "response", 
                                  parm.type = "lambda",
                                  newdata = 
                                    data.frame(elev = 0, 
                                               slope = 0, 
                                               aspect = c(rep(c("N","E",
                                                                "S","W"),2)), 
                                               veg = c(rep("Shrubs",4),
                                                       rep("Herbaceous",4))), 
                                  c.hat = group.chat)$matrix.output)
  pred$veg = c(rep("Shrubs",4),rep("Herbaceous",4))
  pred = ddply(pred, .(veg), summarize, 
               density.pred = mean(mod.avg.pred), 
               se = mean(uncond.se), 
               lcl = mean(lower.CL), 
               ucl = mean(upper.CL))
  return(pred)
}
veg.pred.males <- veg.pred.fun(machos, c.hat.adults.nb)
veg.pred.females <- veg.pred.fun(hembras, c.hat.adults.nb)
veg.pred.juveniles <- veg.pred.fun(juvs, c.hat.juvs.neg)
  
# combine model-averaged covariate predictions by sex
elev.pred <- rbind(elev.pred.males, elev.pred.females, elev.pred.juveniles)
elev.pred$Sex <- c(rep("Males", 30), rep("Females", 30), rep("Juveniles", 30))
elev.pred$Sex <- factor(elev.pred$Sex, 
                        levels = c("Juveniles", "Females", "Males"))

slope.pred <- rbind(slope.pred.males, slope.pred.females, slope.pred.juveniles)
slope.pred$Sex <- c(rep("Males", 30), rep("Females", 30), rep("Juveniles", 30))
slope.pred$Sex <- factor(slope.pred$Sex, 
                         levels = c("Juveniles", "Females", "Males"))

aspect.pred <- rbind(aspect.pred.males, aspect.pred.females, aspect.pred.juveniles)
aspect.pred$Sex <- c(rep("Males", 4), rep("Females", 4), rep("Juveniles", 4))
aspect.pred$Sex <- factor(aspect.pred$Sex, 
                          levels = c("Juveniles", "Females", "Males"))

veg.pred <- rbind(veg.pred.males, veg.pred.females, veg.pred.juveniles)
veg.pred$Sex <- c(rep("Males", 2), rep("Females", 2), rep("Juveniles", 2))
veg.pred$Sex <- factor(veg.pred$Sex, 
                       levels = c("Juveniles", "Females", "Males"))

# PLOTS
elev.plot <- ggplot(elev.pred, aes(x = elev, y = density.pred, col = Sex)) + 
  geom_line(lwd = 1.1) + geom_line(aes(y = lcl), lty = "dashed") + 
  geom_line(aes(y = ucl), lty = "dashed") + 
  labs(x = "Elevation (m)", y = NULL) + ylim(c(0,7)) + 
  theme_classic() + mythemes + 
  scale_color_brewer(palette = "Dark2")

slope.plot <- ggplot(slope.pred, aes(x = slope, y = density.pred, col = Sex)) + 
  geom_line(lwd = 1.1) + geom_line(aes(y = lcl), lty = "dashed") + 
  geom_line(aes(y = ucl), lty = "dashed") + 
  labs(x = "Slope", y = NULL) + ylim(c(0,7)) + 
  theme_classic() + mythemes + 
  scale_color_brewer(palette = "Dark2")

aspect.plot <- ggplot(aspect.pred, aes(x = aspect, y = density.pred, col = Sex)) +
  geom_point(position=position_dodge(0.5)) + 
  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = 0.5, 
                position=position_dodge(0.5)) + 
  labs(x = "Aspect", y = NULL) + ylim(c(0,7)) + 
  theme_classic() + mythemes + 
  scale_color_brewer(palette = "Dark2")

veg.plot <- ggplot(veg.pred, aes(x = veg, y = density.pred, col = Sex)) + 
  geom_point(position=position_dodge(0.5)) + 
  geom_errorbar(aes(ymin = lcl, ymax = ucl), width = 0.25, 
                position=position_dodge(0.5)) + 
  labs(x = "Vegetation", y = NULL) + ylim(c(0,7)) +
  theme_classic() + mythemes + 
  scale_color_brewer(palette = "Dark2")

combined.pred.plots <- ggarrange(elev.plot, slope.plot, 
                                 aspect.plot, veg.plot, nrow = 2, ncol = 2, 
                                 common.legend = TRUE, legend = "bottom",
                                 labels = c("a", "b", "c", "d"),
                                 label.x = c(rep(0.1, 4)))

annotate_figure(combined.pred.plots,
                left = text_grob(expression(Iguanas ~ ha^-1), 
                                 rot = 90, size = 18))
```

Adult iguanas, particularly males, seem to show a greater affinity for northern and western slopes.

It appears that the elevation effect on juveniles is possibly a statistical artifact of their small sample size. There may be a lower volume of iguanas at low elevations (i.e., near coastal). But we'll need a larger sample to confirm that effect.

\ 
\ 

#### **Distribution and abundance**
***

Let's now obtain model-averaged abundance estimates and distribution maps for the iguana population on Santa Fe from the full-island survey in 2011.

First we need to load and stack rasters of the covariates.

```{r}
library(raster)
library(sp)
library(rgdal)
library(rasterVis)
library(viridis)
# load rasters
elev <- raster("data/elev_z_ha_2")
slope <- raster("data/slope_z_ha_2")
aspect <- raster("data/aspect_ha_2")
veg <- raster("data/veg_ha_2")

# stack rasters
santafe.raster <- stack(elev, slope, aspect, veg)
names(santafe.raster) <- c("elev", "slope", "aspect", "veg")
# note: continuous rasters are on z-scale to match the data in the models
# for aspect: N = 1, E = 2, S = 3, W = 4
# for veg: Shrubs = 1, Herbaceous = 2
plot(santafe.raster)
```

Now we can make our predictions.

```{r, fig.height=7, fig.width=12}
# convert covariate rasters to data frame with each row representing one pixel
raster.covs <- as.data.frame(santafe.raster, xy = TRUE)
raster.covs$ID <- rownames(raster.covs)
# reassign categorical covariates to match what was put into the models
raster.covs$veg <- "Herbaceous"
raster.covs$veg[raster.covs$veg_COUNT == 1610] <- "Shrubs"
raster.covs$aspect <- "E"
raster.covs$aspect[raster.covs$aspect_COUNT == 605] <- "N"
raster.covs$aspect[raster.covs$aspect_COUNT == 809] <- "S"
raster.covs$aspect[raster.covs$aspect_COUNT == 279] <- "W"
newdat <- 
  na.omit(data.frame(elev = raster.covs$elev, 
                     slope = raster.covs$slope, 
                     aspect = as.factor(raster.covs$aspect), 
                     veg = as.factor(raster.covs$veg)))

## males
male.pred <- modavgPred(cand.set = machos, type = "response", 
                        parm.type = "lambda", newdata = newdat, 
                        c.hat = c.hat.adults.nb)
male.pred <- data.frame(ID = rownames(newdat),
                        lambda = male.pred$mod.avg.pred,
                        lcl = male.pred$lower.CL,
                        ucl = male.pred$upper.CL)
# combine predictions with XY data
male.pred <- merge(male.pred, raster.covs, by = "ID", all = TRUE)
male.pred.est <- male.pred[,c(5,6,2)]
male.pred.lower <- male.pred[,c(5,6,3)]
male.pred.upper <- male.pred[,c(5,6,4)]

## females
female.pred <- modavgPred(cand.set = hembras, type = "response", 
                          parm.type = "lambda", newdata = newdat, 
                          c.hat = c.hat.adults.nb)
female.pred <- data.frame(ID = rownames(newdat),
                        lambda = female.pred$mod.avg.pred,
                        lcl = female.pred$lower.CL,
                        ucl = female.pred$upper.CL)
# combine predictions with XY data
female.pred <- merge(female.pred, raster.covs, by = "ID", all = TRUE)
female.pred.est <- female.pred[,c(5,6,2)]
female.pred.lower <- female.pred[,c(5,6,3)]
female.pred.upper <- female.pred[,c(5,6,4)]

## juveniles
juv.pred <- modavgPred(cand.set = juvs, type = "response", 
                          parm.type = "lambda", newdata = newdat, 
                       c.hat = c.hat.juvs.neg)
juv.pred <- data.frame(ID = rownames(newdat),
                        lambda = juv.pred$mod.avg.pred,
                        lcl = juv.pred$lower.CL,
                        ucl = juv.pred$upper.CL)
# combine predictions with XY data
juv.pred <- merge(juv.pred, raster.covs, by = "ID", all = TRUE)
juv.pred.est <- juv.pred[,c(5,6,2)]
juv.pred.lower <- juv.pred[,c(5,6,3)]
juv.pred.upper <- juv.pred[,c(5,6,4)]

## total
## from subgroup estimates
total.pred.sum = data.frame(x = juv.pred.est$x,
                            y = juv.pred.est$y,
                            lambda = 
                              juv.pred.est$lambda + 
                              male.pred.est$lambda +
                              female.pred.est$lambda)
total.pred.sum.lower = data.frame(x = juv.pred.lower$x,
                                  y = juv.pred.lower$y,
                                  lcl = 
                                    juv.pred.lower$lcl + 
                                    male.pred.lower$lcl +
                                    female.pred.lower$lcl)
total.pred.sum.upper = data.frame(x = juv.pred.upper$x,
                                  y = juv.pred.upper$y,
                                  ucl = 
                                    juv.pred.upper$ucl + 
                                    male.pred.upper$ucl +
                                    female.pred.upper$ucl)
## from full dataset models
total.pred <- modavgPred(cand.set = all, type = "response", 
                         parm.type = "lambda", newdata = newdat, 
                         c.hat = c.hat.all.nb)
total.pred <- data.frame(ID = rownames(newdat),
                        lambda = total.pred$mod.avg.pred,
                        lcl = total.pred$lower.CL,
                        ucl = total.pred$upper.CL)
# combine predictions with XY data
total.pred <- merge(total.pred, raster.covs, by = "ID", all = TRUE)
total.pred.est <- total.pred[,c(5,6,2)]
total.pred.lower <- total.pred[,c(5,6,3)]
total.pred.upper <- total.pred[,c(5,6,4)]

# combine predictions into one plot
library(lattice)
library(grid)
library(gridExtra)
library(colorRamps)
library(grDevices)

r1 <- ggplot(juv.pred.est, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lambda)) +
  geom_polygon(inherit.aes = FALSE, data = santafe.shp, 
               color = "black", fill = "transparent", lwd = 1.1, 
               aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") +  
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(a) juveniles") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + coord_equal()

r2 <- ggplot(female.pred.est, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lambda)) + 
  geom_polygon(inherit.aes = FALSE, data = santafe.shp, 
               color = "black", fill = "transparent", lwd = 1.1, 
               aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(b) females") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + coord_equal()

r3 <- ggplot(male.pred.est, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lambda)) + 
  geom_polygon(inherit.aes = FALSE, data = santafe.shp, 
               color = "black", fill = "transparent", lwd = 1.1, 
               aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(c) males") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + coord_equal()

r4 <- ggplot(total.pred.sum, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lambda)) + 
  geom_polygon(inherit.aes = FALSE, data = santafe.shp, 
               color = "black", fill = "transparent", lwd = 1.1, 
               aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(d) total") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + coord_equal()

ggarrange(r1, r2, r3, r4, ncol = 2, nrow = 2, common.legend = FALSE)
```


What is the total estimated population size (with confidence limits) from summing the pixel values of juveniles, females, and males?

```{r}
juvenile.pop.2011 <- data.frame(abundance = sum(na.omit(juv.pred$lambda)), 
                                lcl = sum(na.omit(juv.pred$lcl)),
                                ucl = sum(na.omit(juv.pred$ucl)))
female.pop.2011 <- data.frame(abundance = sum(na.omit(female.pred$lambda)), 
                                lcl = sum(na.omit(female.pred$lcl)),
                                ucl = sum(na.omit(female.pred$ucl)))
male.pop.2011 <- data.frame(abundance = sum(na.omit(male.pred$lambda)), 
                                lcl = sum(na.omit(male.pred$lcl)),
                                ucl = sum(na.omit(male.pred$ucl)))
# total estimate as sum of separate juvenile and adult estimates
total.pop.2011 <- data.frame(abundance = 
                               juvenile.pop.2011$abundance +
                               female.pop.2011$abundance +
                               male.pop.2011$abundance,
                             lcl = 
                               juvenile.pop.2011$lcl +
                               female.pop.2011$lcl +
                               male.pop.2011$lcl,
                             ucl =
                               juvenile.pop.2011$ucl +
                               female.pop.2011$ucl +
                               male.pop.2011$ucl)

# separate total estimate from the complete dataset
total.pop.2011.sep <- data.frame(abundance = sum(na.omit(total.pred$lambda)), 
                                 lcl = sum(na.omit(total.pred$lcl)),
                                 ucl = sum(na.omit(total.pred$ucl)))

# print the population estimates
iguana.pop.2011 <- rbind(juvenile.pop.2011, female.pop.2011, 
                         male.pop.2011, total.pop.2011)
iguana.pop.2011$type <- c("juveniles", "females", "males", "total")
iguana.pop.2011 <- iguana.pop.2011[,c(4,1,2,3)]
iguana.pop.2011

# print the separate total population estimate
total.pop.2011.sep
```

We can also map the 95% CI bounds for these density estimates.

Here are the lower bounds of the density estimates.

```{r, fig.height=7, fig.width=12}
r1 <- ggplot(juv.pred.lower, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lcl)) +
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") +  
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(a) juveniles") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r2 <- ggplot(female.pred.lower, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lcl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(b) females") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r3 <- ggplot(male.pred.lower, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lcl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(c) males") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r4 <- ggplot(total.pred.sum.lower, aes(x = x, y = y)) + 
  geom_tile(aes(fill = lcl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(d) total") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

ggarrange(r1, r2, r3, r4, ncol = 2, nrow = 2, common.legend = FALSE)
```

And here are the upper bounds.

```{r, fig.height=7, fig.width=12}
r1 <- ggplot(juv.pred.upper, aes(x = x, y = y)) + 
  geom_tile(aes(fill = ucl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) +
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") +  
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(a) juveniles") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r2 <- ggplot(female.pred.upper, aes(x = x, y = y)) + 
  geom_tile(aes(fill = ucl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(b) females") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r3 <- ggplot(male.pred.upper, aes(x = x, y = y)) + 
  geom_tile(aes(fill = ucl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes +
  labs(x = "\nLongitude", y = "Latitude\n", title = "(c) males") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

r4 <- ggplot(total.pred.sum.upper, aes(x = x, y = y)) + 
  geom_tile(aes(fill = ucl)) + 
  geom_polygon(inherit.aes = FALSE, 
               data = santafe.shp, color = "black", fill = "transparent", 
               lwd = 1.1, aes(x = long, y = lat)) + 
  scale_fill_gradientn(colors = c("darkgreen", "yellow", "red3"), 
                       na.value = "transparent") + 
  theme_bw() + mythemes + 
  labs(x = "\nLongitude", y = "Latitude\n", title = "(d) total") + 
  guides(fill = guide_colorbar(raster = TRUE, 
                               title = expression(Iguanas ~ ha^-1), 
                               title.position = "top")) + 
  coord_equal()

ggarrange(r1, r2, r3, r4, ncol = 2, nrow = 2, common.legend = FALSE)
```

### Changes from 2011--2020

Now let's use hierarchical distance sampling models to compare density estimates between years from our iguana transects. We are only using a subset of the original island-wide transects here that are within the center of the island where tortoises were released. These transects (n=28), and the permanent plots in between them, were visited three times, once before and twice after tortoise introduction.

Here is all our data prep code to run the distance sampling models in `unmarked`. We're going to stack transects by year to get abundance estimates as a function of time, tortoise density, and other covariates.

```{r}
# detach plyr to avoid conflicts
detach("package:plyr", unload = TRUE)
### LOAD DISTANCE SAMPLING DATA OF SUBSET OF TRANSECTS ###
library(readxl)
iguanas <- suppressMessages(read_excel("data/iguanas_distsamp_2011_2017_2020.xlsx", 
                                       na = "NA"))
iguanas$transect_yr <- as.factor(paste(iguanas$transect, iguanas$year, sep = "-"))

# make time a continuous covariate and impute mean survey time for missing transects
iguanas$hm <- hour(iguanas$time) + minute(iguanas$time)/60
iguanas$hm[is.na(iguanas$hm)] <- mean(iguanas$hm, na.rm = T)

# get mean times for each transect_yr
transect.times <- iguanas %>%
  group_by(transect_yr) %>%
  summarise(time = mean(hm)) %>%
  ungroup()

# number of visits for each transect
transect.visits <- iguanas %>%
  distinct(transect, year) %>%
  group_by(transect) %>%
  summarise(visits = n()) %>%
  ungroup()

# load transect buffers
iguana.buffs <- readOGR("data/iguana_transects_50m_buff.shp", verbose=FALSE)
iguana.buffs <- spTransform(iguana.buffs, CRS("+init=epsg:32715"))

# get zonal statistics for tortoise densities in iguana transect buffers
buff.2017 <- 
  data.frame(transect = iguana.buffs$transect,
             tden = c(raster::extract(tortoise.brick.adj$Y2017, 
                                      iguana.buffs, fun = mean, na.rm = TRUE)),
             tden2yr = c(raster::extract(mean(tortoise.brick.adj[[1:2]]), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             tden5yr = c(raster::extract(mean(tortoise.brick.adj[[1:2]], 
                                              tortoise.brick.adj[[1:3]]*0), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             year = 2017)
buff.2020 <- 
  data.frame(transect = iguana.buffs$transect,
             tden = c(raster::extract(tortoise.brick.adj$Y2020, 
                                      iguana.buffs, fun = mean, na.rm = TRUE)),
             tden2yr = c(raster::extract(mean(tortoise.brick.adj[[4:5]]), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             tden5yr = c(raster::extract(mean(tortoise.brick.adj[[1:5]]),
                                         iguana.buffs, fun = mean, na.rm = TRUE)), 
             year = 2020)

buff.tden <- rbind(buff.2017, buff.2020)

# subset transects to those surveyed in all three years
iguanas.sub <- iguanas %>%
  filter(transect %in% transect.visits$transect[transect.visits$visits == 3]) %>%
  droplevels() %>%
  as.data.frame()

# summarize total counts of iguanas each year within same subset of transects
iguanas.sub %>%
  filter(!is.na(distance)) %>%
  group_by(year) %>%
  summarise(n_iguanas = n()) %>%
  ungroup()

# identify distance to truncate iguana observations (convert to NAs)
iguanas.sub$quantile <- q.rank(iguanas.sub$distance)
max.dist <- min(iguanas.sub$distance[iguanas.sub$quantile >= 0.975], na.rm = T)

# prepare observations and covariates for unmarked
ydat <- formatDistData(iguanas.sub,
                       distCol="distance",
                       transectNameCol="transect_yr",
                       dist.breaks=seq(0,max.dist,length.out = 6))

### LOAD COVARIATES ###
covs <- read.csv(file = "data/distsamp_covars.csv", 
                 header = TRUE, row.names="transect") 

# subset to transects surveyed in all three years
covs <- covs %>%
  mutate(transect = rownames(.)) %>%
  filter(transect %in% transect.visits$transect[transect.visits$visits == 3]) %>%
  as.data.frame()

# standardize continuous covariates
covs$elev.z <- scale(covs$elev)
covs$slope.z <- scale(covs$slope)

# repeat data frame for each survey year
covs <- rbind(covs, covs, covs)
covs$year <- c(rep(2011, length(unique(covs$transect))), 
               rep(2017, length(unique(covs$transect))), 
               rep(2020, length(unique(covs$transect))))

# add tortoise density and time covariates
covs <- covs %>%
  left_join(buff.tden, by = c("transect", "year")) %>%
  mutate_all(~replace(., is.na(.), 0)) %>%
  mutate(transect_yr = paste(transect, year, sep = "-")) %>%
  filter(transect_yr %in% iguanas$transect_yr) %>%
  left_join(transect.times, by = c("transect_yr")) %>%
  mutate(tden.z = scale(tden),
         tden2yr.z = scale(tden2yr),
         tden5yr.z = scale(tden5yr),
         time.z = scale(time)) %>%
  droplevels() %>%
  as.data.frame() 

ydat.df <- data.frame(ydat) %>%
  mutate(transect_yr = rownames(.)) %>%
  left_join(covs, by = "transect_yr")

umf <- 
  unmarkedFrameDS(y = ydat, 
                  siteCovs = data.frame(time = ydat.df$time.z,
                                        year = as.factor(ydat.df$year),
                                        elev = ydat.df$elev.z,
                                        slope = ydat.df$slope.z,
                                        aspect = ydat.df$aspect,
                                        veg = ydat.df$veg,
                                        tden = ydat.df$tden.z,
                                        tden2yr = ydat.df$tden2yr.z,
                                        tden5yr = ydat.df$tden5yr.z), 
                  dist.breaks=seq(0,max.dist,length.out = 6),
                  unitsIn="m", survey="line", tlength = rep(500, nrow(covs)))

summary(umf)
```

Let's examine our covariates to see if we have any colinearity in our geographic and new tortoise covariates before running our distance sampling models.

```{r, echo = FALSE}
# get VIF w current tortoise density variable
corvif(covs[,c(3,4,6,7,8,14)]) # no colinearity
# get VIF w recent tortoise density variable
corvif(covs[,c(3,4,6,7,8,16)]) # no colinearity
```

The VIF scores indicate that there is no colinearity among our covariates. 

Now I'll create our models. First we want to identify the correct detection function.

```{r}
# create six base models and compare the global model for three different detection functions 
haz.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="hazard", output="density", unitsOut="ha")

haz.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="hazard", output="density", unitsOut="ha")

hn.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="halfnorm", output="density", unitsOut="ha")

hn.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="halfnorm", output="density", unitsOut="ha")

nexp.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

aictab(cand.set = list(haz.t, hn.t, nexp.t,
                       haz.t2, hn.t2, nexp.t2),
       modnames = c("hazard", "halfnorm", "negexp",
                    "hazard2", "halfnorm2", "negexp2"))
```

We're going to go with the negative exponential detection function to model iguana density. Let's run our goodness of fit tests.

```{r}
set.seed(1)
GoF <- parboot(nexp.t, fitstats, nsim=1000, report=5) ; GoF
observed <- data.frame(test = names(GoF@t0),
                       value = GoF@t0) %>% melt(id = "test")
GoF@t.star %>%
  melt() %>%
  dplyr::rename(test = Var2) %>%
  ggplot(aes(x = value)) +
  geom_histogram(col = "white", fill = "grey5", alpha = 0.3) +
  geom_vline(data = observed, aes(xintercept = value), 
             col = "blue", lwd = 0.9) +
  facet_wrap(~test, nrow = 3, scales = "free") + 
  theme_classic() + mythemes +
  labs(x = "Bootstrapped statistic", y = "Frequency")
  
c.hat <- GoF@t0[2] / mean(GoF@t.star[,2]); c.hat
```

The global model seems to fit pretty well. 

There is very slight overdispersion, so let's account for that in our model rankings and estimates.

Here is our candidate list of models.

```{r}
# create candidate models, rank with QAIC
nexp.null <- distsamp(
  ~1 ~1,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.year <- distsamp(
  ~time+year ~year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.hab <- distsamp(
  ~time+year ~elev+slope+veg+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.tden <- distsamp(
  ~time+year ~tden+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.tden5y <- distsamp(
  ~time+year ~tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.full <- distsamp(
  ~time+year ~elev+slope+veg+tden+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.full.5y <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")
```

We'll rank models with the `aictab` function from the `AICcmodavg` package.

```{r}
iguana.rankings <- 
  aictab(cand.set = list(nexp.null, nexp.year, nexp.hab, nexp.tden, 
                         nexp.tden5y, nexp.full, nexp.full.5y), c.hat = c.hat,
         modnames = c("null", "year", "habitat", "tortoises", 
                      "tortoises (5 yr)", "habitat + tortoises", 
                      "habitat + tortoises (5 yr)"))
iguana.rankings
write.csv(iguana.rankings, "data/iguana_model_rankings_stacked.csv")
```

Interesting. The year model is on top and nothing is within 2 QAICc units, which suggests that iguana population does not vary with our tortoise and/or environmental covariates.

Let's look at the parameter estimates from that year model.

```{r}
summary(nexp.year)
```

It does not appear that iguana density changes significantly over time. Detection rates may be greater in 2020. No hour effect on detection probability.

Out of curiosity, what do the next two models with the tortoise density look like?

```{r}
nexp.tden5y
nexp.tden
```

Tortoise density has no effect on iguana density.

Let's use the top model plot out our iguana density estimates for 2011, 2017, and 2020 (and include our tortoise density estimates in the plot as a reference).

```{r}
library(adehabitatHR)
# get minimal convex polygon of transect coordinates
transect.points <- 
  SpatialPoints(sp::coordinates(subset(iguana.buffs, 
                                       transect %in% iguanas.sub$transect)))

survey.zone <- mcp(transect.points, percent = 100)
writeOGR(obj = survey.zone, dsn = getwd(),  layer = "data/core_survey_zone", 
         driver="ESRI Shapefile", overwrite_layer=TRUE)

# get iguana density predictions from top model
i.lambda <- predict(nexp.year, type = "state", c.hat = c.hat, 
                      newdata = data.frame(year = c("2011", "2017", "2020")))

i.lambda$N_hat = i.lambda$Predicted * survey.zone$area
i.lambda$N_lower = i.lambda$lower * survey.zone$area
i.lambda$N_upper = i.lambda$upper * survey.zone$area
i.lambda$pct_change = (i.lambda$N_hat - i.lambda$N_hat[1])/i.lambda$N_hat[1]
i.lambda$pct_change_lwr = (i.lambda$N_lower - i.lambda$N_lower[1])/i.lambda$N_lower[1]
i.lambda$pct_change_upr = (i.lambda$N_upper - i.lambda$N_upper[1])/i.lambda$N_upper[1] 

i.lambda

# get mean tortoise density in 2017 and 2020 in survey zone
t.lambda <- 
  data.frame(estimate = c(0, raster::extract(tortoise.brick.adj$Y2017, 
                                             survey.zone, 
                                             fun = mean, na.rm = TRUE),
                          raster::extract(tortoise.brick.adj$Y2020, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE)),
             lower = c(0, raster::extract(tortoise.brick.adj.lcl$Y2017, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE),
                       raster::extract(tortoise.brick.adj.lcl$Y2020, 
                                       survey.zone, 
                                       fun = mean, na.rm = TRUE)),
             upper = c(0, raster::extract(tortoise.brick.adj.ucl$Y2017, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE),
                               raster::extract(tortoise.brick.adj.ucl$Y2020, 
                                               survey.zone,
                                       fun = mean, na.rm = TRUE)))

# combine iguana and tortoise density data frames for plotting together
sf.densities <- data.frame(density = c(i.lambda$Predicted, t.lambda$estimate),
                           lcl = c(i.lambda$lower, t.lambda$lower),
                           ucl = c(i.lambda$upper, t.lambda$upper),
                           Year = c(rep(c("2011", "2017", "2020"),2)),
                           species = c(rep("iguana", 3), rep("tortoise", 3)))

# print density / abundance table
sf.densities

# plot
distsamp.plot <-
  ggplot(sf.densities, aes(Year, density, color = species)) + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl)) +
  geom_vline(aes(xintercept = 1.71), col = "grey50", 
             lty = "dashed", lwd = 1.1) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  geom_pointrange(aes(ymin = lcl, ymax = ucl)) +
  theme_classic() + mythemes + 
  labs(x = "Year", y = "Density (per ha)") + ylim(0,10) +
  annotate("text", x = 3.2, y = sf.densities$density[3], 
           label = "iguanas", col = col2[1], size = 4) +
  annotate("text", x = 3.2, y = sf.densities$density[6], 
           label = "tortoises", col = col2[2], size = 4) +
  scale_color_manual(values = col2) + theme(legend.position = "none")

distsamp.plot
```

The population may increased slightly from 2011 to 2020 (~ 529 [421--512] individuals or 34% [17--55%]), but there is a lot of uncertainty around those estimates so there is no strong evidence to support any iguana change over time or tortoise impact on iguana distribution or abundance. This could change as tortoises get larger and begin reproducing, thus having a more sustained impact on the environment in Santa Fe. Future monitoring will be essential to verify any impacts on the iguana population.

Let's ask the same question about iguana population change using the repeated plot counts from 2011 and 2020.

## Plot data

```{r}
# load data
plots2011 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2011")) %>% arrange(Punto)
plots2017 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2017")) %>% arrange(Punto)
plots2020 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2020")) %>% arrange(Punto)
```

Plots were also measured in 2017, but iguana data from at least 10 plots from the core zone were lost and unrecoverable. So we will focus on the two years, 2011 (before) and 2020 (after) which we have complete data for.

```{r}
# filter the 2011 data to include only those plots that were surveyed in 2020
plots2011 <- plots2011 %>%
  filter(Punto %in% plots2020$Punto)

# combine the 2011 and 2020 data
iguana_plots <- 
  data.frame(Plot = plots2011$Punto, 
             Lat = plots2011$Latitud, Lon = plots2011$Longitud,
             ITM2011 = plots2011$ITM, ITH2011 = plots2011$ITH, 
             ITJ2011 = plots2011$ITJ, ITT2011 = plots2011$ITT, 
             ITM2020 = plots2020$ITM, ITH2020 = plots2020$ITH, 
             ITJ2020 = plots2020$ITJ, ITT2020 = plots2020$ITT,
             TG2011 = 0, TG2020 = plots2020$TGH+plots2020$TGM+plots2020$TGJ,
             HI2011 = plots2011$HI, HI2020 = plots2020$HI,
             CA2011 = plots2011$CA, CS2011 = plots2011$CS, 
             CJ2011 = plots2011$CJ, CT2011 = plots2011$CT,
             CA2020 = plots2020$CA, CS2020 = plots2020$CS, 
             CJ2020 = plots2020$CJ, CT2020 = plots2020$CT)
```

### Wilcoxin tests

First let's use a Wilcoxin test to compare iguana and iguana fecal density in plots between 2011 and 2020.

```{r}
# male iguanas
pop.diff.m <- wilcox.test(iguana_plots$ITM2011, iguana_plots$ITM2020, 
                          paired = TRUE); pop.diff.m
# female iguanas
pop.diff.f <- wilcox.test(iguana_plots$ITH2011, iguana_plots$ITH2020, 
                          paired = TRUE); pop.diff.f
# total iguanas
pop.diff.t <- wilcox.test(iguana_plots$ITT2011, iguana_plots$ITT2020, 
                          paired = TRUE); pop.diff.t
# fecal denstiy
fec.diff <- wilcox.test(iguana_plots$HI2011, iguana_plots$HI2020, 
                        paired = TRUE); fec.diff
```

According to these tests, there are no differences in iguana density before and after tortoise introductions. But there are a lot of plots with no differences between years, and those measurements are ignored in the significance test. There is a difference in iguana feces (more in 2020), but that may simply be due to human measurement error (including confusion with juvenile tortoise feces).

Let's also look at the same comparisons with Wilcoxin tests for cactus plot counts.

```{r}
# juvenile cactus
pop.diff.cj <- wilcox.test(iguana_plots$CJ2011, iguana_plots$CJ2020, 
                           paired = TRUE); pop.diff.cj
# subadult cactus
pop.diff.cs <- wilcox.test(iguana_plots$CS2011, iguana_plots$CS2020, 
                           paired = TRUE); pop.diff.cs
# adult cactus
pop.diff.ca <- wilcox.test(iguana_plots$CA2011, iguana_plots$CA2020, 
                           paired = TRUE); pop.diff.ca
# total cactus
pop.diff.ct <- wilcox.test(iguana_plots$CT2011, iguana_plots$CT2020, 
                           paired = TRUE); pop.diff.ct

library(broom)
library(tidyr)
iguana_plots %>%
  dplyr::select(Plot, CJ2011, CJ2020, CS2011, CS2020, 
                CA2011, CA2020, CT2011, CT2020) %>%
  pivot_longer(-Plot, names_to = "CountStage", values_to = "Count") %>%
  mutate(Year = ifelse(CountStage %in% c("CJ2011", "CS2011", "CA2011", "CT2011"), 
                       "2011", "2020"),
         Stage = case_when(CountStage %in% c("CJ2011", "CJ2020") ~ "Juvenile",
                           CountStage %in% c("CS2011", "CS2020") ~ "Subadult",
                           CountStage %in% c("CA2011", "CA2020") ~ "Adult",
                           CountStage %in% c("CT2011", "CT2020") ~ "Total"),
         Label = case_when(Stage %in% "Juvenile" ~ "a",
                           Stage %in% "Subadult" ~ "b",
                           Stage %in% "Adult" ~ "c",
                           Stage %in% "Total" ~ "d"),
         Stage = factor(Stage, levels = c("Juvenile", "Subadult", "Adult", "Total")),
         p_value = case_when(CountStage %in% c("CJ2011", "CJ2020") ~ 
                               pop.diff.cj$p.value,
                             CountStage %in% c("CS2011", "CS2020") ~ 
                               pop.diff.cs$p.value,
                             CountStage %in% c("CA2011", "CA2020") ~ 
                               pop.diff.ca$p.value,
                             CountStage %in% c("CT2011", "CT2020") ~ 
                               pop.diff.ct$p.value)) %>%
  group_by(Stage) %>%
  mutate(label.y = max(Count)) %>% ungroup() %>%
  ggpaired(x = "Year", y = "Count", id = "Plot", 
           color = "Year", line.color = alpha("grey", 0.2),
           line.size = 0.4, palette = "jco") +
  # wilcox paired test
  stat_compare_means(paired = TRUE, label.x = 1.2, size = 3) +
  geom_text(aes(x = 0.5,  y = label.y, label = Label, size = 4)) +
  facet_wrap(~Stage, nrow = 2, scales = "free") + 
  theme_classic() + mythemes +
  labs(x = "Year", y = "Cactus per plot") +
  theme(legend.position = "none") -> cactus.wilcox.plot

cactus.wilcox.plot
```

At all stages, we see changes in cactus density. There is a very weak change in adult cactus.

Let's just tabulate a summary of cactus density in our plots before and after tortoise reintroduction.

```{r}
t(
    sapply(iguana_plots[,16:23], function(...) 
      list(means = mean(..., na.rm = T)/((pi*25^2)/10000), 
           se = (sd(..., na.rm = T)/sqrt(43))/((pi*25^2)/10000)))
  )
```

### Iguana count GLMM

We'll mixed models to compare iguana plot counts of iguanas and cactus in 2011 and 2020 with the `lme4` package. This will help us understand the direction of these trends for cactus.

Let's connect our tortoise density raster to the iguana plot data. I'll create a shapefile from the plot points, and summarize the recent (5yr average) tortoise density surrounding those points (50m buffer).

```{r}
# create shapefile for plots
iguana_plots_shp <- iguana_plots
coordinates(object = iguana_plots_shp) <- ~ Lon + Lat
proj4string(iguana_plots_shp) <- CRS("+proj=longlat +datum=WGS84")
iguana_plots_shp <- spTransform(iguana_plots_shp, 
                                CRSobj = CRS("+init=epsg:32715"))

# create buffer for plots
library(rgeos)
plot_buffers <- gBuffer(iguana_plots_shp, byid = TRUE, width = 50, 
                        capStyle="ROUND")

# get zonal statistics for tortoise densities in iguana plot buffers
iguana_plots$tden <- c(raster::extract(tortoise.brick.adj[[6]], 
                                       plot_buffers,
                                       fun = mean, na.rm = TRUE))
iguana_plots$tden5y <- c(raster::extract(mean(tortoise.brick.adj[[1:5]]), 
                                         plot_buffers,
                                         fun = mean, na.rm = TRUE))

# divide tortoise density values into "high" and "low" density treatments
iguana_plots$tdencat <- 
  as.factor(ifelse(iguana_plots$tden5y < quantile(iguana_plots$tden5y, 0.5), 
                   "low", "high"))

library(reshape2)
# melt iguana data
iguana.melt <- iguana_plots %>%
  dplyr::select(c(Plot, ITM2011, ITM2020, ITH2011, ITH2020, 
                  ITJ2011, ITJ2020, ITT2011, ITT2020, tden5y, tdencat)) %>%
  melt(id = c("Plot", "tden5y", "tdencat"))

# melt cactus data
cactus.melt.juv <- iguana_plots %>%
  dplyr::select(c(Plot, CJ2011, CJ2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CJ = value,
         year = as.factor(ifelse(variable %in% "CJ2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CJ))

cactus.melt.sub <- iguana_plots %>%
  dplyr::select(c(Plot, CS2011, CS2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CS = value,
         year = as.factor(ifelse(variable %in% "CS2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CS))

cactus.melt.adu <- iguana_plots %>%
  dplyr::select(c(Plot, CA2011, CA2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CA = value,
         year = as.factor(ifelse(variable %in% "CA2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CA))

cactus.melt.tot <- iguana_plots %>%
  dplyr::select(c(Plot, CT2011, CT2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CT = value,
         year = as.factor(ifelse(variable %in% "CT2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CT))

# create data frame of iguana and cactus plot counts for GLMMs
iguana.total <- iguana.melt %>%
  filter(variable %in% "ITT2011" | variable %in% "ITT2020") %>%
  mutate(year = as.factor(ifelse(variable %in% "ITT2011", "2011", "2020"))) %>%
  left_join(cactus.melt.juv, by = c("Plot", "year")) %>%
  left_join(cactus.melt.sub, by = c("Plot", "year")) %>%
  left_join(cactus.melt.adu, by = c("Plot", "year")) %>%
  left_join(cactus.melt.tot, by = c("Plot", "year")) %>%
  mutate(status = as.factor(ifelse(value > 0, 1, 0)),
         iguanas = value)
```

Now let's build our GLMM and plot out the time * tortoise contrast.

```{r}
library(lme4)
library(lmerTest)
library(DHARMa)
library(ggeffects)

iguana.total$tdencat <- factor(iguana.total$tdencat, levels = c("low", "high"))

# models
## null
iguana.null <-glmer(iguanas ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
iguana.year <-glmer(iguanas ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## tortoise
iguana.yearXtort <- glmer(iguanas ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted models with Likelihood ratio test
library(lmtest)
lrtest(iguana.null, iguana.year, iguana.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = iguana.yearXtort)
plot(simulationOutput)
summary(iguana.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
ggpredict(iguana.yearXtort, terms = c("year", "tdencat"), 
          type = "fe", ci.lvl = 0.95)  %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) -> iguana.pred

# plot iguana density predictions
quadrant.plot <-
  ggplot(iguana.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + labs(x = "Year", y = "Iguana density (per ha)") +
  theme(legend.position = c(.8,.8), legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.plot
```

This model from the plot data tells that the total iguana population has not changed much from 2011 to present. Overall, the plots suggest a slight decline in the tortoise release zone after repatriation (in contrast to the distance sampling data). The distribution of iguanas may have shifted, with tortoises displacing some iguanas to other areas that were less occupied before. But the interaction between tortoise density and time was very weak.

### Cactus count GLMMs

Let's finally look at how cactus densities have changed over time with tortoises using the same model structure. Starting with *juvenile* cactus.

```{r}
# models
## null
cactus.null <-glmer(CJ ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CJ ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CJ ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
          type = "fe", ci.lvl = 0.95)  %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) -> cactus.pred


cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.cj.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes +
  labs(x = "Year", y = expression(Juveniles ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.cj.plot
```

Juvenile cactus counts have increased---almost tripled---before and after tortoise introduction. There is also a positive effect of tortoise density on juvenile cactus. Worth noticing that the high density tortoise areas seemed to have more cactus before there were any tortoise, which may just reflect the similar habitat selection strategies of iguanas at these different sites.

What about *subadult* cactus?

```{r}
# models
## null
cactus.null <-glmer(CS ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CS ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CS ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95)%>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) 

# plot iguana density predictions
quadrant.cs.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + 
  labs(x = "Year", y = expression(Subadults ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.cs.plot
```

Again we see an increase in subadult cactus. The effect here is weaker than for juveniles. No effect of tortoise density here.

What about **adult** cactus? We shouldn't see a noticeable change here.

```{r}
# models
## null
cactus.null <-glmer(CA ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CA ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CA ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.ca.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + 
  labs(x = "Year", y = expression(Adults ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.ca.plot
```

There is a slight decline in adult cactus counts from 2011 to 2020.

Let's look at *total* cactus change.

```{r}
# models
## null
cactus.null <-glmer(CT ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## year
cactus.year <- glmer(CT ~ year + (1|Plot), 
                    family = poisson, data = iguana.total)
## fitted
cactus.yearXtort <- glmer(CT ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.ct.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), 
                    name = "Tortoise density") +
  theme_classic() + mythemes + labs(x = "Year", y = expression(Total ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.ct.plot
```

Overall, we see an increase in cactus in the tortoise release zone on Santa Fe between 2011 and 2020. The overall change is independent of tortoise density variation, but as we saw before that variable is informative for certain cactus stages.

Let's pull all these cactus figures together.

```{r, fig.height = 6, fig.width = 8}
ggarrange(quadrant.cj.plot, quadrant.cs.plot, 
          quadrant.ca.plot, quadrant.ct.plot,
          nrow = 2, ncol = 2, labels = c("a", "b", "c", "d"), align = "hv",
          label.x = c(0.19, 0.19, 0.19, 0.19), common.legend = TRUE)
```


It may also be helpful to visualize changes in proportions of different age classes of cactus from 2011 to 2020.

```{r}
iguana.class.tab <-
  data.frame(year = rep(iguana.total$year, 3),
             iguana = c(iguana.total$CJ, iguana.total$CS, iguana.total$CA),
             type = c(rep("Juvenile", nrow(iguana.total)), 
                      rep("Subadult", nrow(iguana.total)),
                      rep("Adult", nrow(iguana.total))),
             total = rep(iguana.total$CT, 3))

iguana.class.tab %>%
  mutate(prop = iguana / total,
         type = factor(type, levels = c("Adult", "Subadult", "Juvenile"))) %>%
  group_by(type, year) %>%
  summarise(mean_prop = mean(prop),
            se_prop = sd(prop)/sqrt(n())) %>%
  ungroup() -> iguana.class.props 

cactus.prop.plot <-
  ggplot(iguana.class.props, aes(x = year, fill = type)) +
  geom_bar(aes(y = mean_prop), stat = "identity") +
  geom_text(aes(label = round(mean_prop,2), y = mean_prop), 
            position = position_stack(vjust = 0.5), size = 4) +
  scale_fill_manual(values = col2[c(2:4)], name = "Stage") +
  labs(x = "Year", y = "Proportion of cactus") + 
  theme_classic() + mythemes 

cactus.prop.plot
```


Future monitoring, especially a repeat of the full-island iguana survey, will be essential for describing iguana and cactus demographic change with the growing tortoise population.

\ 
\ 

# Session info
***
```{r}
sessionInfo()
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>