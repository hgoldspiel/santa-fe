---
title: "Ecological Outcomes of Tortoise Restoration on Santa Fe Island"
author: "Harrison B Goldspiel"
date: 'Last update: `r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    toc: true
    toc_float: true
    smooth_scroll: false
    css: "styles.css"
    theme: yeti
    code_folding: show
editor_options: 
  chunk_output_type: inline
bibliography: literature.bib
---

<style>
p.caption {
  font-size: 0.8em;
  font-style: italic;
}
</style>

```{r, setup, warning = FALSE, message = FALSE}
# clear working environment and set wd
rm(list=ls())
wd <- getwd()

library(knitr)
library(kableExtra)
knitr::opts_knit$set(root.dir = wd)
knitr::opts_chunk$set(fig.align = "center", fig.pos = "h", fig.path = 'figures/',
                      message = FALSE, warning = FALSE, dpi = 600)

#load some R packages
library(ggplot2)
library(ggalt)
library(ggthemes)
library(ggExtra)
library(lisa)
library(lubridate)
library(tidyverse)
library(reshape2)

# load custom functions and settings
source("custom_functions_settings.R", verbose = FALSE)
```
\  
\  
\  

**Summary**: This document provides a synthesis of initial demographic outcomes of the release of 551 captive bred Española tortoises on the island of Santa Fe in the Galapagos archipelago. I summarize the results from three separate analyses on the (1) growth, (2) survival, and (3) dispersal of these tortoises from 2015 to 2020.

```{r, tortoise-photo, echo = FALSE, out.width = "35%", out.height = "35%", fig.align = "center", fig.cap = "A juvenile Española tortoise on Santa Fe Island."}

include_graphics("images/tortoise.jpg")
```

I'll also examine potential impacts of tortoises on the Santa Fe land iguana population, the only major (extant) native herbivore on Santa Fe, as well as the endemic cactus population.

# Growth
***

## Body condition

First I'll load the Santa Fe tortoise data with body metrics and time intervals. 

```{r, load-data}
library(readxl)
# load recapture data
sf_recaps <- suppressMessages(read_excel(
  path = "data/tortoise_data_Mar_2020.xlsx",
  sheet = "Marcacion Recaptura Limpias", na = "NA",
  col_types = c("numeric", rep("text", 4), rep("numeric", 5), 
                rep("text", 4), rep("numeric", 12), rep("text", 3))))

head(sf_recaps)
```

We'll change some column names and create some extra survey variables. I'll clean everything in a long chunk (hidden, see the accompanying .Rmd file for the complete source code) and create a new object for examining growth patterns.

```{r, clean-Santa-Fe-tortoise-recapture-data-for-growth-GAMs, echo = FALSE}
# reformat recapture data
recaps_df <- data.frame(PIT_capture = sf_recaps$`Número de PIT`,
                        PIT_release = sf_recaps$`PIT DPNG liberado`,
                        PIT_final = sf_recaps$PIT_final,
                        Year = sf_recaps$`Año`, 
                        Month = sf_recaps$Mes, 
                        Day = sf_recaps$`Día`,
                        Latitude = sf_recaps$Latitud, Longitude = sf_recaps$Longitud,
                        LC_release = sf_recaps$LC_at_liberation,
                        Peso_release = sf_recaps$Peso_at_liberation,
                        Age_release = sf_recaps$age_at_liberation,
                        LC_capture = sf_recaps$`Largo Curvo (cm)`, 
                        Peso_capture = sf_recaps$`Peso (Kg)`, 
                        Age_capture = sf_recaps$age_at_recapture,
                        Cohort = as.factor(sf_recaps$Year_liberated))
# load release data
sf_release <- read_excel(path = "data/tortoise_data_Mar_2020.xlsx",
                         sheet = "Tortugas liberadas DPNG", na = "NA",
                         col_types = c(rep("text", 5), "numeric", "date", 
                                       rep("numeric", 3), "text", 
                                       rep("numeric", 6)))
# reformat release data
release_df <- data.frame(PIT_capture = sf_release$`No. con PIT`,
                         PIT_release = sf_release$`No. con PIT`,
                         PIT_final = sf_release$`No. con PIT (final)`,
                         Year = sf_release$`Year liberated`, 
                         Month = sf_release$`Month liberated`,
                         Day = sf_release$`Day liberated`,
                         Latitude = sf_release$Latitud, Longitude = sf_release$Longitud,
                         LC_release = sf_release$`Largo curvo (cm)`,
                         Peso_release = sf_release$`Peso (g)`/1000,
                         Age_release = sf_release$Age - 0.5,
                         LC_capture = sf_release$`Largo curvo (cm)`,
                         Peso_capture = sf_release$`Peso (g)`/1000,
                         Age_capture = sf_release$Age - 0.5,
                         Cohort = as.factor(sf_release$`Year liberated`))

# combine release and recapture data
santafe.data <- rbind(recaps_df, release_df)

# add unique row ID
santafe.data$unique_id <- c(1:nrow(santafe.data))

# add occasions
santafe.data$Occasion <- NA
santafe.data$Occasion[santafe.data$Year == 2015 & santafe.data$Month == 6] <- 1
santafe.data$Occasion[santafe.data$Year == 2015 & santafe.data$Month == 8] <- 2
santafe.data$Occasion[santafe.data$Year == 2016 & santafe.data$Month == 6] <- 3
santafe.data$Occasion[santafe.data$Year == 2017 & santafe.data$Month == 4] <- 4
santafe.data$Occasion[santafe.data$Year == 2017 & santafe.data$Month == 6] <- 5
santafe.data$Occasion[santafe.data$Year == 2018 & santafe.data$Month == 6] <- 6
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 2] <- 7
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 4] <- 8
santafe.data$Occasion[santafe.data$Year == 2019 & santafe.data$Month == 8] <- 9
santafe.data$Occasion[santafe.data$Year == 2020] <- 10

# add more exact liberation measurement dates
santafe.data$Year_firstmeasure <- santafe.data$Year
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2015"] <- 2015
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2017"] <- 2017
santafe.data$Year_firstmeasure[santafe.data$Cohort == "2019"] <- 2018
santafe.data$Month_firstmeasure <- santafe.data$Month
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2015"] <- 6
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2017"] <- 4
santafe.data$Month_firstmeasure[santafe.data$Cohort == "2019"] <- 12
santafe.data$Day_firstmeasure <- santafe.data$Day
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2015"] <- 27
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2017"] <- 17
santafe.data$Day_firstmeasure[santafe.data$Cohort == "2019"] <- 12

# create "LC class" variable
santafe.data$LC_class <- floor(santafe.data$LC_capture/10)*10

# calculate actual ages (to the nearest month) upon each capture
elapsed_months <- function(end_date, start_date) {
    ed <- as.POSIXlt(end_date)
    sd <- as.POSIXlt(start_date)
    12 * (ed$year - sd$year) + (ed$mon - sd$mon)
}

santafe.data$date_capture <- as.Date(paste(santafe.data$Year, 
                                           santafe.data$Month, 
                                           santafe.data$Day, 
                                           sep = "-"))

santafe.data$date_firstmeasure <- as.Date(paste(santafe.data$Year_firstmeasure, 
                                           santafe.data$Month_firstmeasure, 
                                           santafe.data$Day_firstmeasure, 
                                           sep = "-"))

santafe.data$dec.date <- decimal_date(santafe.data$date_capture)


santafe.data$Age_actual <- 
  santafe.data$Age_release + elapsed_months(santafe.data$date_capture,
                                            santafe.data$date_firstmeasure)/12

# let's impute the mean length and weight of 2019 tortoises at release for 982126055990440
santafe.data$LC_release[santafe.data$PIT_final == "982126055990440"] <- 
  mean(na.omit(santafe.data$LC_release[santafe.data$Cohort == "2019"]))
santafe.data$Peso_release[santafe.data$PIT_final == "982126055990440"] <-
  mean(na.omit(santafe.data$Peso_release[santafe.data$Cohort == "2019"]))
santafe.data$LC_capture[santafe.data$PIT_final == "982126055990440"] <-
  santafe.data$LC_release[santafe.data$PIT_final == "982126055990440"]
santafe.data$Peso_capture[santafe.data$PIT_final == "982126055990440"] <-
  santafe.data$Peso_release[santafe.data$PIT_final == "982126055990440"]

# let's omit all individuals without any release data
santafe.raw <- santafe.data[which(santafe.data$LC_release > 0),]
```

We have some measurement errors and potential outliers in the data. We'll label points as outliers according to a 3 * IQR rule, with quartiles specified separately along 2-cm length increments (for increments with 10 or more points). 

We might have to manually label some additional measurements as outliers if they fall in an increment with a small sample size but are clearly off the length versus weight curve. 

```{r, SF-morphology-outliers}
# get thresholds for extreme outliers (3 * IQR)
santafe.thresholds <- santafe.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  group_by(lc_cat_2) %>%
  summarise(Q3 = quantile(Peso_capture, 0.75, na.rm = T),
            Q1 = quantile(Peso_capture, 0.25, na.rm = T),
            IQR = Q3-Q1,
            upper = Q3+3*IQR,
            lower = Q1-3*IQR,
            n = n()) %>% ungroup()

# identify points beyond outlier thresholds
santafe.outliers <- santafe.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  left_join(santafe.thresholds, by = "lc_cat_2") %>%
  filter(Peso_capture > upper & n >= 10 | Peso_capture < lower & n >= 10 |
           Peso_capture > 1 & LC_capture < 20)

# number of Santa Fe outliers
nrow(santafe.outliers)

ggplot(santafe.raw, aes(x = LC_capture, y = Peso_capture)) + 
  geom_point(alpha = 0.3, shape = 16) + 
  geom_point(data = santafe.outliers, aes(x = LC_capture, y = Peso_capture), 
             colour="red", fill = "red", shape = 16) + 
  theme_classic() + mythemes
```

Let's omit those 71 outliers before modeling body condition and growth rates.

```{r, omit-santafe-outliers}
santafe.clean <- santafe.raw[santafe.raw$unique_id %notin% 
                               santafe.outliers$unique_id,]
santafe.clean$PIT_final <- as.factor(santafe.clean$PIT_final)
```

Here I'll model the simple relationship between body mass and size (curved carapace length) using generalized additive mixed models (GAMMs), including a random effect for tortoise ID (PIT tag). This will allow us to estimate a body condition function, while also accounting for the variation in individual morphology and growth patterns. We can do this in the `mgcv` package [@Wood2011].

```{r, body-condition-GAM-for-Santa-Fe-tortoises}
library(mgcv)
gam.largavpeso.sf <- bam(Peso_capture ~ s(LC_capture) + s(PIT_final, bs="re"), 
                         data = santafe.clean)
summary(gam.largavpeso.sf)
```

```{r, predicted-body-condition-of-SF-tortoises}
library(tidymv)
largavpeso.sf.plot <-  
  plot_smooths(model = gam.largavpeso.sf, series = LC_capture) + 
  geom_point(data = santafe.clean, 
             mapping = aes(x = LC_capture, y = Peso_capture, fill = Cohort,
                           color = Cohort, shape = Cohort), 
             position = "jitter", alpha = 0.7) + 
  geom_line(size = 0.5, col = "black") +
  labs(y = "Weight (kg)", x = "Curved carapace length (cm)") + 
  scale_shape_manual(values = c(21, 22, 24)) +
  scale_color_manual(values = c("indianred4", "dodgerblue4", "goldenrod")) +
  scale_fill_manual(values = c("indianred4", "dodgerblue4", "goldenrod")) + 
  theme(legend.position = "top") + theme_classic() + mythemes

largavpeso.sf.plot
```

It doesn't look like there is any between-cohort variation in body condition. All cohorts are evenly distributed along the fitted body condition curve.

We can explore this further by platting the residuals. Let's inspect a few things:

+ Residuals by release cohort
+ Residuals by time

```{r, SF-body-cond-res-plots}
body.res <-
  santafe.clean %>%
  filter(!is.na(LC_capture) & !is.na(Peso_capture)) %>%
  mutate(resid = gam.largavpeso.sf$residuals) %>%
  mutate(time_since_release = date_capture - date_firstmeasure,
         Cohort2 = as.factor(case_when(Cohort == "2015" ~ "Cohort 1",
                                       Cohort == "2017" ~ "Cohort 2",
                                       Cohort == "2019" ~ "Cohort 3")),
         release = ifelse(time_since_release == 0 | time_since_release == 77, 
                          "release", "recapture"),
         time_occ = case_when(Occasion == "1" ~ mean(dec.date[Occasion == "1"]),
                              Occasion == "2" ~ mean(dec.date[Occasion == "2"]),
                              Occasion == "3" ~ mean(dec.date[Occasion == "3"]),
                              Occasion == "4" ~ mean(dec.date[Occasion == "4"]),
                              Occasion == "5" ~ mean(dec.date[Occasion == "5"]),
                              Occasion == "6" ~ mean(dec.date[Occasion == "6"]),
                              Occasion == "7" ~ mean(dec.date[Occasion == "7"]),
                              Occasion == "8" ~ mean(dec.date[Occasion == "8"]),
                              Occasion == "9" ~ mean(dec.date[Occasion == "9"]),
                              Occasion == "10" ~ mean(dec.date[Occasion == "10"]
                                                      )))
                              
ggplot(body.res, aes(x = Cohort2, y = resid)) +
  geom_violin(fill = "midnightblue", color = "midnightblue") +
  geom_boxplot(width = 0.1) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  ylab("Body condition residual") + xlab("Cohort") +
  theme_classic() + mythemes

body.res %>%
  group_by(time_occ, Cohort2) %>%
  summarise(resid = mean(resid)) %>%
  ggplot() +    
  geom_hline(aes(yintercept = 0), lty = "dashed", alpha = 0.4) +
  geom_point(data = body.res, aes(x = time_occ, y = resid), 
             shape = 16, alpha = 0.1, col = "grey50", position = "jitter") +
  geom_point(aes(x = time_occ, y = resid), color = "red", shape = "-", size = 6) +
  facet_wrap(~Cohort2, nrow = 3) + 
  ylab("Body condition residual") + xlab("Capture date") +
  theme_classic() + mythemes -> bc.res.plot

bc.res.plot
```

There don't appear to be any differences in body condition between release cohorts. There also don't appear to be any trends in body condition over time, except for a recent uptick (heavier) in the last year.

Let's load the morphology data from tortoises on Española Island.

```{r, read-espanola-data}
espanola.data <- read.csv("data/espanola_tortoise_data.csv")

# add unique id column
espanola.data$unique_id <- c(1:nrow(espanola.data))
```

Let's examine the data for potential outliers as we did before with the Santa Fe tortoises. We'll constrain our Española data to be within the same age range of our Santa Fe tortoises. We'll also omit data from 1980 to 1991 for comparing body condition, as the weight measurements during those years were filled with measurement or data entry errors that cannot be resolved.

```{r, Espanola-outliers}
espanola.raw <- 
  espanola.data[espanola.data$Year %notin% c(1980:1991) &
                  espanola.data$Age_capture >= min(santafe.clean$Age_actual) &
                  espanola.data$Age_capture <= max(santafe.clean$Age_actual),]

espanola.thresholds <- espanola.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  group_by(lc_cat_2) %>%
  summarise(Q3 = quantile(Peso_capture, 0.75, na.rm = T),
            Q1 = quantile(Peso_capture, 0.25, na.rm = T),
            IQR = Q3-Q1,
            upper = Q3+3*IQR,
            lower = Q1-3*IQR,
            n = n()) %>% ungroup()

espanola.outliers <- espanola.raw %>%
  mutate(lc_cat_2 = floor_any(LC_capture, 2)) %>%
  left_join(espanola.thresholds, by = "lc_cat_2") %>%
  filter(Peso_capture > upper & n >= 10 | Peso_capture < lower & n <= 10)

nrow(espanola.outliers)

ggplot(espanola.raw, aes(x = LC_capture, y = Peso_capture)) + 
  geom_point(alpha = 0.3, shape = 16) +
  geom_point(data = espanola.outliers, aes(x=LC_capture, y = Peso_capture), 
             colour="red", fill = "red", shape = 16) + xlim(c(15,70)) +
  theme_classic() + mythemes
```

There are 27 captures here that we'll remove.

```{r}
espanola.clean <- 
  espanola.data[espanola.data$unique_id %notin% espanola.outliers$unique_id &
                  espanola.data$Year %notin% c(1980:1991) &
                  espanola.data$LC_capture < 70 &
                  espanola.data$Age_capture <= max(santafe.clean$Age_actual) &
                  espanola.data$Age_capture >= min(santafe.clean$Age_actual),]

espanola.clean <- espanola.clean[!is.na(espanola.clean$Year),]
```

Let's combine our cleaned Santa Fe and Española datasets to model both populations together and display the regional growth contrasts.

```{r}
espanola.clean$dec.date <- 
  decimal_date(as.Date(paste(espanola.clean$Year, 
                             espanola.clean$Month, 
                             espanola.clean$Year, 
                             sep = "-"), format = "%Y-%m-%d"))
espanola.clean$Age_actual <- espanola.clean$dec.date - espanola.clean$Birth_year
espanola.clean$mod.ID <- as.factor(espanola.clean$mod.ID)
espanola.clean$PIT <- as.factor(espanola.clean$PIT)

hood.data <- data.frame(
  dec.date = c(santafe.clean$dec.date, espanola.clean$dec.date),
  LC_capture = c(santafe.clean$LC_capture, espanola.clean$LC_capture),
  Peso_capture = c(santafe.clean$Peso_capture, espanola.clean$Peso_capture),
  Age_release = c(santafe.clean$Age_release, espanola.clean$Age_release),
  Age_capture = c(santafe.clean$Age_actual, espanola.clean$Age_actual),
  ID = as.factor(c(as.character(santafe.clean$PIT_final), 
                   as.character(espanola.clean$mod.ID))),
  Island = as.factor(c(rep("Santa Fe", nrow(santafe.clean)), 
                           rep("Española", nrow(espanola.clean)))))

# make island an ordered factor for the factor smooth interactions
hood.data$Island_ord <- ordered(hood.data$Island)

# summary of body condition data captures
hood.data %>%
  group_by(ID, Island) %>%
  summarise(n_raw = n()) %>%
  group_by(Island) %>%
  summarise(tortoises = length(unique(ID)),
            n = sum(n_raw),
            min_n = min(n_raw),
            mean_n = mean(n_raw),
            max_n = max(n_raw),
            sd_n = sd(n_raw)) %>% ungroup()
```

As one final preparation for our body condition and somatic growth GAMMs, we're going to link climate information (i.e., precipitation anomalies) to the captures in this dataset. Tortoise growth rates are affected by limits made on plant productivity due to seasonal rainfall patterns and climate extremes (https://doi.org/10.1016/C2018-0-01381-X: Charney 2021; Goldspiel & Gibbs, 2021), so we want to account for this stochasticity in growth variation when comparing morphological functions on Santa Fe to those on native Española.

We'll do this by converting daily precipitation records from the meteorological station at the Charles Darwin Research Station to a monthly standardized precipitation index (SPI) in the `SPEI` package [@Hayes2000]. We'll use a five-month lag period when making the index, which roughly corresponds to the length of the core wet season on Santa Fe Island. Finally, we'll link the five-month SPI series to each tortoise capture by calculating a 12-month rolling average for each capture date (i.e., tortoise growth as a function of climate variation in the last year).

```{r}
gal.clim <- read.csv("data/pa_cdf_climate.csv")
gal.clim$date <- as.Date(gal.clim$observation_date, format = "%m/%d/%Y")
gal.clim$yr_month <- format(gal.clim$date, "%Y-%m")

## get potential evapotranspiration
gal.clim$pet_turc <- 
  0.013*(gal.clim$mean_air_temp/(gal.clim$mean_air_temp+15))*((100/4.1868)+50)

## get monthly temp values
gal.clim.month.mean <- 
  gal.clim %>%
  group_by(yr_month) %>%
  summarise(mean_temp = mean(mean_air_temp, na.rm = T),
            mean_min_temp = mean(min_air_temp, na.rm = T),
            mean_max_temp = mean(max_air_temp, na.rm = T),
            mean_humidity = mean(humidity, na.rm = T),
            tot_precip = sum(precipitation, na.rm = T),
            dec.date = decimal_date(mean(date)))

## new data frame of dates and spi5 values
library(SPEI)
cdf.spi <- 
  data.frame(
    yr_month = gal.clim.month.mean$yr_month[5:nrow(gal.clim.month.mean)],
    dec.date = gal.clim.month.mean$dec.date[5:nrow(gal.clim.month.mean)],
    tot_prec = gal.clim.month.mean$tot_precip[5:nrow(gal.clim.month.mean)],
    spi5 = spi(gal.clim.month.mean$tot_precip,5)$fitted[5:nrow(gal.clim.month.mean),])

## create lagged SPI values to connect to body condition data (1 year rolling average)
library(zoo)
cdf.spi$spi5_1yr = rollmean(cdf.spi$spi5, 12, align = "right", fill = NA)

find.spi.lag <- function(cap.date) {
  return(cdf.spi$spi5_1yr[which.min(abs(cdf.spi$dec.date - cap.date))])
  }

hood.data <- hood.data %>%
  mutate(spi5_1yr = map_dbl(dec.date, find.spi.lag))
```


Let's now model the relationship between length and weight and compare that body condition function to the Santa Fe tortoise data. We'll do this explicitly in one model by including “island” as an independent variable (i.e., as an ordered factor smooth interaction and a separate fixed effect---see @Pedersen2019).

```{r, SF-and-Espanola-body-condition-scatterplot}
hood.bc.gam <- bam(Peso_capture ~ 
                     Island + 
                     s(LC_capture) +
                     s(LC_capture, by = Island_ord) + 
                     s(spi5_1yr) +
                     s(ID, bs = "re"), data = hood.data)

summary(hood.bc.gam)

# create length sequence for prediction
larga.sim = c(rep(seq(min(santafe.clean$LC_capture), 
                max(santafe.clean$LC_capture), length.out = 100), 2))

# create sequence of islands for prediction
island.sim = c(rep("Santa Fe", 100), rep("Española", 100))

# create new data frame with model covariates for prediction
newdat = data.frame(LC_capture = larga.sim, 
                    Island_ord = island.sim, 
                    Island = island.sim,
                    spi5_1yr = 0)

# predict average curves for both locations
hood.bc.pred <- predict.gam(hood.bc.gam, newdata = newdat,
                            exclude = "s(ID)", newdata.guaranteed = TRUE, 
                            type = "response", se.fit=TRUE)

# put predicted values and error in new data frame for plotting
hood.bc <- data.frame(cbind(island.sim), 
                      as.numeric(as.character(larga.sim)), 
                      as.numeric(as.character(hood.bc.pred$fit)),
                      as.numeric(as.character(hood.bc.pred$se.fit)))
colnames(hood.bc) <- c("Island", "larga", "peso", "SE")

# plot
hood.bc.plot <- ggplot(hood.bc, 
                       aes(x = larga, y = peso, color = Island, fill = Island)) + 
  geom_ribbon(aes(ymin = peso - 1.96*SE, ymax = peso + 1.96*SE), 
              color = "transparent", alpha = 0.2) +
  geom_point(inherit.aes = FALSE, 
             data = hood.data[hood.data$Island == "Santa Fe",], 
             mapping = aes(x = LC_capture, y = Peso_capture), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#00BFC4") + 
  geom_point(inherit.aes = FALSE, 
             data = hood.data[hood.data$Island == "Española",], 
             mapping = aes(x = LC_capture, y = Peso_capture), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#F8766D") + 
  geom_line(size = 1.1) +
  scale_color_manual(values = c("indianred4", "dodgerblue4")) + 
  scale_fill_manual(values = c("indianred4", "dodgerblue4")) +
  labs(y = "Weight (kg)", x = "Curved carapace length (cm)") + 
  theme_classic() + mythemes + theme(legend.position = "bottom") + 
  xlim(min(santafe.clean$LC_capture), max(santafe.clean$LC_capture)) + 
  ylim(c(0,22))

hood.bc.plot
```

It looks like the Santa Fe and Española tortoise populations are showing similar morphological patterns. There is a slight divergence in body condition that begins at about 40 cm, where tortoises on Santa Fe are a bit heavier for a given size than those on Española.

Let's export our body condition model table to a csv file.

```{r}
bc.model.summary <- summary(hood.bc.gam)
write.csv(bc.model.summary$p.table, "data/bc_mod_parametric.csv")
write.csv(bc.model.summary$s.table, "data/bc_mod_smooth.csv")
```

Let's look at the data just one other way with box plots.

```{r, SF-and-Espanola-body-condition-boxplot}
hood.data$LC_class <- as.factor(floor_any(hood.data$LC_capture, 10))

ggplot(na.omit(hood.data[hood.data$LC_class == "20" | 
                           hood.data$LC_class == "30" |
                           hood.data$LC_class == "40" | 
                           hood.data$LC_class == "50",]), 
       aes(x = LC_class, y = Peso_capture, color = Island)) +
  geom_boxplot(outlier.alpha = 0.5, outlier.shape = 16) + 
  labs(y = "Weight (kg)", x = "Curved carapace length class (cm)") +
  scale_color_manual(values = c("indianred4", "dodgerblue4")) +
  guides(color = guide_legend(title = "Island")) + 
  theme_classic() + mythemes + 
  theme(legend.position = "bottom")
```

These boxplots indicate that any small divergence in body condition specified by the GAM, is likely negligible.

## Somatic growth rates

Let's now compare the actual somatic growth rates for tortoises on Santa Fe and Española, using intermediate length as a predictor. 

I'll follow a few protocols to make our Santa Fe and Española data more comparable and limit data errors: (1) I omit all growth intervals less than 1 year or greater than 5 years (the latter being the amount of time elapsed since tortoises were introduced to Santa Fe); (2) I apply some filtering rules to omit some questionable measurements that are likely products of data recording and entering errors; and (3) I truncate tabulated growth rates at negative and positive extremes of -2.5 cm / yr and 10 cm / yr.

```{r, tabulate-growth-data}
# first get reduced data frame with:
## (1) just individuals captured at least twice, and 
## (2) containing size data
growth.input <- hood.data %>%
  filter(is.na(LC_capture) == FALSE) %>%
  group_by(Island, ID) %>%
  filter(n() > 1) %>%
  mutate(cap_date = dec.date) %>%
  arrange(cap_date) %>%
  ungroup() %>%
  mutate(unique_id = c(1:length(dec.date))) %>% 
  as.data.frame()

# function to calculate growth rates
growth.tabulate <- function(data){
  ## CLEANING LOOP
  clean_data <- NULL
  # nest by island
  for(Island in unique(data$Island)){
    # nest by tortoise ID
    for(ID in unique(data$ID[data$Island %in% Island])){
      tdata <- data[data$Island %in% Island & data$ID %in% ID,]
      final_cap = last(tdata$unique_id)
      current_cap = 1
      while(current_cap != final_cap){
        for(cap in 2:nrow(tdata)){
          current_cap = tdata$unique_id[cap]
          if(
            # If recap is too soon after the previous capture...
            tdata$cap_date[cap] - tdata$cap_date[cap-1] < 1 |
            # or shrinks
            tdata$LC_capture[cap] / tdata$LC_capture[cap-1] < 0.95 |
            # or grows quicker than 10 cm / yr
            (tdata$LC_capture[cap] - tdata$LC_capture[cap-1]) / 
            (tdata$cap_date[cap] - tdata$cap_date[cap-1]) > 10) {
            # remove cap 
            tdata <- tdata[-cap,]
            break
          }
        }
      }
      clean_data <- bind_rows(clean_data, tdata)
    }
  }
  #### CALCULATE GROWTH RATES FOR REMAINING INTERVALS ####
  growth_data <- NULL
  clean_data <- clean_data %>%
    group_by(Island, ID) %>%
    filter(n() > 1) %>% ungroup() %>%
    as.data.frame()
  # construct rows for growth dataset from clean data
  for(Island in unique(clean_data$Island)){
    # nest by tortoise ID
    for(ID in unique(clean_data$ID[clean_data$Island %in% Island])){
      tdata <- clean_data[clean_data$Island %in% Island & clean_data$ID %in% ID,]
      for(cap in 2:nrow(tdata)){
        new.df <- data.frame(
          # island
          Island = Island,
          # ID of tortoise
          ID = ID,
          # capture date
          cap_year = tdata$cap_date[cap-1],
          # recapture date
          recap_year = tdata$cap_date[cap],
          # time between captures
          years_between = tdata$cap_date[cap] - tdata$cap_date[cap-1],
          # mid-year between captures
          midyear = mean(c(tdata$cap_date[cap], tdata$cap_date[cap-1])),
          # original length
          cap_lc = tdata$LC_capture[cap-1],
          # recapture length
          recap_lc = tdata$LC_capture[cap],
          # size difference between captures
          delta_lc = tdata$LC_capture[cap] - tdata$LC_capture[cap-1],
          # mid-size between captures
          mid_lc = mean(c(tdata$LC_capture[cap], tdata$LC_capture[cap-1])),
          # mid age
          mid_age = mean(c(tdata$Age_capture[cap], tdata$Age_capture[cap-1])),
          # growth rate
          growth_cm_yr = (tdata$LC_capture[cap] - tdata$LC_capture[cap-1])/
            (tdata$cap_date[cap] - tdata$cap_date[cap-1]),
          spi5 = mean(cdf.spi$spi5[cdf.spi$dec.date >= tdata$cap_date[cap-1] &
                                    cdf.spi$dec.date < tdata$cap_date[cap]]),
          stringsAsFactors = FALSE)
        growth_data <- bind_rows(growth_data, new.df)
      }
    }
  }
  return(growth_data)
}

# run growth function
growth.output <- growth.tabulate(growth.input)

# filter out additional growth intervals
growth.dat <- growth.output %>%
  filter(years_between <= 5) %>%
  mutate(ID = as.factor(ID),
         Island = as.factor(Island),
         growth_rate_pc = p.rank(growth_cm_yr),
         growth_rate_final = growth_cm_yr,
         growth_rate_final = ifelse(growth_cm_yr <= -2.5 | 
                                      growth_cm_yr >= 10, NA, growth_rate_final))
```

Let's take a quick look at a summary of our growth dataset.

```{r, growth-dat-summary}
mean.growth.rates <- 
  growth.dat %>%
  group_by(Island) %>%
  summarise(mean_growth = mean(growth_rate_final),
            sd_growth = sd(growth_rate_final))

growth.dat %>%
  group_by(ID, Island) %>%
  summarise(n_raw = n()) %>%
  group_by(Island) %>%
  summarise(tortoises = length(unique(ID)),
            n = sum(n_raw),
            min_n = min(n_raw),
            mean_n = mean(n_raw),
            max_n = max(n_raw),
            sd_n = sd(n_raw)) %>%
  left_join(mean.growth.rates, by = "Island") %>%
  mutate(se = sd_growth/sqrt(n)) %>%
  ungroup()
```

Okay now let's run a somatic growth model for just Santa Fe. In this instance, our variable for climate variation represents the mean precipitation anomaly (SPI-5) value over each capture interval for each individual.

```{r, Santa-Fe-somatic-growth-rates-GAMM}
santafe.growth.dat <- growth.dat %>%
  filter(Island == "Santa Fe") %>%
  droplevels()

santafe.growth.gam <- bam(growth_rate_final ~ 
                            s(mid_lc) + 
                            s(spi5) +
                            s(ID, bs="re"), 
                          data = santafe.growth.dat)

summary(santafe.growth.gam)
```

```{r, predicted-somatic-growth-rates-of-SF-tortoises}
larga.sim = seq(min(na.omit(santafe.growth.dat$mid_lc)), 
                max(na.omit(santafe.growth.dat$mid_lc)), length.out = 100)

# santa fe prediction
newdat <- data.frame(mid_lc = larga.sim, spi5 = 0)
santafe.pred <- predict.gam(santafe.growth.gam, newdata = newdat, 
                            exclude = "s(ID)", newdata.guaranteed = TRUE,
                            type = "response", se.fit=TRUE)
santafe.pred <- data.frame(cbind(larga.sim, santafe.pred$fit, 
                                 santafe.pred$se.fit))
colnames(santafe.pred) <- c("larga", "rate", "SE")

### PLOT ###
santafe.growth.plot <-  ggplot(santafe.pred, aes(x = larga, y = rate)) + 
  geom_point(inherit.aes = FALSE, data = santafe.growth.dat, 
             mapping = aes(x = mid_lc, y = growth_cm_yr), 
             position = "jitter", alpha = 0.1) + geom_line(size = 1.1) + 
  geom_line(aes(y=rate - 2*SE), linetype = "dashed") + 
  geom_line(aes(y=rate + 2*SE), linetype = "dashed") + 
  geom_line(mapping = aes(y = 0), linetype = "dashed", col = "black") + 
  labs(y = expression(paste("Growth rate (cm yr"^{-1},")")), 
       x = "Intermediate curved carapace length (cm)") + 
  theme_classic() + mythemes +
  scale_shape_manual(values=c(2,1)) + ylim(-2.5, 10)

santafe.growth.plot 
```

The Santa Fe tortoises are growing steadily, with rates plateauing at just over 4 cm / yr once they reach 35 cm in length. 

Let's examine the residuals over time.

```{r, santa-fe-growth-residuals}
santafe.cohorts <- santafe.raw %>%
  group_by(PIT_final) %>%
  summarise(ID = unique(PIT_final),
            Cohort = unique(Cohort))

growth.res <-
  santafe.growth.dat %>%
  filter(!is.na(growth_rate_final)) %>%
  mutate(resid = santafe.growth.gam$residuals) %>%
  left_join(santafe.cohorts, by = "ID") %>%
  mutate(Cohort2 = case_when(Cohort == "2015" ~ "1 (2015)",
                             Cohort == "2017" ~ "2 (2017)",
                             Cohort == "2019" ~ "3 (2019"))

growth.res.plot <- 
  ggplot(growth.res, aes(x = midyear, y = resid)) +
  geom_point(shape = 16, alpha = 0.2) + 
  scale_y_continuous(breaks = c(-3,0,3)) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  ylab("Growth residual") + xlab("Intermediate capture date") +
  theme_classic() + mythemes

growth.res.plot
```

There doesn't appear to be any residual trend over time, indicating that growth rates have been stable for the Santa Fe tortoise population since release.

Let's compare Santa Fe and Española growth rates in the same model.

```{r, hoodensis-somatic-growth-GAMM}
growth.dat$Island_ord = ordered(growth.dat$Island)

hood.growth.gam <- bam(growth_rate_final ~ 
                         Island + 
                         s(mid_lc) + 
                         s(mid_lc, by = Island_ord) + 
                         s(spi5) +
                         s(ID, bs="re"), data = growth.dat)

summary(hood.growth.gam)
```

There is a difference in growth rates between the two populations. Santa Fe seems to have slightly lower growth rates.

Let's export this model table to a csv.

```{r}
growth.model.summary <- summary(hood.growth.gam)
write.csv(growth.model.summary$p.table, "data/growth_mod_parametric.csv")
write.csv(growth.model.summary$s.table, "data/growth_mod_smooth.csv")
```

Now let's plot out the predicted growth rates for each population to see how they may differ.

```{r, predicted-hoodensis-growth-rates}
age.sim = rep(c(seq(min(na.omit(growth.dat$mid_age)), 
                max(na.omit(growth.dat$mid_age)), length.out = 100)),2)

length.sim = c(seq(min(growth.dat$mid_lc[growth.dat$Island == "Santa Fe"]), 
                max(growth.dat$mid_lc[growth.dat$Island == "Santa Fe"]), 
                length.out = 100),
              seq(min(growth.dat$mid_lc[growth.dat$Island == "Española"]), 
                max(growth.dat$mid_lc[growth.dat$Island == "Española"]), 
                length.out = 100))

newdat = data.frame(mid_lc = length.sim,
                    Island = as.factor(c(rep("Santa Fe", 100), 
                                         rep("Española", 100))),
                    Island_ord = as.factor(c(rep("Santa Fe", 100), 
                                             rep("Española", 100))),
                    spi5 = 0)

hood.pred <- predict.gam(hood.growth.gam, newdata = newdat, 
                         newdata.guaranteed = TRUE,
                             exclude = "s(ID)", type = "response", se.fit=TRUE)
hood.pred <- data.frame(length = length.sim, 
                        Island = c(rep("Santa Fe", 100), rep("Española", 100)), 
                        rate = hood.pred$fit, 
                        SE = hood.pred$se.fit)

hood.growth.plot <- ggplot(hood.pred, 
                           aes(x = length, y = rate, 
                               fill = Island, color = Island)) + 
  geom_point(inherit.aes = FALSE, 
             data = growth.dat[growth.dat$Island == "Santa Fe",], 
             mapping = aes(x = mid_lc, y = growth_rate_final), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#00BFC4") + 
  geom_point(inherit.aes = FALSE, 
             data = growth.dat[growth.dat$Island == "Española",], 
             mapping = aes(x = mid_lc, y = growth_rate_final), 
             position = "jitter", shape = 16, alpha = 0.2, col = "#F8766D") + 
  geom_ribbon(aes(ymin = rate - 1.96*SE, ymax = rate + 1.96*SE), 
              color = "transparent", alpha = 0.2) +
  geom_line(size = 1.1) + 
  scale_color_manual(values = c("indianred4", "dodgerblue4")) +
  scale_fill_manual(values = c("indianred4", "dodgerblue4")) +
  labs(y = expression(paste("Growth rate (cm yr"^{-1},")")), 
       x = "Intermediate length (cm)") + theme_classic() + mythemes +
  ylim(0, 7.5) + theme(legend.position = "bottom")

hood.growth.plot
```
There are in fact some differences in the growth rates between tortoises on Santa Fe and Española. The Santa Fe tortoises begin with slower growth rates than those on Española. This could possibly be explained by the harsher environment on Santa Fe. Juvenile tortoises may have more limited foraging opportunities during the day in the hot season because of there is less cover. Release ages could also play a role, as Santa Fe tortoises were on average older upon release than Española tortoises. Tortoises may require a few years to acclimate to their environment after being repatriated.

After they exceed about 40 cm in length, the Santa Fe tortoises begin to grow faster than their counterparts on Española. This would make sense, considering the greater food resources on Santa Fe. There might simply be more food for them to eat. Still, the confidence intervals overlap for most of these population-level growth functions.

Let's create a composite growth figure.

```{r, composite-growth-fig, fig.height = 7, fig.width = 7}
library(ggpubr)

growth.fig <- 
  ggarrange(hood.bc.plot, hood.growth.plot,
            nrow = 2, common.legend = TRUE, legend = "top",
            labels = c("a", "b"), label.x = c(0.1, 0.1))

growth.fig
```

# Survival
***
## Model preparation

Here we'll use capture-mark-recapture population models (i.e., Cormack-Jolly-Seber or CJS models) [@Cormack1964; @Estimates2013; @Seber1965] to get an estimate of survival rates of the three release cohorts of tortoises on Santa Fe. I'll implement these models in Program MARK [@White1999] via the `RMark` package.

First we need to reformat the mark-recapture data to create individual encounter histories for program MARK.

```{r, prepare-survival-data-for-RMark}
library(reshape2)
## Aggregate by tag/mark ID to create annual encounter histories
santafe.ch <- santafe.raw %>%
  dplyr::select(c("PIT_final", "Occasion", "LC_capture", "Age_actual", 
                  "Age_release", "LC_release", "Peso_release", "Cohort")) %>%
  mutate(PIT = as.factor(PIT_final),
         Cohort = as.factor(Cohort)) %>%
  group_by(PIT, Occasion, Cohort) %>%
  summarise_all(mean) %>%
  dcast(PIT + Age_release + LC_release + Peso_release + Cohort ~ Occasion) %>%
  mutate_at(c(as.character(1:10)), ~ifelse(is.na(.), 0, 1)) %>%
  ungroup()
  
colnames(santafe.ch) <- c("PIT", "age_release", "length", "weight", 
                          "release_cohort",  "T0", "T0_17", "T1", "T1_83",
                          "T2", "T3", "T3_67", "T3_84", "T4_17", "T4_75")

# aggregate encounter history and reorder columns for input to MARK
santafe.ch <- 
  data.frame(ch = paste(santafe.ch$T0, santafe.ch$T0_17, santafe.ch$T1, 
                        santafe.ch$T1_83, santafe.ch$T2, santafe.ch$T3,
                        santafe.ch$T3_67, santafe.ch$T3_84,
                        santafe.ch$T4_17, santafe.ch$T4_75, sep = ""), 
             santafe.ch[,c(2:5)])

## write as a .txt file 
write.table(santafe.ch, "data/santafe_ch.txt", sep = "\t", col.names = TRUE, 
            row.names = FALSE, quote=FALSE)
```

We'll use that text file that I just exported to set up the input data.

```{r, set up input data for CJS}
library(RMark)
tortoises <- import.chdata("data/santafe_ch.txt", header = TRUE, 
                               field.types=c("n", "n", "n", "f")) 

effortcov <- data.frame(read.csv("data/tortoise_survey_effort.csv"))
```

Survey effort represents "person-days" for each survey occasion.

Now we'll process the input data for CJS. Because there were uneven time intervals between tortoise surveys we'll have to be careful here and specify the exact amount of time (in decimal years) between surveys for the models to estimates annual survival properly.

```{r, process-data-for-juvenile-CJS}
# make process data
tortoises$age_release <- as.factor(tortoises$age_release)
tortoises.process <- 
  process.data(tortoises,model="CJS",begin.time=0,
               time.intervals=c(0.17, 0.83, 0.83, 0.17, 
                                1.00, 0.67, 0.17, 0.33, 0.58), 
               groups = c("release_cohort", "age_release"), age.var = 2,
               initial.ages = c(4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5))
 
kable(tortoises.process$data, "html", 
      caption = "Tortoise capture data in Santa Fe") %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")
```
<br>

Now we'll make the design data for CJS. We have to fix two parameters--detection for the 2015 cohort of tortoises in April of 2017 and detection for the 2015 and 2017 cohorts in February of 2019. The new cohorts of tortoises were released then, but no surveys were conducted. So we need MARK to know that detection for the older cohorts in those time periods was zero.

```{r, make-design-data-for-juvenile-CJS}
# make CJS ddl
tortoises.ddl <- make.design.data(tortoises.process)

# merge effort data
tortoises.ddl$p <- merge_design.covariates(tortoises.ddl$p,effortcov, bytime = TRUE)

# fix detection for the 2015 cohort in occasion 4 (time 1.83) when no sampling occured
tortoises.ddl$p$fix <- NA
tortoises.ddl$p$fix[tortoises.ddl$p$time == "1.83" & 
                      tortoises.ddl$p$release_cohort == "2015"] <- 0

# fix detection for the 2015 & 2017 cohorts in occassion 7 (time 3.67) when no sampling occured
tortoises.ddl$p$fix[tortoises.ddl$p$time == "3.67" &
                      c(tortoises.ddl$p$release_cohort == "2015" |
                          tortoises.ddl$p$release_cohort == "2017")] <- 0

# design data PIMS
kable(tortoises.ddl[[1]][], "html", 
      caption = "PIMS for Phi (survival) parameter") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")

kable(tortoises.ddl[[2]][], "html", 
      caption = "PIMS for p (detection) parameter") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")
```
<br>

Now let's build models. We'll consider four possible survival models in which survival varies temporally, by release size, or release cohort. We'll also consider whether detection varies by year, tortoise size, or effort.

We'll run all combinations of these models as well as nulls---`Phi(.)` and `p(.)`---for a total of 16 CJS models.

```{r, make-models-for-CJS}
# apparent survival (Phi)
Phi.dot = list(formula=~1)
Phi.time = list(formula=~time)
Phi.length = list(formula=~length)
Phi.cohort = list(formula=~release_cohort)

# detection (p)
p.dot = list(formula=~1)
p.time = list(formula=~time)
p.effort = list(formula=~effort)
p.length = list(formula=~length)
```

Let's first examine goodness of fit for our data before ranking models.

```{r, GoF-for-adult-CJS}
set.seed(1)
RGOF <- release.gof(tortoises.process)
RGOF
chat <- RGOF$Chi.square[3]/RGOF$df[3]
chat
```

There is no lack of model fit. We'll still account for slight overdispersion with c-hat.

## Model outcomes

```{r, run-CJS-models, results = FALSE, warning = FALSE, comment = FALSE, message = FALSE}
# make and model list
tortoises.list <- create.model.list("CJS")

tortoises.results <- mark.wrapper(tortoises.list,
                                  data=tortoises.process,
                                  ddl=tortoises.ddl,
                                  output = FALSE)

tortoises.results <- adjust.chat(chat, tortoises.results)
```

```{r, print-QAICc-table-for-juvenile-CJS-models}
aic.table.tortoises <- model.table(tortoises.results, 
                                   use.lnl = TRUE, use.AIC = TRUE)
aic.table.tortoises$model <- gsub("~", "", aic.table.tortoises$model)
aic.table.tortoises$model <- gsub("1", ".", aic.table.tortoises$model)
aic.table.tortoises$model <- gsub(")", ") ", aic.table.tortoises$model)

kable(aic.table.tortoises[,3:8], "html", 
      caption = "AIC tortoise model rankings", digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  scroll_box(height = "300px")

write.csv(aic.table.tortoises[,3:8], "data/santafe_CJS_aictab_2020.csv")
```
<br>

It doesn't look like any variable strongly influences survival, as the top survival model is the null mode---Phi(.). There is some strong evidence for time-varying detection, but not much support for effort as a driver of detection variability.

Let's look at what the top model says about apparent survival.

```{r, apparent-survival-estimates-from-top-model}
# beta estimates
kable(tortoises.results$Phi.dot.p.time$results$beta, "html", 
      caption = "Beta estimates of Phi(.)p(time)") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
# real estimates
kable(tortoises.results$Phi.dot.p.time$results$real, "html", 
      caption = "Real estimates of Phi(.)p(time)") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

The model states there is an overall annual survival rate of 0.947.

Because there was model uncertainty, we should still model average our survival estimates to get probabilities for each year for plotting later on.

```{r, model-averaging-for-CJS-models}
set.seed(101)
# survival
tortoises.mod.avg.phi <- model.average(tortoises.results,"Phi", 
                                       vcv=TRUE, drop = FALSE)
tortoises.mod.avg.phi.unique <- unique(tortoises.mod.avg.phi$estimates[,2:5])

kable(tortoises.mod.avg.phi.unique, "html", 
      caption = "Model-averaged Phi estimates") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")

# detection
# remove the fully time dependent model: Phi(time)p(time)
# so we can estimate the variance for detection in the last occasion
tortoises.results.omit <- remove.mark(tortoises.results, 16)
tortoises.mod.avg.p <- model.average(tortoises.results.omit, "p", 
                                     vcv=TRUE, drop = FALSE)
tortoises.mod.avg.p.unique <- unique(tortoises.mod.avg.p$estimates[,2:5])

kable(tortoises.mod.avg.p.unique, "html", 
      caption = "Model-averaged p estimates") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

Let's use the overall survival estimates from the first model to get a quick estimate of abundance, using the following calculations. 

```{r, total-population-estimates}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi + 191*phi^(2/12)
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi + 155*phi^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020 <- N_2019 * phi^(8/12) + 34

# get the lower and upper confidence intervals
# lower 95% CL
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr + 191*lwr^(2/12)
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr + 155*lwr^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020_lwr <- N_2019_lwr * lwr^(8/12) + 34

# upper 95% CL
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr + 191*upr^(2/12)
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr + 155*upr^(4/12)
# add the final 34 individuals that were added in December of 2019
N_2020_upr <- N_2019_upr * upr^(8/12) + 34

santafe_pop_15_20 <- 
  data.frame(Year = c("2015", "2016", "2017", "2018", "2019", "2020"),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

kable(santafe_pop_15_20, 
      caption = "Population estimates (2015-2020) of the 
      tortoises released on Santa Fe.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```
<br>

Let's also track the estimated population size of each cohort individually.

```{r, cohort-specific-population-size-estimates, echo = FALSE}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

# 2015 cohort
N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi 
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(9/12)
# get the lower and upper confidence intervals
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr
N_2020_lwr <- N_2019_lwr * phi^(9/12)
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr
N_2020_upr <- N_2019_upr * phi^(9/12)
# pull together into one table
cohort_2015_pop <- 
  data.frame(Year = c("Release (June 2015)", "2016", 
                      "2017", "2018", "2019", "2020 (March)"),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

# 2017 cohort
N_2017 <- 191
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(11/12)
# get the lower and upper confidence intervals
N_2017_lwr <- 191
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr 
N_2020_lwr <- N_2019_lwr * lwr^(11/12)
N_2017_upr <- 191
N_2018_upr <- N_2017_upr * upr 
N_2019_upr <- N_2018_upr * upr 
N_2020_upr <- N_2019_upr * upr^(11/12)
# pull together into one table
cohort_2017_pop <- 
  data.frame(Year = c("Release (Apr 2017)", "2018", "2019", "2020 (March)"),
             N = c(N_2017, N_2018, N_2019, N_2020),
             lcl = c(N_2017_lwr, N_2018_lwr, N_2019_lwr, N_2020_lwr),
             ucl = c(N_2017_upr, N_2018_upr, N_2019_upr, N_2020_upr))

# 2019 cohort
N_2019_rel <- 155
N_2020 <- N_2019_rel * phi^(13/12)
# get the lower and upper confidence intervals
N_2019_rel_lwr <- 155
N_2020_lwr <- N_2019_rel_lwr * lwr^(13/12)
N_2019_rel_upr <- 155
N_2020_upr <- N_2019_rel_upr * upr^(13/12)
# pull together into one table
cohort_2019_pop <- data.frame(Year = c("Release (Feb 2019)", "2020 (March)"),
                              N = c(N_2019_rel, N_2020),
                              lcl = c(N_2019_rel_lwr, N_2020_lwr),
                              ucl = c(N_2019_rel_upr, N_2020_upr))
# pull all cohort tables into one composite table for Santa Fe
cohort_pops <- rbind(cohort_2015_pop, cohort_2017_pop, cohort_2019_pop)

row.specs = "background-color: #666; color: #fff;"
kable(cohort_pops, 
      caption = "Population estimates of tortoises on Santa Fe (2015-2020).") %>%
  pack_rows("First release cohort (2015)", 1, 6, label_row_css = row.specs) %>%
  pack_rows("Second release cohort (2017)", 7, 10, label_row_css = row.specs) %>%
  pack_rows("Third release cohort (2019)", 11, 12, label_row_css = row.specs) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

```{r, get-population-size-estimates-for-plotting, echo = FALSE}
phi <- tortoises.results$Phi.dot.p.time$results$real[1,1]
lwr <- tortoises.results$Phi.dot.p.time$results$real[1,3]
upr <- tortoises.results$Phi.dot.p.time$results$real[1,4]

N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017pre <- N_2016 * phi^(10/12)
N_2017release <- N_2017pre + 191 
N_2018 <- N_2017release * phi^(14/12)
N_2019pre <- N_2018 * phi^(8/12)
N_2019release <- N_2019pre + 155
N_2019 <- N_2019release * phi^(4/12)
N_2020 <- N_2019 * phi^(8/12)

# get the lower and upper confidence intervals
## lwr
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017pre_lwr <- N_2016_lwr * lwr^(10/12)
N_2017release_lwr <- N_2017pre_lwr + 191
N_2018_lwr <- N_2017release * lwr^(14/12)
N_2019pre_lwr <- N_2018_lwr * lwr^(8/12)
N_2019release_lwr <- N_2019pre_lwr + 155
N_2019_lwr <- N_2019release_lwr * phi^(4/12)
N_2020_lwr <- N_2019_lwr * phi^(8/12)

## upr
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017pre_upr <- N_2016_upr * upr^(10/12)
N_2017release_upr <- N_2017pre_upr + 191
N_2018_upr <- N_2017release * upr^(14/12)
N_2019pre_upr <- N_2018_upr * upr^(8/12)
N_2019release_upr <- N_2019pre_upr + 155
N_2019_upr <- N_2019release_upr * phi^(4/12)
N_2020_upr <- N_2019_upr * phi^(8/12)

N_dates <- 
  decimal_date(as.Date(c("2015-06-01", "2015-06-01", "2016-06-01", "2017-04-01", 
                         "2017-04-01", "2018-06-01", "2019-02-01", "2019-02-01", 
                         "2019-06-01", "2020-03-01"), 
                       format = "%Y-%m-%d"))

total_pop <- 
  data.frame(Year = N_dates,
             N_cum = c(0,205,205,205,396,396,396,551,551,551),
             N_hat = c(0,N_2015, N_2016, N_2017pre, N_2017release, 
                       N_2018, N_2019pre, N_2019release, N_2019, N_2020),
             lwr = c(0,N_2015_lwr,N_2016_lwr, N_2017pre_lwr, N_2017release_lwr, 
                     N_2018_lwr, N_2019pre_lwr, N_2019release_lwr, 
                     N_2019_lwr, N_2020_lwr),
             upr = c(0,N_2015_upr,N_2016_upr, N_2017pre_upr, N_2017release_upr, 
                     N_2018_upr, N_2019pre_upr, N_2019release_upr, 
                     N_2019_upr, N_2020_upr))

# 2015 cohort
N_2015 <- 205
N_2016 <- N_2015 * phi
N_2017 <- N_2016 * phi 
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(9/12)

# get the lower and upper confidence intervals
N_2015_lwr <- 205
N_2016_lwr <- N_2015_lwr * lwr
N_2017_lwr <- N_2016_lwr * lwr
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr
N_2020_lwr <- N_2019_lwr * phi^(9/12)
N_2015_upr <- 205
N_2016_upr <- N_2015_upr * upr
N_2017_upr <- N_2016_upr * upr
N_2018_upr <- N_2017_upr * upr
N_2019_upr <- N_2018_upr * upr
N_2020_upr <- N_2019_upr * phi^(9/12)

cohort_2015_pop <- 
  data.frame(Year = c(1,2,3,4,5,5.75),
             N = c(N_2015,N_2016, N_2017, N_2018, N_2019, N_2020),
             lwr = c(N_2015_lwr,N_2016_lwr, N_2017_lwr, 
                     N_2018_lwr, N_2019_lwr, N_2020_lwr),
             upr = c(N_2015_upr,N_2016_upr, N_2017_upr, 
                     N_2018_upr, N_2019_upr, N_2020_upr))

# 2017 cohort
N_2017 <- 191
N_2018 <- N_2017 * phi 
N_2019 <- N_2018 * phi 
N_2020 <- N_2019 * phi^(11/12)
# get the lower and upper confidence intervals
N_2017_lwr <- 191
N_2018_lwr <- N_2017_lwr * lwr 
N_2019_lwr <- N_2018_lwr * lwr 
N_2020_lwr <- N_2019_lwr * lwr^(11/12)
N_2017_upr <- 191
N_2018_upr <- N_2017_upr * upr 
N_2019_upr <- N_2018_upr * upr 
N_2020_upr <- N_2019_upr * upr^(11/12)

cohort_2017_pop <- 
  data.frame(Year = c(2.83,3.83,4.83,5.75),
             N = c(N_2017, N_2018, N_2019, N_2020),
             lwr = c(N_2017_lwr, N_2018_lwr, N_2019_lwr, N_2020_lwr),
             upr = c(N_2017_upr, N_2018_upr, N_2019_upr, N_2020_upr))


# 2019 cohort
N_2019_rel <- 155
N_2020 <- N_2019_rel * phi^(13/12)
# get the lower and upper confidence intervals
N_2019_rel_lwr <- 155
N_2020_lwr <- N_2019_rel_lwr * lwr^(13/12)
N_2019_rel_upr <- 155
N_2020_upr <- N_2019_rel_upr * upr^(13/12)

cohort_2019_pop <- data.frame(Year = c(4.67,5.75),
                              N = c(N_2019_rel, N_2020),
                              lwr = c(N_2019_rel_lwr, N_2020_lwr),
                              upr = c(N_2019_rel_upr, N_2020_upr))


cohort_pops <- rbind(cohort_2015_pop, cohort_2017_pop, cohort_2019_pop)
cohort_pops$cohort <- c(rep("2015",6), rep("2017",4), rep("2019",2))
```

Let's put these estimates of survival, detection, and population size together in a single figure.

```{r}
# create the df for plotting population parameter estimates
tortoises.mod.avg.phi.unique$cohort <- 
  c(rep("2015",9), rep("2017",9), rep("2019", 9))

tortoises.mod.avg.phi.unique$year <- 
  c(rep(c(2015,2015,2016,2017,2017,2018,2019,2019,2019),3))

tortoises.phi.df <- tortoises.mod.avg.phi.unique %>%
  filter(lcl > 0.01) %>% # remove the final 2019 survival estimate with inflated variances
  group_by(year) %>%
  summarise(phi = mean(estimate),
            se = mean(se),
            lcl = mean(lcl),
            ucl = mean(ucl)) %>%
  ungroup() %>%
  mutate(time = c(2015.5, 2016.5, 2017.5, 2018.5, 2019.5))

det.df <- tortoises.mod.avg.p.unique[c(1:2,4:8),] %>%
  mutate(year = decimal_date(as.Date(c("2015-08-01", "2016-06-01", 
                                       "2017-06-01", "2018-06-01",
                                       "2019-04-01", "2019-08-01", 
                                       "2020-03-01"), 
                                     format = "%Y-%m-%d")))

scaleFUN <- function(x) sprintf("%.2f", x)

espanola.phi <- data.frame(stage = c("juvenile", "subadult/adult"),
                           phi = c(0.931, 0.979),
                           lcl = c(0.902, 0.927),
                           ucl = c(0.951, 0.992))

santafe.phi.plot <- 
  ggplot(tortoises.phi.df,  aes(x = time, y = phi)) +
  geom_hline(data = espanola.phi, inherit.aes = FALSE, 
             aes(yintercept = phi), 
             lty = "dashed", lwd = 1.1, col = "grey") +
  geom_pointrange(aes(ymin = lcl, ymax = ucl), 
                  shape = 21, fill = "black", fatten = 3, 
                  color = "black", size = 1.1, stroke = 1.3) +
  labs(y = expression(paste("Apparent survival ( ", phi, " )")), x = "Year") + 
  scale_y_continuous(limits = c(floor_any(min(tortoises.phi.df$lcl),0.05), 1), 
                     labels = scaleFUN) + 
  xlim(2015,2020.5) + 
  theme(legend.position = "top") + 
  annotate("text", x = 2020.15, y = 0.94, 
           label = "juvenile", size = 4, col = "black") +
  annotate("text", x = 2020.15, y = 0.99, 
           label = "(sub)adult", size = 4, col = "black") + 
  theme_classic() + mythemes

santafe.phi.plot
  
santafe.p.plot <- 
  ggplot(det.df, aes(x = year, y = estimate)) +  geom_line() + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl), 
                  shape = 21, fill = "black", fatten = 3, 
                  color = "black", size = 1.1, stroke = 1.3) +
  geom_hline(aes(yintercept = mean(det.df$estimate)), lty = "dashed") +
  ylab("Detection probability") + xlab("Year") +
  scale_y_continuous(limits = c(0.3,1), labels = scaleFUN) +
  xlim(2015,2020.5) + theme_classic() + mythemes

santafe.p.plot

santafe.n.plot <- 
  ggplot(data = total_pop) +
  geom_line(aes(x = Year, y = N_cum), color = "black") +
  geom_line(aes(x = Year, y = N_hat), color = "black") +
  geom_ribbon(aes(x = Year, ymin = lwr, ymax = upr), alpha = 0.5) +
  annotate("text", 
           x = decimal_date(as.Date("2015-06-01", format = "%Y-%m-%d")), 
           y = 205+34, label = "Release 1", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2017-04-01", format = "%Y-%m-%d")),  
           y = 396+34, label = "Release 2", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2019-02-01", format = "%Y-%m-%d")),
           y = 551+34, label = "Release 3", size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-25", format = "%Y-%m-%d")),
           y = 551, label = 551, size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-25", format = "%Y-%m-%d")),
           y = last(total_pop$N_hat), 
           label = round(last(total_pop$N_hat),0), size = 4) +
  annotate("text", 
           x = decimal_date(as.Date("2020-05-01", format = "%Y-%m-%d")),
           y = last(total_pop$N_hat) * 0.88, 
           label = paste("(",round(last(total_pop$N_hat)/551*100,1),"%",")", 
                         sep = ""), size = 4) +
  ylab("Population size") + xlab("Year") +
  xlim(2015,2020.5) + ylim(0,600) + theme_classic() + mythemes

santafe.n.plot
```

```{r, hoodensis-demographic-outcomes, fig.height = 7, fig.width = 9}
# combine survival, abundance, and morphology figures into a 2x2 composite
ggarrange(santafe.phi.plot + ggtitle("a"),
          santafe.n.plot + ggtitle("b"), 
          hood.bc.plot + ggtitle("c"),
          hood.growth.plot + ggtitle("d"),
          legend = "bottom", common.legend = TRUE)
```

# Population projections
***

We'll make deterministic and stochastic population projections in the R package `popbio.` These will be **female-only** models, making the assumption that approximately half of all tortoise eggs become female.

Let's first create our four-stage Lefkovitch matrices.

```{r}
library(popbio)
# hatching viability parameter estimates and quantiles from kevin'a ABC
egghatchvia <- c(0.3447368, 0.2305263, 0.2636842, 0.3005263, 0.3078947, 
                 0.3447368, 0.3815789, 0.4184211, 0.418421, 0.4184211)

names(egghatchvia) <- c("mean", "p025", "p05", "p10", "p25", 
                        "p50", "p75", "p90", "p95", "p975")

# starting female population in 2020
n_2020 <- c(0, 0, round(last(total_pop$N_hat)/2), 20)

# vital rates
propfem <- 0.5 # proportion of population that is female
repro <- 17 # reproductive age

# survivorship from egg to juvenile (age 1) (from Kevin's Espnola ABC)
G1 <- egghatchvia["mean"] 
G1_lwr <- egghatchvia["p025"]
G1_upr <- egghatchvia["p975"]
# annual survival, phi (1-4 yrs)
s1 <- 0.75 
s1_lwr <- 0.6
s1_upr <- 0.9
# young juvenile stage survival parameter for matrix
P1 <- ((1-s1^(3-1))/(1-s1^3))*s1
P1_lwr <- ((1-s1_lwr^(3-1))/(1-s1_lwr^3))*s1_lwr
P1_upr <- ((1-s1_upr^(3-1))/(1-s1_upr^3))*s1_upr
# juvenile/subadult survival (4-17 yrs) (Santa Fe rates)
s2 <- tortoises.results$Phi.dot.p.time$results$real$estimate[1]
s2_lwr <- tortoises.results$Phi.dot.p.time$results$real$lcl[1]
s2_upr <- tortoises.results$Phi.dot.p.time$results$real$ucl[1]
# juvenile/subadult stage survival parameter for matrix
P2 <- ((1-s2^(13-1))/(1-s2^13))*s2
P2_lwr <- ((1-s2_lwr^(13-1))/(1-s2_lwr^13))*s2_lwr
P2_upr <- ((1-s2_upr^(13-1))/(1-s2_upr^13))*s2_upr
# survivorship from 1 to 4 (using the range from Gibbs et al. 2014)
G2 <- round(s1^3*(1-s1)/(1-s1^3),3) 
G2_lwr <- round(s1_lwr^3*(1-s1_lwr)/(1-s1_lwr^3),3)
G2_upr <- round(s1_upr^3*(1-s1_upr)/(1-s1_upr^3),3)
# survivorship from 4 to 17 (using the subadult/adult survival rates from Espanola)
G3 <- round(s2^13*(1-s2)/(1-s2^13),3) 
G3_lwr <- round(s2_lwr^13*(1-s2_lwr)/(1-s2_lwr^13),3)
G3_upr <- round(s2_upr^13*(1-s2_upr)/(1-s2_upr^13),3)
# annual survival for adult stage, phi (8 + years old)
P3 <- 0.979 
P3_lwr <- 0.927
P3_upr <- 0.992
# mean annual number of female eggs produced (Gibbs et al. 2014) 
F1 <- 7*propfem*P3
F1_lwr <- 4*propfem*P3_lwr
F1_upr <- 10*propfem*P3_upr

# make matrices
stages <- c("egg/hatchling", "young juvenile", "juvenile/subadult", "adult")
tortoise.matrix <- matrix(c(0, 0, 0, F1,
                            G1, P1, 0, 0,
                            0, G2, P2, 0,
                            0, 0, G3, P3),
                          nrow = 4, ncol = 4, byrow = T)
tortoise.matrix.lwr <- matrix(c(0, 0, 0, F1_lwr,
                                G1_lwr, P1_lwr, 0, 0,
                                0, G2_lwr, P2_lwr, 0,
                                0, 0, G3_lwr, P3_lwr),
                              nrow = 4, ncol = 4, byrow = T)
tortoise.matrix.upr <- matrix(c(0, 0, 0, F1_upr,
                                G1_upr, P1_upr, 0, 0,
                                0, G2_upr, P2_upr, 0,
                                0, 0, G3_upr, P3_upr),
                              nrow = 4, ncol = 4, byrow = T)
```

Now let's run the deterministic projection to extract stable stage proportions and population growth rates.

We will project the Santa Fe population from 2020 to 2100.

```{r deterministic-projection}
set.seed(123)

it <- 81 # time steps for model

# deterministic model
tortoise.proj <- pop.projection(tortoise.matrix, n_2020, it)
tortoise.proj.lwr <- pop.projection(tortoise.matrix.lwr, n_2020, it)
tortoise.proj.upr <- pop.projection(tortoise.matrix.upr, n_2020, it)

proj.df <- data.frame(Year = c(2020:2100), 
                      N_projected = tortoise.proj$stage.vectors[4,],
                      N_proj_lwr = tortoise.proj.lwr$stage.vectors[4,],
                      N_proj_upr = tortoise.proj.upr$stage.vectors[4,])

# time to saturation (K = 1500 female tortoises)
min(proj.df$Year[proj.df$N_projected >= 1500]) # max year at saturation
min(proj.df$Year[proj.df$N_proj_upr >= 1500]) # earliest year at saturation
    
# plot projection (without density dependence)
ggplot(proj.df, aes(Year, N_projected)) + geom_line(col = "blue", lwd = 1.1) + 
  geom_line(aes(x = Year, y = N_proj_lwr), col = "grey10") +
  geom_line(aes(x = Year, y = N_proj_upr), col = "grey10") +
  theme_classic() + xlim(2020, 2050) + ylim(0,1500)

# minimum adult population size
min(proj.df[,2:4]) 
# population growth rate
tortoise.proj$lambda 
tortoise.proj.lwr$lambda
tortoise.proj.upr$lambda
# stable stages 
tortoise.proj$stable.stage 
tortoise.proj.lwr$stable.stage 
tortoise.proj.upr$stable.stage 
# generation time
generation.time(tortoise.matrix)
generation.time(tortoise.matrix.lwr)
generation.time(tortoise.matrix.upr)
```

Without any other constraints on the tortoise population, these vital rates should ensure long-term persistence without future releases. Growth rates are very high, and the stable stage proportion for adult is between 0.1--0.2.

Now let's create our stochastic model.

```{r stochastic-projection-final-pop}
# stochastic projection (with density dependence)
tortoise.matrices <- list(tortoise.matrix, tortoise.matrix.lwr, 
                          tortoise.matrix.upr)
# nmax = K = K for Santa Fe (3000) divided by 2 times the stable stage prop. for adults
tortoise.proj.stoch <- 
  stoch.projection(matrices = tortoise.matrices,
                   n0 = n_2020, 
                   tmax = it, 
                   nreps = 10000,
                   prob = c(0.68, 0.16, 0.16),
                   nmax = 1500/tortoise.proj$stable.stage[4])

final.fem.pop <- tortoise.proj.stoch[,4]
hist(final.fem.pop, main = "Santa Fe adult female pop. in 2100", 
     xlab = "N adults")
abline(v = mean(final.fem.pop), col = "red", lwd = 2)
```

Almost all of our stochastic projections end with a female adult population > 1000 individuals. The mean projection for 2100 is just below 1500.

Let's run the stochastic projection again, but this time we'll put the projections in a for loop that will let us get population size estimates at each time step so we can plot out the projected female population from 2020 to 2100.

```{r, stochastic-projection-trends}
extin=c()
popQuant = matrix(NA, 3, 82)
popQuant[,1] = rep(sum(n_2020), 3)
popMean	= vector('numeric', 82)
popMean[1] = sum(n_2020)
popSD	= vector('numeric', 82)
popSD[1] = NA

for(i in 1:81){
  matriz=c()
  interactionX=10000
  quasi=75
  popExtinctProject <- 
    stoch.projection(matrices=tortoise.matrices, n0=n_2020, tmax=i, 
                     nmax = 1500/tortoise.proj$stable.stage[4], 
                     nreps = interactionX, 
                     prob = c(0.68, 0.16, 0.16), verbose=FALSE)
  for(ii in 1:interactionX){
    a <- popExtinctProject[ii,4]
    matriz <- rbind(matriz,c(a))
  }
  vv <- matriz[matriz<quasi]
  s <- length(vv)
  extin <- c(extin,s)
  
  popQuant[,i+1] <- quantile(popExtinctProject[,4], probs=c(0.025, 0.5, 0.975))
  popMean[i+1] <- mean(popExtinctProject[,4])
  popSD[i+1] <- sd(popExtinctProject[,4])
}

stoch.proj.df <- data.frame(Year = c(2020:2100), 
                            N_projected = c(n_2020[4],popMean[2:81]),
                            N_proj_med = c(n_2020[4],popQuant[2,2:81]),
                            N_proj_lwr = c(n_2020[4],popQuant[1,2:81]),
                            N_proj_upr = c(n_2020[4],popQuant[3,2:81]))

# table of stochastic projections (annual means across iterations)
kable(stoch.proj.df) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>% 
  scroll_box(height = "300px")

# plot projection (with density dependence)
stoch.pop.plot <- ggplot(stoch.proj.df, aes(Year, N_projected)) + 
  geom_ribbon(aes(ymin = N_proj_lwr, ymax = N_proj_upr), 
              fill = "grey", alpha = 0.7) +
  geom_line(lwd = 1.1) + ylab("Female population (adults)") +
  theme_classic() + mythemes

stoch.pop.plot

# quasiextinction probs
plot(extin/interactionX, type='l', lwd=2, xlab="Years into the future", 
     main="Extinction probability for Santa Fe population")

# pop growth rate
popSGR <- stoch.growth.rate(tortoise.matrices, 
                            verbose=F,
                            prob = c(0.68, 0.16, 0.16))

lambdaCI <- list()
lambdaCI$approx	<- exp(popSGR$approx)
lambdaCI$sim <- exp(popSGR$sim)
lambdaCI$sim.CI	<- exp(popSGR$sim.CI)
cat('lambda\n')
print(lambdaCI)
```

These projections obviously do not take into account environmental stochasticity that affects tortoise vital rates (e.g., drought, ENSO cycles, temperature change, shifting sex ratios). Those information would help improve the accuracy of these projections, setting them in a more realistic future context with ongoing global change.

Let's attach this projection figure to our other survival and abundance figures.

```{r, population-parameter-plot, fig.height = 6, fig.width = 10}
library(cowplot)
ggdraw() +
  draw_plot(santafe.phi.plot, x = 0, y = 0.5, width = 0.5, height = 0.5) +
  draw_plot(santafe.p.plot, x = 0.5, y = 0.5, width = 0.5, height = 0.5) +
  draw_plot(santafe.n.plot, x = 0, y = 0, width = 0.5, height = 0.5) +
  draw_plot(stoch.pop.plot, x = 0.5, y = 0, width = 0.5, height = 0.5) +
  draw_plot_label(label = c("a", "b", "c", "d"), size = 15,
                  x = c(0.08, 0.58, 0.08, 0.58), y = c(1, 1, 0.5, 0.5))
```

# Dispersal
***
## Data preparation

To assess dispersal I used the coordinates from individual tortoise capture records on Santa Fe from 2015 to 2020.

```{r, read-dispersal-data}
# rename santa fe data frame, remove rows without location data
movements <- santafe.data[is.na(santafe.data$Latitude) == FALSE,]
movements$Date <- paste(movements$Month, movements$Day, movements$Year, 
                        sep = "/")
movements$Date <- as.Date(movements$Date,format='%m/%d/%Y')
```

We should add one more column to the data frame---**Days_ellapsed**---to describe the time since release for each observation. But because there are three release dates, we really need three distinct groups of values for that column specific to their release cohorts.

```{r, process-dispersal-dates-and-export-to-GIS}
# create shapefile
movements2015 <- subset(movements, Cohort == "2015")
movements2017 <- subset(movements, Cohort == "2017")
movements2019 <- subset(movements, Cohort == "2019")
movementsNA <- subset(movements, is.na(Cohort))
movements2015$Days_ellapsed <- julian(movements2015$Date, 
                                      origin = as.Date("2015-06-27"))
movements2017$Days_ellapsed <- julian(movements2017$Date, 
                                      origin = as.Date("2017-04-17"))
movements2019$Days_ellapsed <- julian(movements2019$Date, 
                                      origin = as.Date("2019-02-27"))
movementsNA$Days_ellapsed <- NA
# combine them into one dataset again
movements <- rbind(movements2015, movements2017, movements2019, movementsNA)
```

Let's now convert our coordinates to UTMs, calculate the distance of each point from the original release point, and make some simple plots of the study area and tortoise locations. 

I'll start by only showing the 2015 release cohort over time. Then I'll produce the same plots including the 2017 cohort. I also need to update the UTM coordinates for the Santa Fe island shapefile so they are on the same scale as the tortoise points (relative to a central release point of 0,0).

```{r}
library(sp)
library(rgdal)
library(raster)
# create shapefile
coordinates(object = movements) <- ~ Longitude + Latitude
proj4string(movements) <- CRS("+proj=longlat +datum=WGS84")
movements.shp <- spTransform(movements, CRSobj = CRS("+init=epsg:32715"))
movements.shp$X <- movements.shp@coords[,"Longitude"]
movements.shp$Y <- movements.shp@coords[,"Latitude"]
# Here I create new X and Y UTM fields that make coordinates relative to 
# the release point (0,0). 
# This will make it easier to quickly assess dispersal distances in the maps, 
# by centering the release point at 0,0.
movements.shp$X_corrected <- movements.shp$X - 827253
movements.shp$Y_corrected <- movements.shp$Y - 9909160
movements.data <- as.data.frame(movements.shp)
# reformat the occasion column as factor
movements.data <- movements.data %>%
  mutate(occ = as.factor(Occasion),
         occ = recode(occ, "1" = "June 2015", "2" = "August 2015", 
                      "3" = "June 2016", "4" = "April 2017", "5" = "June 2017", 
                      "6" = "June 2018", "7" = "February 2019", 
                      "8" = "April 2019", "9" = "August 2019", 
                      "10" = "March 2020")) %>% as.data.frame()
```

## Spatial patterns - recapture data

```{r, load-santa-fe-outline-and-put-on-same-spatial-scale-as-tortoise-data}
santafe.shp <- readOGR("data/Santa_Fe.shp", verbose=FALSE)
santafe.shp <- spTransform(santafe.shp, CRS("+init=epsg:32715"))
santafe <- fortify(santafe.shp)
santafe$X <- santafe$long - 827253
santafe$Y <- santafe$lat - 9909160
```

Here is the code to make dispersal maps for specific occasions and cohorts. I'll make plots for the first release cohorts and the total population.

First let's look at the general distribution, showing tortoise locations at each occasion with overlayed 95% confidence ellipses.

```{r, dispersal-scatterplots-first-cohort, fig.height=10, fig.width=12}
library(ggsn)
disp.scatter <- function(data, occasion, cohort){
  ggplot(data = data[data$occ == occasion & data$Cohort == cohort,], 
         aes(x = X_corrected, y = Y_corrected)) +
    geom_polygon(inherit.aes = FALSE, data = santafe, 
                 aes(x = santafe$X, y = santafe$Y), fill = "grey") +
    geom_point(shape = 16, alpha = 0.5) +
    geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
               shape = 4, size = 1, stroke = 1.5, color = "red") +
    stat_ellipse(aes(x = X_corrected, y = Y_corrected), color = "blue", 
                 level = 0.95, lwd = 0.9) +
    theme_classic() + mythemes + coord_equal() + theme(legend.position="none") + 
    labs(x = "Distance from release (m)", y = "Distance from release (m)") +
    annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
    annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)
}

stat.ellipse.area <- function(plot){
 # Get ellipse coordinates from plot 
 # (from StackOverflow: https://tinyurl.com/yaulv58n)
  pb = ggplot_build(plot)
  el = pb$data[[4]][c("x","y")]
  # Center of ellipse
  ctr = MASS::cov.trob(el)$center 
  # Calculate distance to center from each point on the ellipse
  dist2center <- sqrt(rowSums((t(t(el)-ctr))^2))
  # Calculate area of ellipse from semi-major and semi-minor axes. 
  # These are, respectively, the largest and smallest values of dist2center. 
  return(pi*min(dist2center)*max(dist2center)/10000) # area in hectares of ellipse
}

p1 <- disp.scatter(movements.data, "June 2016", "2015")
p2 <- disp.scatter(movements.data, "June 2017", "2015")
p3 <- disp.scatter(movements.data, "June 2018", "2015")
p4 <- disp.scatter(movements.data, "August 2019", "2015")

# first cohort spread
first.cohort.spread <- data.frame(
  year = c(2016:2019),
  area = c(stat.ellipse.area(p1),stat.ellipse.area(p2),
           stat.ellipse.area(p3),stat.ellipse.area(p4)),
  prop.island = c(stat.ellipse.area(p1)/2473,stat.ellipse.area(p2)/2473,
                  stat.ellipse.area(p3)/2473,stat.ellipse.area(p4)/2473)
)

p1 <- p1 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[1], 1), " ha (",
                         round(first.cohort.spread$prop.island[1]*100, 1), "%)", 
                         sep = ""), size = 5)
p2 <- p2 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[2], 1), " ha (",
                         round(first.cohort.spread$prop.island[2]*100, 1), "%)", 
                         sep = ""), size = 5)
p3 <- p3 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[3], 1), " ha (",
                         round(first.cohort.spread$prop.island[3]*100, 1), "%)", 
                         sep = ""), size = 5)
p4 <- p4 + 
  annotate("text", x = 0, y = 1800, 
           label = paste(round(first.cohort.spread$area[4], 1), " ha (",
                         round(first.cohort.spread$prop.island[4]*100, 1), "%)", 
                         sep = ""), size = 5)

plot_grid(p1, p2, p3, p4,
          ncol  = 2, 
          labels = c("1 year", "2 years", "3 years", "4 years"), 
          label_size = 20)
```

The first cohort is slowly spreading over the center of the island and seems to be doubling in area almost every year since release.

Let's see what these movements look like for the 2015 cohort when you connect the observations of individual tortoises over time as traces.

```{r, traces-first-cohort, fig.cap = "Individual tortoise dispersal routes from first release cohort on Santa Fe island (2015-2020)"}
traces1 <- ggplot() +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(data = movements.data[movements.data$Cohort == "2015",], 
            aes(x = X_corrected, 
                y = Y_corrected, group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "2015 cohort (4.5 years)", subtitle = "", caption = "") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

traces1
```

Let's now look at all the traces of all cohorts together.

```{r, traces-all-cohorts, fig.cap = "Individual tortoise dispersal routes on Santa Fe island (2015-2020)"}
all.traces <-
  ggplot(data = movements.data,
                  aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(aes(group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() +
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)+
  theme(plot.margin = unit(c(0,0,0,0), "mm"))

all.traces
```


Interesting how tortoise movement has not been one directional. Many tortoises make large outward movements after release, only to return close to the center of the island on another occasion. These are only snapshots, so we really can't say much about tortoise movement or dispersal from these traces, other than that some tortoises seem to be exploratory in these initial post-release movements.

Finally, let's look at dispersal ellipses for the whole tortoise population from the last survey occasion in 2020. 

```{r, final-distribution-scatterplot-with-cohort-ellipses, fig.cap = "Distribution of tortoise cohorts on Santa Fe, as of March 2020."}
p.final.cohorts <-   
  ggplot(data = movements.data[movements.data$occ == "March 2020" & 
                                   !is.na(movements.data$Cohort),], 
         aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(inherit.aes = FALSE, data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_point(shape = 16, alpha = 0.5) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  stat_ellipse(aes(x = X_corrected, y = Y_corrected, color = Cohort),
               level = 0.95, lwd = 0.9) + 
  scale_y_continuous(limits = c(-2100, 3100), breaks = seq(-2000, 2000, 1000)) +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + mythemes + coord_equal() + theme(legend.position="top") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  theme(plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))

# Get ellipse coordinates from plot 
# (from StackOverflow: https://tinyurl.com/yaulv58n)
pb <- ggplot_build(p.final.cohorts)
cohort.areas <- NULL
for(group in unique(pb$data[[4]]$group)){
  el = pb$data[[4]]
  el.group = el[el$group == group,]
  el.group.xy = el.group[c("x","y")]
  # Center of ellipse
  ctr = MASS::cov.trob(el.group.xy)$center 
  # Calculate distance to center from each point on the ellipse
  dist2center <- sqrt(rowSums((t(t(el.group.xy)-ctr))^2))
  # Calculate area of ellipse from semi-major and semi-minor axes. 
  # These are, respectively, the largest and smallest values of dist2center. 
  area_ha <- pi*min(dist2center)*max(dist2center)/10000
  dat <- data.frame(cohort = group,
                    color = el.group$colour,
                    area_ha = area_ha,
                    area_perc = area_ha/2473 * 100,
                    stringsAsFactors = FALSE)
  cohort.areas <- bind_rows(cohort.areas, dat)
}

p.final.cohorts1 <- 
  p.final.cohorts + 
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15) +
  annotate("text", x = -2500, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "1"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "1"], 
                               2), "%)", sep = ""), size = 4, 
           color = cohort.areas$color[cohort.areas$cohort == "1"]) +
  annotate("text", x = 0, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "2"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "2"], 
                               2), "%)", sep = ""), size = 4,
            color = cohort.areas$color[cohort.areas$cohort == "2"]) +
  annotate("text", x = 2500, y = 3000, 
           label = paste(round(cohort.areas$area_ha[cohort.areas$cohort == "3"], 
                               1), " ha (",
                         round(cohort.areas$area_perc[cohort.areas$cohort == "3"], 
                               2), "%)", sep = ""), size = 4,
            color = cohort.areas$color[cohort.areas$cohort == "3"]) +
  theme(plot.margin = unit(c(0,0,0,0), "mm"))

p.final.cohorts1
```

These final distributions seem to reinforce the "doubling" seen in the first cohort's dispersal distances over time. The first cohort is distributed over an area roughly twice the size of the second cohort, which is also roughly twice as widespread as the third cohort.

What about the ellipse for the whole population in 2020?

```{r, final-distribution-scatterplot-total-ellipse}
p.final <- 
  ggplot(data = movements.data[movements.data$occ == "March 2020",], 
         aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(inherit.aes = FALSE, data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_point(shape = 16, alpha = 0.5) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 1, stroke = 1.5, color = "red") +
  stat_ellipse(aes(x = X_corrected, y = Y_corrected),
               level = 0.95, lwd = 0.9, color = "blue") +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  theme_classic() + mythemes + coord_equal() + theme(legend.position="top") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

p.final + annotate("text", x = 0, y = 1800, 
                   label = paste(round(stat.ellipse.area(p.final), 1), 
                                 " ha (",
                                 round(stat.ellipse.area(p.final)/2473*100, 1), 
                                 "%)", 
                                 sep = ""), size = 5)
```

Let's now examine how tortoise distributions vary over time with kernel density maps.

```{r}
library(spatstat)
# create a spatstat spatial planar point pattern (ppp) object
tortoises.ppp <- as(movements.shp, "ppp")
santafe.owin <- as.owin(santafe.shp)

# merge the points to the island boundary
tortoises.santafe <- tortoises.ppp[santafe.owin]
tortoises.santafe$marks <- tortoises.santafe$marks %>%
  mutate(occ = as.factor(Occasion),
         occ = recode(occ, "1" = "June 2015", "2" = "August 2015", 
                      "3" = "June 2016", "4" = "April 2017", "5" = "June 2017", 
                      "6" = "June 2018", "7" = "February 2019", 
                      "8" = "April 2019", "9" = "August 2019", 
                      "10" = "March 2020")) %>% as.data.frame()
```

Here I calculate kernel density of tortoises on Santa Fe, at six time events (August 2015, June 2016, June 2017, June 2018, August 2019, and March 2020). These maps are kind of like heat maps: brighter colors/higher values indicate greater tortoise densities. 

Because detection is imperfect, density estimates will be imperfect based on the raw capture locations. So I'll multiply the resulting density rasters by the time-specific detection value obtained by our top CJS model for each survey occasion.

```{r, kernel-density-trends-total-pop, fig.height=5, fig.width=10}
# kernel density function
den.fun <- function(ppp, res){
  den.list <- list()
  ras.list <- list()
  for(occasion in c("August 2015", "June 2016", "June 2017", 
                    "June 2018", "August 2019", "March 2020")){
    # get kernel density surface
    t <- subset.ppp(ppp, occ == occasion)
    t <- rescale(t, 100)
    den <- density.ppp(t, diggle = TRUE, sigma = bw.ppl, eps = 1)
    den$xcol <- den$xcol*100
    den$yrow <- den$yrow*100
    den$xrange <- den$xrange*100
    den$yrange <- den$yrange*100
    # convert spatstat images to raster
    ras <- raster(den)
    crs(ras) <- CRS("+init=epsg:32715")
    # add objects to lists
    den.list[[occasion]] <- den
    ras.list[[occasion]] <- ras
  }
  return(list(density = den.list, raster = ras.list))
}

den.list <- den.fun(ppp = tortoises.santafe)
tortoise.brick.raw <- brick(den.list$raster)
values(tortoise.brick.raw)[values(tortoise.brick.raw) < 0] <- 0
tortoise.brick.adj <- tortoise.brick.raw
tortoise.brick.adj.lcl <- tortoise.brick.raw
tortoise.brick.adj.ucl <- tortoise.brick.raw

# correct density for detection probability
det.seq <- list()
det.seq[["est"]] <- det.df$estimate[c(1:4,6:7)]
det.seq[["lcl"]] <- det.df$ucl[c(1:4,6:7)]
det.seq[["ucl"]] <- det.df$lcl[c(1:4,6:7)]
for(i in c(1:6)){
  values(tortoise.brick.adj[[i]]) <- 
    values(tortoise.brick.adj[[i]])/det.seq[["est"]][i]
  values(tortoise.brick.adj.lcl[[i]]) <-
    values(tortoise.brick.adj.lcl[[i]])/det.seq[["lcl"]][i]
  values(tortoise.brick.adj.ucl[[i]]) <-
    values(tortoise.brick.adj.ucl[[i]])/det.seq[["ucl"]][i]
}

# write individual rasters
for(i in names(tortoise.brick.raw)){
  writeRaster(tortoise.brick.raw[[i]], filename = 
                file.path(paste("data/tdensity/tortdenraw", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
  writeRaster(tortoise.brick.adj[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
  writeRaster(tortoise.brick.adj.lcl[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj_lcl", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
   writeRaster(tortoise.brick.adj.ucl[[i]], filename = 
                file.path(paste("data/tdensity/tortdenadj_ucl", i, ".tif")),
              format = "GTiff", overwrite = TRUE)
}
# write rasterbrick as multi-band raster
writeRaster(tortoise.brick.raw, 
            filename=file.path("data/tort_kden_raw_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj, 
            filename=file.path("data/tort_kden_adj_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj.lcl, 
            filename=file.path("data/tort_kden_adj_lcl_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)
writeRaster(tortoise.brick.adj.ucl, 
            filename=file.path("data/tort_kden_adj_ucl_2015_2020.tif"), 
            format="GTiff", overwrite=TRUE)

library(rasterVis)
names(tortoise.brick.adj) <- c("Y2015", "Y2016", "Y2017", 
                               "Y2018", "Y2019", "Y2020")
names(tortoise.brick.adj.lcl) <- c("Y2015", "Y2016", "Y2017", 
                                   "Y2018", "Y2019", "Y2020")
names(tortoise.brick.adj.ucl) <- c("Y2015", "Y2016", "Y2017", 
                                   "Y2018", "Y2019", "Y2020")

release.pt <- data.frame(x = 827253, y = 9909160)
coordinates(release.pt) <- ~ x + y

total.density.plots <-
  levelplot(tortoise.brick.adj, par.settings = viridisTheme, 
            scales = list(cex = 1.5),
            colorkey = list(labels = list(cex = 1.5)),
            par.strip.text = list(cex = 1.5), layout = c(3,2)) +
  layer(sp.points(release.pt, pch = 4, cex=1, col="red", alpha = 0.7))

total.density.plots
```

In this next composite figure I'm only showing densities for the first release cohort. 

```{r, kernel-density-trends-first-cohort, fig.height=5, fig.width=10}
den.list <- den.fun(ppp = subset(tortoises.santafe, Cohort == "2015"))
tortoise.brick.2015 <- brick(den.list$raster)
# replace negative values with 0
values(tortoise.brick.2015)[values(tortoise.brick.2015) < 0] <- 0
# adjust estimates for imperfect detection
for(i in c(1:6)){
  values(tortoise.brick.2015[[i]]) <- 
    values(tortoise.brick.2015[[i]]) / det.seq[["est"]][i]
}
names(tortoise.brick.2015) <- c("Y2015", "Y2016", "Y2017", 
                                "Y2018", "Y2019", "Y2020")

levelplot(tortoise.brick.2015, par.settings = viridisTheme, 
          scales = list(cex = 1.5),
          colorkey = list(labels = list(cex = 1.5)),
          par.strip.text = list(cex = 1.5), layout = c(3,2),
          main = list("Dispersal of first release cohort", cex = 1.5)) +
  layer(sp.points(release.pt, pch = 4, cex=1, col="red", alpha = 0.7))
```

At four and a half years since release, the first release cohort is widely dispersed across several spatial clusters.

Let's now quantify dispersal over time. In this next chunk of code and following figure I look at the kernel density estimates from dispersal distances (Euclidean distance from release point), highlighting the distances of the 50% isopleth with black lines, 95% isopleth with blue lines, and max distances with red lines for each occasion.

```{r, calculate-dispersal-rates-over-time}
movements.data$dist <- sqrt((movements.data$X - 827253)^2 +
                              (movements.data$Y - 9909160)^2)
movements.data$dist[movements.data$Days_ellapsed == 0] <- 0

# density plot function
den.plot <- function(data, cohort, occasion){
  dens <- density(data[data$Cohort %in% cohort & data$occ == occasion,]$dist)
  q95 <- quantile(dens, 0.95)
  q50 <- quantile(dens, 0.50)
  ggplot(data[data$Cohort %in% cohort & data$occ == occasion,], aes(dist)) + 
    geom_density(fill = "grey") + 
    geom_segment(aes(x = q50, xend = q50, yend = 0, y = 0.0075),
                 lwd = 0.8, color = "black", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    geom_segment(aes(x = q95, xend = q95, yend = 0, y = 0.0075), 
                 lwd = 0.8, color = "blue", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    geom_segment(aes(x = max(dist), xend = max(dist), yend = 0, y = 0.0075), 
                 lwd = 0.8, color = "red", 
                 arrow = arrow(length = unit(0.5, "cm"))) +
    theme_classic() + mythemes + theme(plot.title = element_text(size = 18)) +
    scale_x_continuous(expand = c(0,0), limits = c(0,2100), 
                       breaks = seq(0,2000,250)) +
    scale_y_continuous(expand = c(0,0), limits = c(0,0.0075)) + 
    geom_rug(sides = "b", alpha= 0.5)
}

# 2015 cohort
## 2015 dispersal plot for 2015 cohort / total
p15_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "August 2015") +
  labs(title = "August 2015 (2 months)", x = NULL, y = NULL)
## 2016 dispersal plot for 2015 cohort / total
p16_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2016") +
  labs(title = "June 2016 (1 year)", x = NULL, y = NULL)
## 2017 dispersal plot for 2015 cohort
p17_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2017") +
  labs(title = "June 2017 (2 years)", x = NULL, y = NULL)
## 2018 dispersal plot for 2015 cohort
p18_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "June 2018") +
  labs(title = "June 2018 (3 years)", x = NULL, y = NULL)
## 2019 dispersal plot for 2015 cohort
p19_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "August 2019") +
  labs(title = "August 2019 (4 years)", x = NULL, y = NULL)
## 2020 dispersal plot for 2015 cohort
p20_c15 <- den.plot(data = movements.data, cohort = "2015", 
                    occasion = "March 2020") +
  labs(title = "March 2020 (4.5 years)", x = NULL, y = NULL)

# 2017 cohort
## 2017 dispersal plot for 2017 cohort
p17_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "June 2017") +
  labs(title = "June 2017 (2 months)", x = NULL, y = NULL)
## 2018 dispersal plot for 2017 cohort
p18_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "June 2018") +
  labs(title = "June 2018 (1 year)", x = NULL, y = NULL)
## 2019 dispersal plot for 2017 cohort
p19_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "August 2019") +
  labs(title = "August 2019 (2 years)", x = NULL, y = NULL)
## 2020 dispersal plot for 2017 cohort
p20_c17 <- den.plot(data = movements.data, cohort = "2017", 
                    occasion = "March 2020") +
  labs(title = "March 2020 (2.75 years)", x = NULL, y = NULL)

# total
## 2015 dispersal plot for total
p15 <- den.plot(data = movements.data, cohort = "2015", occasion = "August 2015") +
  labs(title="August 2015",x=NULL, y = NULL)
## 2016 dispersal plot for total
p16 <- den.plot(data = movements.data, cohort = "2015", occasion = "June 2016") +
  labs(title="June 2016",x=NULL, y = NULL)
## 2017 dispersal plot for total
p17 <- den.plot(data = movements.data, cohort = c("2015", "2017"), 
                occasion = "June 2017") +
  labs(title="June 2017",x=NULL, y = NULL)
## 2018 dispersal plot for total
p18 <- den.plot(data = movements.data, cohort = c("2015", "2017"), 
                occasion = "June 2018") +
  labs(title="June 2018",x=NULL, y = NULL)
## 2019 dispersal plot for total
p19 <- den.plot(data = movements.data, cohort = c("2015", "2017", "2019"), 
                occasion = "August 2019") + labs(title="August 2019",
                                                 x=NULL, y = NULL)
## 2020 dispersal plot for total
p20 <- den.plot(data = movements.data, cohort = c("2015", "2017", "2019"), 
                occasion = "March 2020") + labs(title="March 2020",
                                                x=NULL, y = NULL)
```

```{r, dispersal-rates-first-cohort, fig.height = 10, fig.width = 12}
# 2015 cohort dispersal plot
dispersal_15cohort <- ggarrange(p15_c15, p16_c15, p17_c15, 
                                p18_c15, p19_c15, p20_c15,
                                ncol = 1, nrow = 6)
annotate_figure(dispersal_15cohort,
                top = text_grob("2015 cohort dispersal", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

```{r, dispersal-rates-second-cohort, fig.height = 8, fig.width = 10}
# 2017 cohort dispersal plot
dispersal_17cohort <- ggarrange(p17_c17, p18_c17, p19_c17, p20_c17, 
                                ncol = 1, nrow = 4)

annotate_figure(dispersal_17cohort,
                top = text_grob("2017 cohort dispersal", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

```{r, total-dispersal-rates, fig.height = 10, fig.width = 12}
# Total disperal plot
dispersal_total <- ggarrange(p15, p16, p17, p18, p19, p20, ncol = 1, nrow = 6)

annotate_figure(dispersal_total,
                top = text_grob("Total dispersal (all cohorts)", 
                                color = "black",size = 20),
                left = text_grob("Density", color = "black", 
                                 size = 18, rot = 90),
                bottom = text_grob("Distance from release (m)", 
                                   color = "black", size = 18))
```

Let's make this previous visualization another way using ridgeplots. I'll align these dispersal surfaces with the population size on Santa Fe.

```{r, dispersal-ridges-with-N, fig.height = 5, fig.width = 9.5}
library(ggridges)
library(purrr)
# cumulative N plot
N.plot <-
  total_pop %>%
  map_df(rev) %>%
  ggplot(aes(x = Year, y = N_hat)) +
  scale_x_reverse() +
  geom_line(lwd = 1) +
  geom_ribbon(aes(x = Year, ymin = 0, ymax = N_hat), fill = "grey") +
  coord_flip() + scale_y_continuous(limits = c(0,600), breaks = c(0,250,500)) +
  scale_x_reverse(limits = c(2020.4, 2014.3), breaks = c(2015:2020)) +
  theme_bw() + mythemes + xlab("Year") + ylab("N-est")

disp.plot <-
  movements.data %>%
  filter(Days_ellapsed > 0 & occ != "April 2019") %>%
  droplevels() %>%
  ggplot(aes(x = dist, y = fct_rev(occ))) +
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2,
                      rel_min_height = 0.01, jittered_points = TRUE,
                      position = position_points_jitter(width = 0.5, height = 0),
                      point_shape = "|", point_size = 1,
                      alpha = 0.7, vline_size = 0.8, vline_color = "blue") +
  theme_bw() + mythemes +
  scale_x_continuous(expand = c(0.02,0), limits = c(0,2000), breaks = seq(0,2000,250)) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  annotate("text", x = 1500, y = 1.3, label = "March 2020", size = 5) +
  annotate("text", x = 1500, y = 2.3, label = "August 2019", size = 5) +
  annotate("text", x = 1500, y = 3.3, label = "June 2018", size = 5) +
  annotate("text", x = 1500, y = 4.3, label = "June 2017", size = 5) +
  annotate("text", x = 1500, y = 5.3, label = "June 2016", size = 5) +
  annotate("text", x = 1500, y = 6.3, label = "August 2015", size = 5) +
  labs(x = "Distance from release (m)", y = NULL)

ggarrange(N.plot, disp.plot, widths = c(1, 4), ncol = 2)
```

Let's directly contrast the initial (+2 months, +1 year, +2 years) dispersal distances between the first two release cohorts. Here I'll show the 95% isopleth with dashed lines and the max distance with solid lines.

```{r, initial-dispersal-rates-first-two-cohorts, fig.height = 5, fig.width = 8}
init.disp.contrast <- 
  movements.data[c(movements.data$Cohort == "2015" & 
                     movements.data$occ == "August 2015") |
                   c(movements.data$Cohort == "2015" & 
                       movements.data$occ == "June 2016") |
                   c(movements.data$Cohort == "2015" & 
                       movements.data$occ == "June 2017") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "June 2017") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "June 2018") |
                   c(movements.data$Cohort == "2017" & 
                       movements.data$occ == "August 2019"),] 

init.disp.contrast <- 
  init.disp.contrast[is.na(init.disp.contrast$PIT_final) == FALSE,]

init.disp.contrast$Ellapsed <- "1-2 months"
init.disp.contrast$Ellapsed[c(init.disp.contrast$Cohort == "2015" & 
                                init.disp.contrast$occ == "June 2016") |
                              c(init.disp.contrast$Cohort == "2017" &
                                  init.disp.contrast$occ == "June 2018")] <- "1 year"
init.disp.contrast$Ellapsed[c(init.disp.contrast$Cohort == "2015" &
                                init.disp.contrast$occ == "June 2017") |
                              c(init.disp.contrast$Cohort == "2017" &
                                  init.disp.contrast$occ == "August 2019")] <- "2 years"

init.disp.contrast$Ellapsed <- factor(init.disp.contrast$Ellapsed, 
                                      levels = c("1-2 months", "1 year", "2 years"))

disp.sum <- init.disp.contrast %>%
  droplevels() %>%
  group_by(Cohort, Ellapsed) %>%
  summarise(q95 = quantile(dist, 0.95, na.rm = T),
            maxdist = max(dist, na.rm = T)) %>%
  ungroup() 

levels(init.disp.contrast$Cohort) <- c("1", "2", "3")
levels(disp.sum$Cohort) <- c("1", "2")

init.disp.contrast.p <- ggplot(init.disp.contrast, aes(dist)) + 
  geom_density(aes(fill = Cohort), alpha = 0.3, lwd = 0.9) +
  geom_segment(data = disp.sum, aes(x = q95, xend = q95, yend = 0, 
                                    y = Inf, color = Cohort), 
               lwd = 0.8, lty = "dashed") +
  geom_segment(data = disp.sum, 
               aes(x = maxdist, xend = maxdist, 
                   yend = 0, y = Inf, color = Cohort), 
               lwd = 0.8, lty = "solid") +
  geom_text(data = disp.sum, 
            aes(label = floor(q95), x = q95, y = 0.0085, 
                angle = 90, color = Cohort), 
            size = 3, show.legend = FALSE) +
  geom_text(data = disp.sum, 
            aes(label = floor(maxdist), x = maxdist, y = 0.0085, 
                angle = 90, color = Cohort), 
            size = 3, show.legend = FALSE) +
  facet_grid(rows = vars(Ellapsed)) + theme_light() + mythemes +
  theme(plot.title = element_text(size = 18)) + 
  labs(y = "Density", x = "Distance from release (m)") +
  coord_cartesian(ylim = c(0, 0.0075), clip = 'off') +
  scale_x_continuous(expand = c(0.02,0), limits = c(0,1600), 
                     breaks = seq(0,1500,250)) +
  scale_y_continuous(expand = c(0,0)) +
  geom_rug(sides = "b", aes(color = Cohort), show.legend = FALSE) +
  theme(panel.spacing = unit(2, "lines")) + 
  theme(plot.margin = unit(c(2,1,1,1), "lines")) + 
  theme(strip.text = element_text(size = 13))
  
init.disp.contrast.p
```

A few takeaways:

(1) Tortoises from all three cohorts seem to rapidly disperse within the first two months after release, and become a bit more fixed thereafter. The second cohort seems to disperse a bit more widely than the first in that initial period. This could be evidence of a density-dependent dispersal process.

(2) The first cohort seemed to become spatially fixed two years post-release. This could be a natural dispersal plateau for the population on this island or be due to a sampling bias that missed individuals that were outside of the sampling zone. I'd have to compare those distance values with uncertainty to say more.

## Spatial patterns - telemetry data

Let's also look at dispersal using radiotelemetry data from a sample of the 2015 cohort, tracked for two years, from release to June of 2017. I'll prepare the data the same way I did for the recapture data.

```{r, read-and-prepare-radiotelemetry-data}
telemetry <- read.csv("data/telemetry_clean.csv")
telemetry$Frecuencia <- as.factor(telemetry$Frecuencia)
telemetry$Date <- as.Date(telemetry$Date,format='%m-%d-%Y')
telemetry <- telemetry[,4:9]

# create extra rows for the June 2015 origin point for each tortoise
teletemp <- data.frame(Date = as.Date("2015-06-27"),
                       PIT = unique(telemetry$PIT),
                       Frecuencia = unique(telemetry$Frecuencia),
                       Latitud = -0.82076,
                       Longitud = -90.060063,
                       LC_cm = NA)

telemetry <- rbind(telemetry, teletemp)
telemetry$Days_ellapsed <- julian(telemetry$Date, 
                                  origin = as.Date("2015-06-27"))

# write to csv, make projected UTM shapefile in ArcMap
write.csv(telemetry, "data/telemetry_data_GIS.csv")

# read shapefile from ArcMap
telemetry.shp <- readOGR("data/telemetry_data_UTM2.shp")

# here I create new X and Y UTM fields that make coordinates relative to the release point (0,0). this will make it easier to quickly assess dispersal distances in the maps by centering the release point at 0,0.

telemetry.shp$X_corrected <- telemetry.shp$X - 827253
telemetry.shp$Y_corrected <- telemetry.shp$Y - 9909160
telemetry.data <- as.data.frame(telemetry.shp)
```

Now let's look at those traces, both in aggregate and color-coded by individual.

```{r, telemetry-traces-2015-cohort}
traces.tele <- ggplot() +
  geom_polygon(data = santafe, aes(x = santafe$X, y = santafe$Y), 
               fill = "grey") +
  geom_path(data = telemetry.data, 
            aes(x = X_corrected, y = Y_corrected, group = Frecuencia), 
            alpha = 0.4, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), shape = 4, size = 2, 
             stroke = 1.5, color = "red") +
  theme_classic() + mythemes + coord_equal() +
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "", subtitle = "", caption = "") +
  annotate("text", x = 3500, y = 2200, label = "N", size = 8) +
  annotate("text", x = 3500, y = 1600, label = "\u2191", size = 15)

traces.tele
```

Let's also look at the same figure but zoomed in and with different colors for each individual.

```{r, telemetry-traces-2015-cohort-zoomed}
traces.tele.ind <- ggplot() +
  geom_polygon(data = santafe, 
               aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(data = telemetry.data, 
            aes(x = X_corrected, y = Y_corrected, 
                group = Frecuencia, color = Frecuencia), lwd = 0.8) +
  geom_point(aes(x = 0, y = 0), shape = 4, size = 2, 
             stroke = 1.5, color = "black") +
  theme_classic() + mythemes + 
  coord_equal(xlim = c(-1500,1500), ylim = c(-1500, 1500)) + 
  theme(legend.position = "none") + 
  labs(x = "Distance from release (m)", y = "Distance from release (m)", 
       title = "", subtitle = "", caption = "") +
  annotate("text", x = 1400, y = 1400, label = "N", size = 8) +
  annotate("text", x = 1400, y = 1000, label = "\u2191", size = 15)

traces.tele.ind
```

## Summary

Let's create one figure that pulls together all of these major movement results: tortoise distributions over time, ellapsed traces, and dispersal ellipses and kernel densities from 2020.

```{r, composite-dispersal-kernel-density-figure, echo = FALSE, fig.height = 9, fig.width = 11}
# pull the abundance and distribution by time plots together into a top panel
top <- ggarrange(N.plot + ggtitle("a") + theme(title = element_text(size = 8)), 
                 disp.plot + ggtitle("b") + theme(title = element_text(size = 8)), 
                 widths = c(1, 4), ncol = 2)

# traces plot with cohort ellipse overlay
traces.ms <- 
  ggplot(data = movements.data, aes(x = X_corrected, y = Y_corrected)) +
  geom_polygon(data = santafe, aes(x = santafe$X, y = santafe$Y), fill = "grey") +
  geom_path(aes(group = PIT_final), alpha = 0.2, lwd = 0.6) +
  geom_point(aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red") +
  stat_ellipse(data = movements.data[movements.data$occ == "March 2020" & 
                                   !is.na(movements.data$Cohort),],
               aes(x = X_corrected, y = Y_corrected, color = Cohort), 
               level = 0.95, lwd = 0.9, alpha = 0.5) +
  theme_bw() + mythemes + coord_equal() +
  theme(plot.margin = unit(c(0,5,0,0), "mm"), legend.position = "bottom") +
  scale_x_continuous(limits = c(-3600, 3700)) +
  scale_y_continuous(limits = c(-2300, 2500)) +
  guides(color = guide_legend(override.aes= list(alpha = 1))) +
  scale_color_manual(values = c("#E69F00", "#56B4E9", "#009E73")) +
  labs(x = "Distance from release (m)", 
       y = "Distance from release (m)", title = "c")

# 2020 kernel density plot
den2020pts <- rasterToPoints(tortoise.brick.adj$Y2020, spatial = TRUE)
den2020df  <- data.frame(den2020pts)
den2020df$X_corrected <- den2020df$x - 827253
den2020df$Y_corrected <- den2020df$y - 9909160

library(scico)
den2020 <- ggplot() + 
  geom_raster(data = den2020df , 
              aes(x = X_corrected, y = Y_corrected, fill = Y2020)) +
  geom_point(inherit.aes = FALSE, aes(x = 0, y = 0), 
             shape = 4, size = 2, stroke = 1.5, color = "red", alpha = 0.7) +
  theme_bw() + mythemes + coord_equal() + 
  theme(plot.margin = unit(c(0,0,0,0), "mm")) +
  scale_x_continuous(limits = c(-3600, 3700)) +
  scale_y_continuous(limits = c(-2300, 2500)) +
  labs(x = "Distance from release (m)", y = NULL, title = "d",
       fill = "Density (per ha)") + 
  scale_fill_scico(palette = 'batlow') +
  theme(legend.position = "bottom", legend.key.width=unit(1,"cm"), 
        axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
        title = element_text(size = 5)) +
  guides(fill = guide_colorbar(title.vjust=0.8))

# bring the trace plot and kernel density plot together into a bottom panel
bottom <- plot_grid(traces.ms + ggtitle("c") + theme(title = element_text(size = 8)),
                    den2020 + ggtitle("d") + theme(title = element_text(size = 8)), 
                    ncol = 2, axis = "tblr", 
                    rel_widths = c(1, 1), align = "h")

library(gridExtra)
grid.arrange(top, bottom, nrow = 2)
```

Let's make one final summary table of our dispersal statistics.

```{r, echo = FALSE}
movements.data.copy <- movements.data %>%
  mutate(Cohort = "Total")

movements.data %>% 
  na.omit() %>%
  bind_rows(movements.data.copy) %>%
  filter(occ != "June 2015" &
           occ != "April 2017" &
           occ != "February 2019" &
           occ != "April 2019") %>%
  group_by(occ, Cohort) %>%
  summarise(Ellapsed = round(max(Days_ellapsed, na.rm = T),1),
            Median = round(median(dist), 1),
            Mean = round(mean(dist),1),
            SD = round(sd(dist),1),
            Upper = round(quantile(dist, 0.95),1),
            Max = round(max(dist, na.rm = T),1)) -> disp.table

disp.table <- disp.table[-c(2,4),-1]

colnames(disp.table) <- c("Cohort", "Days since release", "Median (m)",
                          "Mean (m)", "SD (m)", "95% isopleth (m)", "Max (m)")

library(knitr)
library(kableExtra)
disp.table %>%
  kable(format = "html", escape = F,
        caption = "Summary of tortoise dispersal on Santa Fe from 2015 to 2020.", 
        booktabs = T) %>%
  column_spec(column = 1:7, width = "1em", width_min = "1em") %>% 
  kable_styling("hover", bootstrap_options = c("condensed"))  %>% 
  pack_rows("August 2015", 1, 1, label_row_css = row.specs) %>%
  pack_rows("June 2016", 2, 2, label_row_css = row.specs) %>%
  pack_rows("June 2017", 3, 5, label_row_css = row.specs) %>%
  pack_rows("June 2018", 6, 8, label_row_css = row.specs) %>% 
  pack_rows("August 2019", 9, 12, label_row_css = row.specs) %>%
  pack_rows("March 2020", 13, 16, label_row_css = row.specs)

write.csv(disp.table, "data/tortoise_dispersal_summary.csv")
```

# Ecosystem response

Let's examine our Santa Fe land iguana data from 2011 to 2020 to see whether the population has been affected by the tortoise introduction so far. 

```{r, iguana, echo = FALSE, out.width = "35%", out.height = "35%", fig.align = "center", fig.cap = "A male Santa Fe land iguana (*Conolophus pallidus*)."}

include_graphics("images/iguana.jpg")
```

I'll do this using two corroborative data sets: 

  (1) distance sampling data from transect surveys in 2011, 2017, and 2020

  (2) plot counts from 2011 and 2020

## Iguana trends (transects)

Now let's use hierarchical distance sampling models [@Buckland2001; @Outline2016c] to compare density estimates between years from our iguana transects. We are only using a subset of the original island-wide transects here that are within the center of the island where tortoises were released. These transects (n=28), and the permanent plots in between them, were visited three times, once before and twice after tortoise introduction.

Here is all our data prep code to run the distance sampling models in `unmarked`. We're going to stack transects by year to get abundance estimates as a function of time, tortoise density, and other covariates.

```{r}
### LOAD DISTANCE SAMPLING DATA OF SUBSET OF TRANSECTS ###
iguanas <- suppressMessages(read_excel("data/iguanas_distsamp_2011_2017_2020.xlsx", 
                                       na = "NA"))
iguanas$transect_yr <- as.factor(paste(iguanas$transect, iguanas$year, sep = "-"))

# make time a continuous covariate and impute mean survey time for missing transects
iguanas$hm <- hour(iguanas$time) + minute(iguanas$time)/60
iguanas$hm[is.na(iguanas$hm)] <- mean(iguanas$hm, na.rm = T)

# get mean times for each transect_yr
transect.times <- iguanas %>%
  group_by(transect_yr) %>%
  summarise(time = mean(hm)) %>%
  ungroup()

# number of visits for each transect
transect.visits <- iguanas %>%
  distinct(transect, year) %>%
  group_by(transect) %>%
  summarise(visits = n()) %>%
  ungroup()

# load transect buffers
iguana.buffs <- readOGR("data/iguana_transects_50m_buff.shp", verbose=FALSE)
iguana.buffs <- spTransform(iguana.buffs, CRS("+init=epsg:32715"))

# get zonal statistics for tortoise densities in iguana transect buffers
buff.2017 <- 
  data.frame(transect = iguana.buffs$transect,
             tden = c(raster::extract(tortoise.brick.adj$Y2017, 
                                      iguana.buffs, fun = mean, na.rm = TRUE)),
             tden2yr = c(raster::extract(mean(tortoise.brick.adj[[1:2]]), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             tden5yr = c(raster::extract(mean(tortoise.brick.adj[[1:2]], 
                                              tortoise.brick.adj[[1:3]]*0), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             year = 2017)
buff.2020 <- 
  data.frame(transect = iguana.buffs$transect,
             tden = c(raster::extract(tortoise.brick.adj$Y2020, 
                                      iguana.buffs, fun = mean, na.rm = TRUE)),
             tden2yr = c(raster::extract(mean(tortoise.brick.adj[[4:5]]), 
                                         iguana.buffs, fun = mean, na.rm = TRUE)),
             tden5yr = c(raster::extract(mean(tortoise.brick.adj[[1:5]]),
                                         iguana.buffs, fun = mean, na.rm = TRUE)), 
             year = 2020)

buff.tden <- rbind(buff.2017, buff.2020)

# subset transects to those surveyed in all three years
iguanas.sub <- iguanas %>%
  filter(transect %in% transect.visits$transect[transect.visits$visits == 3]) %>%
  droplevels() %>%
  as.data.frame()

# summarize total counts of iguanas each year within same subset of transects
iguanas.sub %>%
  filter(!is.na(distance)) %>%
  group_by(year) %>%
  summarise(n_iguanas = n()) %>%
  ungroup()

# identify distance to truncate iguana observations (convert to NAs)
iguanas.sub$quantile <- q.rank(iguanas.sub$distance)
max.dist <- min(iguanas.sub$distance[iguanas.sub$quantile >= 0.975], na.rm = T)

# prepare observations and covariates for unmarked
library(unmarked)
ydat <- formatDistData(iguanas.sub,
                       distCol="distance",
                       transectNameCol="transect_yr",
                       dist.breaks=seq(0,max.dist,length.out = 6))

### LOAD COVARIATES ###
covs <- read.csv(file = "data/distsamp_covars.csv", 
                 header = TRUE, row.names="transect") 

# subset to transects surveyed in all three years
covs <- covs %>%
  mutate(transect = rownames(.)) %>%
  filter(transect %in% transect.visits$transect[transect.visits$visits == 3]) %>%
  as.data.frame()

# standardize continuous covariates
covs$elev.z <- scale(covs$elev)
covs$slope.z <- scale(covs$slope)

# repeat data frame for each survey year
covs <- rbind(covs, covs, covs)
covs$year <- c(rep(2011, length(unique(covs$transect))), 
               rep(2017, length(unique(covs$transect))), 
               rep(2020, length(unique(covs$transect))))

# add tortoise density and time covariates
covs <- covs %>%
  left_join(buff.tden, by = c("transect", "year")) %>%
  mutate_all(~replace(., is.na(.), 0)) %>%
  mutate(transect_yr = paste(transect, year, sep = "-")) %>%
  filter(transect_yr %in% iguanas$transect_yr) %>%
  left_join(transect.times, by = c("transect_yr")) %>%
  mutate(tden.z = scale(tden),
         tden2yr.z = scale(tden2yr),
         tden5yr.z = scale(tden5yr),
         time.z = scale(time)) %>%
  droplevels() %>%
  as.data.frame() 

ydat.df <- data.frame(ydat) %>%
  mutate(transect_yr = rownames(.)) %>%
  left_join(covs, by = "transect_yr")

umf <- 
  unmarkedFrameDS(y = ydat, 
                  siteCovs = data.frame(time = ydat.df$time.z,
                                        year = as.factor(ydat.df$year),
                                        elev = ydat.df$elev.z,
                                        slope = ydat.df$slope.z,
                                        aspect = ydat.df$aspect,
                                        veg = ydat.df$veg,
                                        tden = ydat.df$tden.z,
                                        tden2yr = ydat.df$tden2yr.z,
                                        tden5yr = ydat.df$tden5yr.z), 
                  dist.breaks=seq(0,max.dist,length.out = 6),
                  unitsIn="m", survey="line", tlength = rep(500, nrow(covs)))

summary(umf)
```

Let's examine our covariates to see if we have any colinearity in our geographic and new tortoise covariates before running our distance sampling models. Note: our covariates were linked to each transect in GIS by extending a 50m buffer around each transect (with flat ends) and calculating mean or modal values of elevation, slope, and vegetation type for each buffer zone.

Let's look at the variance inflation factors (VIFs) to see if there is any colinearity.

```{r}
# get VIF w current tortoise density variable
corvif(covs[,c(3,4,6,7,8,14)]) # no colinearity
# get VIF w recent tortoise density variable
corvif(covs[,c(3,4,6,7,8,16)]) # no colinearity
```

The VIF scores indicate that there is no colinearity among our covariates. 

Now I'll create our models. First we want to identify the correct detection function.

```{r}
# create six base models and compare the global model for three different detection functions 
haz.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="hazard", output="density", unitsOut="ha")

haz.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="hazard", output="density", unitsOut="ha")

hn.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="halfnorm", output="density", unitsOut="ha")

hn.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="halfnorm", output="density", unitsOut="ha")

nexp.t <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.t2 <- distsamp(
  ~time+I(time^2)+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

library(AICcmodavg)
aictab(cand.set = list(haz.t, hn.t, nexp.t,
                       haz.t2, hn.t2, nexp.t2),
       modnames = c("hazard", "halfnorm", "negexp",
                    "hazard2", "halfnorm2", "negexp2"))
```

We're going to go with the negative exponential detection function to model iguana density. Let's run our goodness of fit tests.

```{r, GoF-iguana-global-distsamp-model}
fitstats <- function(fm) {
    observed <- getY(fm@data)
    expected <- fitted(fm)
    resids <- residuals(fm)
    sse <- sum(resids^2)
    chisq <- sum((observed - expected)^2 / expected, na.rm = TRUE)
    freeTuke <- sum((sqrt(observed) - sqrt(expected))^2, na.rm = TRUE)
    out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)
    return(out)
}

set.seed(1)
GoF <- parboot(nexp.t, fitstats, nsim=1000, report=5) ; GoF
observed <- data.frame(test = names(GoF@t0),
                       value = GoF@t0) %>% melt(id = "test")
GoF@t.star %>%
  melt() %>%
  dplyr::rename(test = Var2) %>%
  ggplot(aes(x = value)) +
  geom_histogram(col = "white", fill = "grey5", alpha = 0.3) +
  geom_vline(data = observed, aes(xintercept = value), 
             col = "blue", lwd = 0.9) +
  facet_wrap(~test, nrow = 3, scales = "free") + 
  theme_classic() + mythemes +
  labs(x = "Bootstrapped statistic", y = "Frequency")
  
c.hat <- GoF@t0[2] / mean(GoF@t.star[,2]); c.hat
```

The global model seems to fit pretty well. 

There is very slight overdispersion, so let's account for that in our model rankings and estimates.

Here is our candidate list of models.

```{r, make-iguana-distsamp-models}
# create candidate models, rank with QAIC
nexp.null <- distsamp(
  ~1 ~1,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.year <- distsamp(
  ~time+year ~year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.hab <- distsamp(
  ~time+year ~elev+slope+veg+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.tden <- distsamp(
  ~time+year ~tden+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.tden5y <- distsamp(
  ~time+year ~tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.full <- distsamp(
  ~time+year ~elev+slope+veg+tden+year,
  umf, keyfun="exp", output="density", unitsOut="ha")

nexp.full.5y <- distsamp(
  ~time+year ~elev+slope+veg+tden5yr+year,
  umf, keyfun="exp", output="density", unitsOut="ha")
```

We'll rank models with the `aictab` function from the `AICcmodavg` package.

```{r, rank-iguana-distsamp-models}
iguana.rankings <- 
  aictab(cand.set = list(nexp.null, nexp.year, nexp.hab, nexp.tden, 
                         nexp.tden5y, nexp.full, nexp.full.5y), c.hat = c.hat,
         modnames = c("null", "year", "habitat", "tortoises", 
                      "tortoises (5 yr)", "habitat + tortoises", 
                      "habitat + tortoises (5 yr)"))
iguana.rankings
write.csv(iguana.rankings, "data/iguana_model_rankings_stacked.csv")
```

Interesting. The year model is on top and only the tortoises models are competitive; however, those tortoise models are closely ranked to the null model as well, suggesting that the iguana population does not vary strongly with our tortoise and certainly not with the other environmental covariates.

Let's look at the parameter estimates from that year model.

```{r}
summary(nexp.year)
```

It does not appear that iguana density changes much over time. Detection rates may be greater in 2020. No hour effect on detection probability.

Out of curiosity, what do the next two models with the tortoise density look like?

```{r}
nexp.tden5y
nexp.tden
```

Tortoise density has no clear effect on iguana density.

Let's use the top model plot out our iguana density estimates for 2011, 2017, and 2020 (and include our tortoise density estimates in the plot as a reference).

```{r, iguana-tortoise-density-estimates, fig.width = 7, fig.height = 5}
library(adehabitatHR)
# get minimal convex polygon of transect coordinates
transect.points <- 
  SpatialPoints(sp::coordinates(subset(iguana.buffs, 
                                       transect %in% iguanas.sub$transect)))

survey.zone <- mcp(transect.points, percent = 100)
writeOGR(obj = survey.zone, dsn = getwd(),  layer = "data/core_survey_zone", 
         driver="ESRI Shapefile", overwrite_layer=TRUE)

# get iguana density predictions from top model
i.lambda <- predict(nexp.year, type = "state", c.hat = c.hat, 
                      newdata = data.frame(year = c("2011", "2017", "2020")))

i.lambda$N_hat = i.lambda$Predicted * survey.zone$area
i.lambda$N_lower = i.lambda$lower * survey.zone$area
i.lambda$N_upper = i.lambda$upper * survey.zone$area
i.lambda$pct_change = (i.lambda$N_hat - i.lambda$N_hat[1])/i.lambda$N_hat[1]
i.lambda$pct_change_lwr = (i.lambda$N_lower - i.lambda$N_lower[1])/i.lambda$N_lower[1]
i.lambda$pct_change_upr = (i.lambda$N_upper - i.lambda$N_upper[1])/i.lambda$N_upper[1] 

# get mean tortoise density in 2017 and 2020 in survey zone
t.lambda <- 
  data.frame(estimate = c(0, raster::extract(tortoise.brick.adj$Y2017, 
                                             survey.zone, 
                                             fun = mean, na.rm = TRUE),
                          raster::extract(tortoise.brick.adj$Y2020, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE)),
             lower = c(0, raster::extract(tortoise.brick.adj.lcl$Y2017, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE),
                       raster::extract(tortoise.brick.adj.lcl$Y2020, 
                                       survey.zone, 
                                       fun = mean, na.rm = TRUE)),
             upper = c(0, raster::extract(tortoise.brick.adj.ucl$Y2017, 
                                          survey.zone, 
                                          fun = mean, na.rm = TRUE),
                               raster::extract(tortoise.brick.adj.ucl$Y2020, 
                                               survey.zone,
                                       fun = mean, na.rm = TRUE)))

# combine iguana and tortoise density data frames for plotting together
sf.densities <- data.frame(density = c(i.lambda$Predicted, t.lambda$estimate),
                           lcl = c(i.lambda$lower, t.lambda$lower),
                           ucl = c(i.lambda$upper, t.lambda$upper),
                           Year = c(rep(c("2011", "2017", "2020"),2)),
                           species = c(rep("iguana", 3), rep("tortoise", 3)))

# print density / abundance table
sf.densities

# plot
distsamp.plot <-
  ggplot(sf.densities, aes(Year, density, color = species)) + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl)) +
  geom_vline(aes(xintercept = 1.71), col = "grey50", 
             lty = "dashed", lwd = 1.1) +
  geom_hline(aes(yintercept = 0), lty = "dashed") +
  geom_pointrange(aes(ymin = lcl, ymax = ucl)) +
  theme_classic() + mythemes + 
  labs(x = "Year", y = "Density (per ha)") + ylim(0,10) +
  annotate("text", x = 3.2, y = sf.densities$density[3], 
           label = "iguanas", col = col2[1], size = 4) +
  annotate("text", x = 3.2, y = sf.densities$density[6], 
           label = "tortoises", col = col2[2], size = 4) +
  scale_color_manual(values = col2) + theme(legend.position = "none")

distsamp.plot
```

The population may have increased slightly from 2011 to 2020 (~ 529 [421--512] individuals or 34% [17--55%]), but there is a lot of uncertainty around those estimates so there is no strong evidence to support any iguana change over time or tortoise impact on iguana distribution or abundance. This could change as tortoises get larger and begin reproducing, thus having a more sustained impact on the environment in Santa Fe. Future monitoring will be essential to verify any impacts on the iguana population.

Let's ask the same question about iguana population change using the repeated plot counts from 2011 and 2020.

## Iguana trends (plots)

```{r, read-plot-data}
# load data
plots2011 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2011")) %>% arrange(Punto)
plots2017 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2017")) %>% arrange(Punto)
plots2020 <- 
  suppressMessages(read_excel("data/iguana_plots_2011_2017_2020.xlsx", 
                              na = "NA", sheet = "2020")) %>% arrange(Punto)
```

Plots were also measured in 2017, but iguana data from at least 10 plots from the core zone were lost and unrecoverable. So we will focus on the two years, 2011 (before) and 2020 (after) which we have complete data for.

```{r, prepare-plot-data}
# filter the 2011 data to include only those plots that were surveyed in 2020
plots2011 <- plots2011 %>%
  filter(Punto %in% plots2020$Punto)

# combine the 2011 and 2020 data
iguana_plots <- 
  data.frame(Plot = plots2011$Punto, 
             Lat = plots2011$Latitud, Lon = plots2011$Longitud,
             ITM2011 = plots2011$ITM, ITH2011 = plots2011$ITH, 
             ITJ2011 = plots2011$ITJ, ITT2011 = plots2011$ITT, 
             ITM2020 = plots2020$ITM, ITH2020 = plots2020$ITH, 
             ITJ2020 = plots2020$ITJ, ITT2020 = plots2020$ITT,
             TG2011 = 0, TG2020 = plots2020$TGH+plots2020$TGM+plots2020$TGJ,
             HI2011 = plots2011$HI, HI2020 = plots2020$HI,
             CA2011 = plots2011$CA, CS2011 = plots2011$CS, 
             CJ2011 = plots2011$CJ, CT2011 = plots2011$CT,
             CA2020 = plots2020$CA, CS2020 = plots2020$CS, 
             CJ2020 = plots2020$CJ, CT2020 = plots2020$CT)
```

### Wilcoxin tests

First let's use a Wilcoxin test to compare iguana and iguana fecal density in plots between 2011 and 2020.

```{r, iguana-wilcoxin-tests}
# male iguanas
pop.diff.m <- wilcox.test(iguana_plots$ITM2011, iguana_plots$ITM2020, 
                          paired = TRUE); pop.diff.m
# female iguanas
pop.diff.f <- wilcox.test(iguana_plots$ITH2011, iguana_plots$ITH2020, 
                          paired = TRUE); pop.diff.f
# total iguanas
pop.diff.t <- wilcox.test(iguana_plots$ITT2011, iguana_plots$ITT2020, 
                          paired = TRUE); pop.diff.t
# fecal denstiy
fec.diff <- wilcox.test(iguana_plots$HI2011, iguana_plots$HI2020, 
                        paired = TRUE); fec.diff
```

According to these tests, there are no differences in iguana density before and after tortoise introductions. But there are a lot of plots with no differences between years, and those measurements are ignored in the significance test. There is a difference in iguana feces (more in 2020), but that may simply be due to human measurement error (including confusion with juvenile tortoise feces).

### Iguana count GLMM

We'll also use generalized linear mixed models to compare iguana plot counts of iguanas and cactus in 2011 and 2020 with the `lme4` package/

Let's connect our tortoise density raster to the iguana plot data. I'll create a shapefile from the plot points, and summarize the recent (5yr average) tortoise density surrounding those points (50m buffer).

```{r, prepare-plot-data-for-GLMMs}
# create shapefile for plots
iguana_plots_shp <- iguana_plots
coordinates(object = iguana_plots_shp) <- ~ Lon + Lat
proj4string(iguana_plots_shp) <- CRS("+proj=longlat +datum=WGS84")
iguana_plots_shp <- spTransform(iguana_plots_shp, 
                                CRSobj = CRS("+init=epsg:32715"))

# create buffer for plots
library(rgeos)
plot_buffers <- gBuffer(iguana_plots_shp, byid = TRUE, width = 50, 
                        capStyle="ROUND")

# get zonal statistics for tortoise densities in iguana plot buffers
iguana_plots$tden <- c(raster::extract(tortoise.brick.adj[[6]], 
                                       plot_buffers,
                                       fun = mean, na.rm = TRUE))
iguana_plots$tden5y <- c(raster::extract(mean(tortoise.brick.adj[[1:5]]), 
                                         plot_buffers,
                                         fun = mean, na.rm = TRUE))

# divide tortoise density values into "high" and "low" density treatments
iguana_plots$tdencat <- 
  as.factor(ifelse(iguana_plots$tden5y < quantile(iguana_plots$tden5y, 0.5), 
                   "low", "high"))

# melt iguana data
iguana.melt <- iguana_plots %>%
  dplyr::select(c(Plot, ITM2011, ITM2020, ITH2011, ITH2020, 
                  ITJ2011, ITJ2020, ITT2011, ITT2020, tden5y, tdencat)) %>%
  melt(id = c("Plot", "tden5y", "tdencat"))

# melt cactus data
cactus.melt.juv <- iguana_plots %>%
  dplyr::select(c(Plot, CJ2011, CJ2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CJ = value,
         year = as.factor(ifelse(variable %in% "CJ2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CJ))

cactus.melt.sub <- iguana_plots %>%
  dplyr::select(c(Plot, CS2011, CS2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CS = value,
         year = as.factor(ifelse(variable %in% "CS2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CS))

cactus.melt.adu <- iguana_plots %>%
  dplyr::select(c(Plot, CA2011, CA2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CA = value,
         year = as.factor(ifelse(variable %in% "CA2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CA))

cactus.melt.tot <- iguana_plots %>%
  dplyr::select(c(Plot, CT2011, CT2020)) %>%
  melt(id = c("Plot")) %>%
  mutate(CT = value,
         year = as.factor(ifelse(variable %in% "CT2011", "2011", "2020"))) %>%
  dplyr::select(c(Plot, year, CT))

# create data frame of iguana and cactus plot counts for GLMMs
iguana.total <- iguana.melt %>%
  filter(variable %in% "ITT2011" | variable %in% "ITT2020") %>%
  mutate(year = as.factor(ifelse(variable %in% "ITT2011", "2011", "2020"))) %>%
  left_join(cactus.melt.juv, by = c("Plot", "year")) %>%
  left_join(cactus.melt.sub, by = c("Plot", "year")) %>%
  left_join(cactus.melt.adu, by = c("Plot", "year")) %>%
  left_join(cactus.melt.tot, by = c("Plot", "year")) %>%
  mutate(status = as.factor(ifelse(value > 0, 1, 0)),
         iguanas = value)
```

Now let's build our GLMM and plot out the time * tortoise contrast.

```{r, iguana-GLMM, fig.width = 7, fig.height = 5}
library(lme4)
library(lmerTest)
library(DHARMa)
library(ggeffects)

iguana.total$tdencat <- factor(iguana.total$tdencat, levels = c("low", "high"))

# models
## null
iguana.null <-glmer(iguanas ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
iguana.year <-glmer(iguanas ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## tortoise
iguana.yearXtort <- glmer(iguanas ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted models with Likelihood ratio test
library(lmtest)
lrtest(iguana.null, iguana.year, iguana.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = iguana.yearXtort)
plot(simulationOutput)
summary(iguana.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
ggpredict(iguana.yearXtort, terms = c("year", "tdencat"), 
          type = "fe", ci.lvl = 0.95)  %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) -> iguana.pred

# plot iguana density predictions
iguana.plot.estimates <-
  ggplot(iguana.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + labs(x = "Year", y = "Iguana density (per ha)") +
  theme(legend.position = c(.8,.8), legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

iguana.plot.estimates
```

This model from the plot data suggests that the total iguana population has not changed from 2011 to present. There was a positive association between tortoise density and iguana plot counts, which could reflect a common underlying habitat suitability. The distribution of iguanas may have shifted, with tortoises displacing some iguanas to other areas that were less occupied before. But the interaction between tortoise density and time was not important in our model.

## Cactus trends

Let's finally look at how cactus densities have changed over time with tortoises in the same long-term monitoring plots using the same Wilcoxin tests and GLMM model structure. 

### Wilcoxin tests

```{r, cactus-wilcoxin-tests, fig.width = 7, fig.height = 5}
# juvenile cactus
pop.diff.cj <- wilcox.test(iguana_plots$CJ2011, iguana_plots$CJ2020, 
                           paired = TRUE); pop.diff.cj
# subadult cactus
pop.diff.cs <- wilcox.test(iguana_plots$CS2011, iguana_plots$CS2020, 
                           paired = TRUE); pop.diff.cs
# adult cactus
pop.diff.ca <- wilcox.test(iguana_plots$CA2011, iguana_plots$CA2020, 
                           paired = TRUE); pop.diff.ca
# total cactus
pop.diff.ct <- wilcox.test(iguana_plots$CT2011, iguana_plots$CT2020, 
                           paired = TRUE); pop.diff.ct

library(broom)
library(tidyr)
iguana_plots %>%
  dplyr::select(Plot, CJ2011, CJ2020, CS2011, CS2020, 
                CA2011, CA2020, CT2011, CT2020) %>%
  pivot_longer(-Plot, names_to = "CountStage", values_to = "Count") %>%
  mutate(Year = ifelse(CountStage %in% c("CJ2011", "CS2011", "CA2011", "CT2011"), 
                       "2011", "2020"),
         Stage = case_when(CountStage %in% c("CJ2011", "CJ2020") ~ "Juveniles",
                           CountStage %in% c("CS2011", "CS2020") ~ "Subadults",
                           CountStage %in% c("CA2011", "CA2020") ~ "Adults",
                           CountStage %in% c("CT2011", "CT2020") ~ "Total"),
         Label = case_when(Stage %in% "Juveniles" ~ "a",
                           Stage %in% "Subadults" ~ "b",
                           Stage %in% "Adults" ~ "c",
                           Stage %in% "Total" ~ "d"),
         Stage = factor(Stage, levels = c("Juveniles", "Subadults", 
                                          "Adults", "Total")),
         p_value = 
           case_when(CountStage %in% c("CJ2011", "CJ2020") ~ pop.diff.cj$p.value,
                     CountStage %in% c("CS2011", "CS2020") ~ pop.diff.cs$p.value,
                     CountStage %in% c("CA2011", "CA2020") ~ pop.diff.ca$p.value,
                     CountStage %in% c("CT2011", "CT2020") ~ pop.diff.ct$p.value)) %>%
  group_by(Stage) %>%
  mutate(label.y = max(Count)) %>% ungroup() %>%
  ggpaired(x = "Year", y = "Count", id = "Plot", 
           color = "Year", line.color = alpha("grey", 0.2),
           line.size = 0.4, palette = "jco") +
  # wilcox paired test
  stat_compare_means(paired = TRUE, label.x = 1.2, size = 3) +
  geom_text(aes(x = 0.5,  y = label.y, label = Label, size = 4)) +
  facet_wrap(~Stage, nrow = 2, scales = "free") + 
  theme_classic() + mythemes +
  labs(x = "Year", y = "Cacti per plot") +
  theme(legend.position = "none") -> cactus.wilcox.plot

cactus.wilcox.plot
```

At all stages, we see changes in cactus density. There is a very weak change in adult cactus.

Let's just tabulate a summary of cactus density in our plots before and after tortoise reintroduction.

```{r, cactus-density-estimates-in-plots}
t(
    sapply(iguana_plots[,16:23], function(...) 
      list(means = mean(..., na.rm = T)/((pi*25^2)/10000), 
           se = (sd(..., na.rm = T)/sqrt(43))/((pi*25^2)/10000)))
  )
```

### Cactus count GLMMs

Finally, let's construct the GLMMs for cactus plot counts. We'll do this for each age class of cactus and the total count, starting with *juvenile* cactus.

```{r, cactus-juvenile-GLMM}
# models
## null
cactus.null <-glmer(CJ ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CJ ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CJ ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
          type = "fe", ci.lvl = 0.95)  %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) -> cactus.pred


cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.cj.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes +
  labs(x = "Year", y = expression(Juveniles ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.cj.plot
```

Juvenile cactus counts have increased---almost tripled---before and after tortoise introduction. There is also a positive effect of tortoise density on juvenile cactus. Worth noticing that the high density tortoise areas seemed to have more cactus before there were any tortoise, which may just reflect the similar habitat selection strategies of iguanas at these different sites.

What about *subadult* cactus?

```{r, cactus-subadult-GLMM}
# models
## null
cactus.null <-glmer(CS ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CS ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CS ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95)%>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2)) 

# plot iguana density predictions
quadrant.cs.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + 
  labs(x = "Year", y = expression(Subadults ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.cs.plot
```

Again we see an increase in subadult cactus. The effect here is weaker than for juveniles. No effect of tortoise density here.

What about **adult** cactus? We shouldn't see a noticeable change here.

```{r, cactus-adult-GLMM}
# models
## null
cactus.null <-glmer(CA ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## time
cactus.year <-glmer(CA ~ year + (1|Plot), 
                  family = poisson, data = iguana.total)
## time x tortoise
cactus.yearXtort <- glmer(CA ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.ca.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), name = "Tortoise density") +
  theme_classic() + mythemes + 
  labs(x = "Year", y = expression(Adults ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.ca.plot
```

There is a slight decline in adult cactus counts from 2011 to 2020.

Let's look at *total* cactus change.

```{r, cactus-total-GLMM}
# models
## null
cactus.null <-glmer(CT ~ 1 + (1|Plot), 
                  family = poisson, data = iguana.total)
## year
cactus.year <- glmer(CT ~ year + (1|Plot), 
                    family = poisson, data = iguana.total)
## fitted
cactus.yearXtort <- glmer(CT ~ year * tdencat + (1|Plot), 
                    family = poisson, data = iguana.total)

# compare null to fitted with Likelihood ratio test
lrtest(cactus.null, cactus.year, cactus.yearXtort)

# inspect model residuals
simulationOutput <- simulateResiduals(fittedModel = cactus.yearXtort)
plot(simulationOutput)
summary(cactus.yearXtort) 

# get predictions from fitted model
## iguana count predictions over tortoise and time contrast
cactus.pred <- ggpredict(cactus.yearXtort, terms = c("year", "tdencat"), 
                         type = "fe", ci.lvl = 0.95) %>%
  mutate(predicted = predicted / ((pi*25^2)/100^2),
         conf.low = conf.low / ((pi*25^2)/100^2),
         conf.high = conf.high / ((pi*25^2)/100^2))

# plot iguana density predictions
quadrant.ct.plot <-
  ggplot(cactus.pred, aes(x = x, y = predicted, group = group, fill = group)) +
  geom_col(stat = "identity", position = position_dodge(0.5), width = 0.4) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                position = position_dodge(0.5), width = 0) +
  scale_fill_manual(values = c("grey50", "grey15"), 
                    name = "Tortoise density") +
  theme_classic() + mythemes + labs(x = "Year", y = expression(Total ~ ha^-1)) +
  theme(legend.position = "top", legend.title = element_text(size = 13), 
        legend.text = element_text(size = 12))

quadrant.ct.plot
```

Overall, we see an increase in cactus in the tortoise release zone on Santa Fe between 2011 and 2020. The overall change is independent of tortoise density variation, but as we saw before that variable is informative for certain cactus stages.

Let's pull all these cactus figures together.

```{r, cactus-GLMMs, fig.height = 5, fig.width = 7}
ggarrange(quadrant.cj.plot, quadrant.cs.plot, 
          quadrant.ca.plot, quadrant.ct.plot,
          nrow = 2, ncol = 2, labels = c("a", "b", "c", "d"), align = "hv",
          label.x = c(0.23, 0.23, 0.23, 0.23), common.legend = TRUE, legend = "bottom") +
  theme(plot.margin = unit(c(10,0,0,0), "mm")) +
  annotate("text", x = 0.5, y = 1.02, label = "Cactus change", size = 5)
```


It may also be helpful to visualize changes in proportions of different age classes of cactus from 2011 to 2020.

```{r, cactus-stage-composition}
iguana.class.tab <-
  data.frame(year = rep(iguana.total$year, 3),
             iguana = c(iguana.total$CJ, iguana.total$CS, iguana.total$CA),
             type = c(rep("Juvenile", nrow(iguana.total)), 
                      rep("Subadult", nrow(iguana.total)),
                      rep("Adult", nrow(iguana.total))),
             total = rep(iguana.total$CT, 3))

iguana.class.tab %>%
  mutate(prop = iguana / total,
         type = factor(type, levels = c("Adult", "Subadult", "Juvenile"))) %>%
  group_by(type, year) %>%
  summarise(mean_prop = mean(prop),
            se_prop = sd(prop)/sqrt(n())) %>%
  ungroup() -> iguana.class.props 

cactus.prop.plot <-
  ggplot(iguana.class.props, aes(x = year, fill = type)) +
  geom_bar(aes(y = mean_prop), stat = "identity") +
  geom_text(aes(label = round(mean_prop,2), y = mean_prop), 
            position = position_stack(vjust = 0.5), size = 4) +
  scale_fill_manual(values = col2[c(2:4)], name = "Stage") +
  scale_x_discrete(limits=rev, expand=c(-2,0)) +
  labs(x = NULL, y = "Proportion of cacti") + coord_flip() +
  theme_void() + mythemes + 
  theme(axis.text.x = element_blank(), legend.position = "none") +
  annotate("text", y = 0.8, x = 0.3, label = "Adult", color = col2[2], size = 5) +
  annotate("text", y = 0.45, x = 0.3, label = "Subadult", color = col2[3], size = 5) +
  annotate("text", y = 0.15, x = 0.3, label = "Juvenile", color = col2[4], size = 5)

cactus.prop.plot
```

The cactus population seems to have some signs of positive recruitment in the last 10 years!

Let's just plot this one more way, combined with the Wilcox outputs from before.

```{r, cactus-wilcoxin-stage-composition, fig.height = 7, fig.width = 7}
ggarrange(
  cactus.wilcox.plot, 
  cactus.prop.plot + annotate("text", y = 0, x = 2.8, 
                              label = "e", color = "black", size = 5), 
  nrow = 2, heights = c(4, 1))
```


Future monitoring, especially a repeat of the full-island iguana survey, will be essential for describing iguana and cactus demographic change with the growing tortoise population.

\ 
\ 

# Session info
***

```{r}
sessionInfo()
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

# References